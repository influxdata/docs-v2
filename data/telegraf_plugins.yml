input:
  - name: ActiveMQ
    id: activemq
    description: |
      This plugin gather queues, topics & subscribers metrics using ActiveMQ
      Console API.
    introduced: 
    tags: []
  - name: Aerospike
    id: aerospike
    description: |
      **DEPRECATED: As of version 1.30 the Aerospike plugin has been deprecated
      in favor of the prometheus plugin and get node statistics & stats for all
      the configured namespaces.

      For what the measurements mean, please consult the [Aerospike Metrics
      Reference Docs](http://www.aerospike.com/docs/reference/metrics).

      The metric names, to make it less complicated in querying, have replaced
      all `-` with `_` as Aerospike metrics come in both forms (no idea why).

      All metrics are attempted to be cast to integers, then booleans, then
      strings.
    introduced: 
    tags: []
  - name: Alibaba (Aliyun) CloudMonitor Service Statistics
    id: aliyuncms
    description: |
      Here and after we use `Aliyun` instead `Alibaba` as it is default naming
      across web console and docs.

      This plugin will pull metric statistics from Aliyun CMS.
    introduced: 
    tags: []
  - name: AMD ROCm System Management Interface (SMI)
    id: amd_rocm_smi
    description: |
      This plugin uses a query on the [`rocm-smi`]() binary to pull GPU stats
      including memory and GPU usage, temperatures and other.
    introduced: 
    tags: []
  - name: AMQP Consumer
    id: amqp_consumer
    description: |
      This plugin provides a consumer for use with AMQP 0-9-1, a prominent
      implementation of this protocol being
      [RabbitMQ](https://www.rabbitmq.com/).

      Metrics are read from a topic exchange using the configured queue and
      binding_key.

      Message payload should be formatted in one of the Telegraf Data Formats.

      For an introduction to AMQP see:

      - [amqp - concepts](https://www.rabbitmq.com/tutorials/amqp-concepts.html)
      - [rabbitmq: getting started](https://www.rabbitmq.com/getstarted.html)
    introduced: 
    tags: []
  - name: Apache
    id: apache
    description: |
      The Apache plugin collects server performance information using the
      [`mod_status`](https://httpd.apache.org/docs/2.4/mod/mod_status.html)
      module of the [Apache HTTP Server](https://httpd.apache.org/).

      Typically, the `mod_status` module is configured to expose a page at the
      `/server-status?auto` location of the Apache server. The
      [ExtendedStatus](https://httpd.apache.org/docs/2.4/mod/core.html#extendedstatus)
      option must be enabled in order to collect all available fields. For
      information about how to configure your server reference the [module
      documentation](https://httpd.apache.org/docs/2.4/mod/mod_status.html#enable).
    introduced: 
    tags: []
  - name: APCUPSD
    id: apcupsd
    description: |
      This plugin reads data from an apcupsd daemon over its NIS network
      protocol.
    introduced: 
    tags: []
  - name: Aurora
    id: aurora
    description: |
      The Aurora Input Plugin gathers metrics from [Apache
      Aurora](https://aurora.apache.org/) schedulers.

      For monitoring recommendations reference [Monitoring your Aurora
      cluster](https://aurora.apache.org/documentation/latest/operations/monitoring/)
    introduced: 
    tags: []
  - name: Azure Monitor
    id: azure_monitor
    description: |
      The `azure_monitor` plugin, gathers metrics of each Azure resource using
      Azure Monitor API. Uses **Logz.io azure-monitor-metrics-receiver**
      package - an SDK wrapper for Azure Monitor SDK.
    introduced: 
    tags: []
  - name: Azure Storage Queue
    id: azure_storage_queue
    description: |
      This plugin gathers sizes of Azure Storage Queues.
    introduced: 
    tags: []
  - name: bcache
    id: bcache
    description: |
      Get bcache stat from stats_total directory and dirty_data file.
    introduced: 
    tags: []
  - name: Beanstalkd
    id: beanstalkd
    description: |
      The `beanstalkd` plugin collects server stats as well as tube stats
      (reported by `stats` and `stats-tube` commands respectively).
    introduced: 
    tags: []
  - name: Beat
    id: beat
    description: |
      The Beat plugin will collect metrics from the given Beat instances. It is
      known to work with Filebeat and Kafkabeat.
    introduced: 
    tags: []
  - name: BIND 9 Nameserver Statistics
    id: bind
    description: |
      This plugin decodes the JSON or XML statistics provided by BIND 9
      nameservers.
    introduced: 
    tags: []
  - name: Bond
    id: bond
    description: |
      The Bond input plugin collects network bond interface status for both the
      network bond interface as well as slave interfaces. The plugin collects
      these metrics from `/proc/net/bonding/*` files.
    introduced: 
    tags: []
  - name: Burrow Kafka Consumer Lag Checking
    id: burrow
    description: |
      Collect Kafka topic, consumer and partition status via
      [Burrow](https://github.com/linkedin/Burrow) HTTP
      [API](https://github.com/linkedin/Burrow/wiki/HTTP-Endpoint).

      Supported Burrow version: `1.x`
    introduced: 
    tags: []
  - name: Ceph Storage
    id: ceph
    description: |
      Collects performance metrics from the MON and OSD nodes in a Ceph storage
      cluster.

      Ceph has introduced a Telegraf and Influx plugin in the 13.x Mimic
      release. The Telegraf module sends to a Telegraf configured with a
      socket_listener. [Learn more in their
      docs](https://docs.ceph.com/en/latest/mgr/telegraf/)
    introduced: 
    tags: []
  - name: CGroup
    id: cgroup
    description: |
      This input plugin will capture specific statistics per cgroup.

      Consider restricting paths to the set of cgroups you really want to
      monitor if you have a large number of cgroups, to avoid any cardinality
      issues.

      Following file formats are supported:

      * Single value

      * New line separated values

      * Space separated values

      * Space separated keys and value, separated by new line
    introduced: 
    tags: []
  - name: chrony
    id: chrony
    description: |
      This plugin queries metrics from a chrony NTP server. For details on the
      meaning of the gathered fields please check the [chronyc
      manual](https://chrony-project.org/doc/4.4/chronyc.html)
    introduced: 
    tags: []
  - name: Cisco Model-Driven Telemetry (MDT)
    id: cisco_telemetry_mdt
    description: |
      Cisco model-driven telemetry (MDT) is an input plugin that consumes
      telemetry data from Cisco IOS XR, IOS XE and NX-OS platforms. It supports
      TCP & GRPC dialout transports. RPC-based transport can utilize TLS for
      authentication and encryption. Telemetry data is expected to be GPB-KV
      (self-describing-gpb) encoded.

      The GRPC dialout transport is supported on various IOS XR (64-bit) 6.1.x
      and later, IOS XE 16.10 and later, as well as NX-OS 7.x and later
      platforms.

      The TCP dialout transport is supported on IOS XR (32-bit and 64-bit)
      6.1.x and later.
    introduced: 
    tags: []
  - name: ClickHouse
    id: clickhouse
    description: |
      This plugin gathers the statistic data from
      [ClickHouse](https://github.com/ClickHouse/ClickHouse) server.

      User's on Clickhouse Cloud will not see the Zookeeper metrics as they may
      not have permissions to query those tables.
    introduced: 
    tags: []
  - name: Google Cloud PubSub
    id: cloud_pubsub
    description: |
      The GCP PubSub plugin ingests metrics from [Google Cloud
      PubSub](https://cloud.google.com/pubsub) and creates metrics using one of
      the supported [input data formats](/telegraf/v1/data_formats/input).
    introduced: 
    tags: []
  - name: Google Cloud PubSub Push
    id: cloud_pubsub_push
    description: |
      The Google Cloud PubSub Push listener is a service input plugin that
      listens for messages sent via an HTTP POST from [Google Cloud
      PubSub](https://cloud.google.com/pubsub). The plugin expects messages in
      Google's Pub/Sub JSON Format ONLY. The intent of the plugin is to allow
      Telegraf to serve as an endpoint of the Google Pub/Sub 'Push' service.
      Google's PubSub service will **only** send over HTTPS/TLS so this plugin
      must be behind a valid proxy or must be configured to use TLS.

      Enable TLS by specifying the file names of a service TLS certificate and
      key.

      Enable mutually authenticated TLS and authorize client connections by
      signing certificate authority by including a list of allowed CA
      certificate file names in `tls_allowed_cacerts`.
    introduced: 
    tags: []
  - name: Amazon CloudWatch Statistics
    id: cloudwatch
    description: |
      This plugin will pull Metric Statistics from Amazon CloudWatch.
    introduced: 
    tags: []
  - name: CloudWatch Metric Streams
    id: cloudwatch_metric_streams
    description: |
      The CloudWatch Metric Streams plugin is a service input plugin that
      listens for metrics sent via HTTP and performs the required processing
      for Metric Streams from AWS.

      For cost, see the Metric Streams example in CloudWatch pricing.
    introduced: 
    tags: []
  - name: Conntrack
    id: conntrack
    description: |
      Collects stats from Netfilter's conntrack-tools.

      There are two collection mechanisms for this plugin:
    introduced: 
    tags: []
  - name: Consul
    id: consul
    description: |
      This plugin will collect statistics about all health checks registered in
      the Consul. It uses [Consul
      API](https://www.consul.io/docs/agent/http/health.html#health_state) to
      query the data. It will not report the
      [telemetry](https://www.consul.io/docs/agent/telemetry.html) but Consul
      can report those stats already using StatsD protocol if needed.
    introduced: 
    tags: []
  - name: Hashicorp Consul Agent Metrics
    id: consul_agent
    description: |
      This plugin grabs metrics from a Consul agent. Telegraf may be present in
      every node and connect to the agent locally. In this case should be
      something like `http://127.0.0.1:8500`.

      > Tested on Consul 1.10.4 .
    introduced: 
    tags: []
  - name: Couchbase
    id: couchbase
    description: |
      Couchbase is a distributed NoSQL database. This plugin gets metrics for
      each Couchbase node, as well as detailed metrics for each bucket, for a
      given couchbase server.
    introduced: 
    tags: []
  - name: CouchDB
    id: couchdb
    description: |
      The CouchDB plugin gathers metrics of CouchDB using [_stats] endpoint.
    introduced: 
    tags: []
  - name: CPU
    id: cpu
    description: |
      The `cpu` plugin gather metrics on the system CPUs.
    introduced: 
    tags: []
  - name: Counter-Strike Global Offensive (CSGO)
    id: csgo
    description: |
      The `csgo` plugin gather metrics from Counter-Strike: Global Offensive
      servers.
    introduced: 
    tags: []
  - name: ctrlX Data Layer
    id: ctrlx_datalayer
    description: |
      The `ctrlx_datalayer` plugin gathers data from the ctrlX Data Layer, a
      communication middleware running on [ctrlX CORE
      devices](https://ctrlx-core.com) from [Bosch
      Rexroth](https://boschrexroth.com). The platform is used for professional
      automation applications like industrial automation, building automation,
      robotics, IoT Gateways or as classical PLC. For more information, see
      [ctrlX AUTOMATION](https://ctrlx-automation.com).
    introduced: 
    tags: []
  - name: DC/OS
    id: dcos
    description: |
      This input plugin gathers metrics from a DC/OS cluster's [metrics
      component](https://docs.mesosphere.com/1.10/metrics/).
    introduced: 
    tags: []
  - name: Directory Monitor
    id: directory_monitor
    description: |
      This plugin monitors a single directory (traversing sub-directories), and
      takes in each file placed in the directory. The plugin will gather all
      files in the directory at the configured interval, and parse the ones
      that haven't been picked up yet.

      This plugin is intended to read files that are moved or copied to the
      monitored directory, and thus files should also not be used by another
      process or else they may fail to be gathered. Please be advised that this
      plugin pulls files directly after they've been in the directory for the
      length of the configurable `directory_duration_threshold`, and thus files
      should not be written 'live' to the monitored directory. If you
      absolutely must write files directly, they must be guaranteed to finish
      writing before the `directory_duration_threshold`.
    introduced: 
    tags: []
  - name: Disk
    id: disk
    description: |
      The disk input plugin gathers metrics about disk usage.

      Note that `used_percent` is calculated by doing `used / (used + free)`,
      _not_ `used / total`, which is how the unix `df` command does it. See
      [wikipedia - df](https://en.wikipedia.org/wiki/Df_(Unix)) for more
      details.
    introduced: 
    tags: []
  - name: DiskIO
    id: diskio
    description: |
      The diskio input plugin gathers metrics about disk traffic and timing.
    introduced: 
    tags: []
  - name: Disque
    id: disque
    description: |
      [Disque](https://github.com/antirez/disque) is an ongoing experiment to
      build a distributed, in-memory, message broker.
    introduced: 
    tags: []
  - name: DMCache
    id: dmcache
    description: |
      This plugin provide a native collection for dmsetup based statistics for
      dm-cache.

      This plugin requires sudo, that is why you should setup and be sure that
      the telegraf is able to execute sudo without a password.

      `sudo /sbin/dmsetup status --target cache` is the full command that
      telegraf will run for debugging purposes.
    introduced: 
    tags: []
  - name: DNS Query
    id: dns_query
    description: |
      The DNS plugin gathers dns query times in milliseconds - like
      [Dig](https://en.wikipedia.org/wiki/Dig_\(command\))
    introduced: 
    tags: []
  - name: Docker
    id: docker
    description: |
      The docker plugin uses the Docker Engine API to gather metrics on running
      docker containers.

      The docker plugin uses the [Official Docker
      Client](https://github.com/moby/moby/tree/master/client) to gather stats
      from the [Engine API](https://docs.docker.com/engine/api/v1.24/).
    introduced: 
    tags: []
  - name: Docker Log
    id: docker_log
    description: |
      The docker log plugin uses the Docker Engine API to get logs on running
      docker containers.

      The docker plugin uses the [Official Docker
      Client](https://github.com/moby/moby/tree/master/client) to gather logs
      from the [Engine API](https://docs.docker.com/engine/api/v1.24/).

      **Note:** This plugin works only for containers with the `local` or
      `json-file` or `journald` logging driver.
    introduced: 
    tags: []
  - name: Dovecot
    id: dovecot
    description: |
      The dovecot plugin uses the Dovecot [v2.1 stats
      protocol](http://wiki2.dovecot.org/Statistics/Old) to gather metrics on
      configured domains.

      When using Dovecot v2.3 you are still able to use this protocol by
      following the [upgrading
      steps](https://wiki2.dovecot.org/Upgrading/2.3#Statistics_Redesign).
    introduced: 
    tags: []
  - name: Data Plane Development Kit (DPDK)
    id: dpdk
    description: |
      The `dpdk` plugin collects metrics exposed by applications built with
      [Data Plane Development Kit](https://www.dpdk.org/) which is an extensive
      set of open source libraries designed for accelerating packet processing
      workloads.

      DPDK provides APIs that enable exposing various statistics from the
      devices used by DPDK applications and enable exposing KPI metrics
      directly from applications. Device statistics include e.g. common
      statistics available across NICs, like: received and sent packets,
      received and sent bytes etc. In addition to this generic statistics, an
      extended statistics API is available that allows providing more detailed,
      driver-specific metrics that are not available as generic statistics.

      [DPDK Release
      20.05](https://doc.dpdk.org/guides/rel_notes/release_20_05.html)
      introduced updated telemetry interface that enables DPDK libraries and
      applications to provide their telemetry. This is referred to as `v2`
      version of this socket-based telemetry interface. This release enabled
      e.g. reading driver-specific extended stats (`/ethdev/xstats`) via this
      new interface.

      [DPDK Release
      20.11](https://doc.dpdk.org/guides/rel_notes/release_20_11.html)
      introduced reading via `v2` interface common statistics (`/ethdev/stats`)
      in addition to existing (`/ethdev/xstats`).

      [DPDK Release
      21.11](https://doc.dpdk.org/guides/rel_notes/release_21_11.html)
      introduced reading via `v2` interface additional ethernet device
      information (`/ethdev/info`). This version also adds support for exposing
      telemetry from multiple `--in-memory` instances of DPDK via dedicated
      sockets. The plugin supports reading from those sockets when `in_memory`
      option is set.

      The example usage of `v2` telemetry interface can be found in [Telemetry
      User Guide](https://doc.dpdk.org/guides/howto/telemetry.html). A variety
      of [DPDK Sample
      Applications](https://doc.dpdk.org/guides/sample_app_ug/index.html) is
      also available for users to discover and test the capabilities of DPDK
      libraries and to explore the exposed metrics.

      > **DPDK Version Info:** This plugin uses this `v2` interface to read
      > telemetry data from applications build with `DPDK version >= 20.05`. The
      > default configuration include reading common statistics from
      > `/ethdev/stats` that is available from `DPDK version >= 20.11`. When
      > using `DPDK 20.05 <= version < DPDK 20.11` it is recommended to disable
      > querying `/ethdev/stats` by setting corresponding `exclude_commands`
      > configuration option.**NOTE:** Since DPDK will most likely run with root
      > privileges, the socket telemetry interface exposed by DPDK will also
      > require root access. This means that either access permissions have to
      > be adjusted for socket telemetry interface to allow Telegraf to access
      > it, or Telegraf should run with root privileges.**NOTE:** There are
      > known issues with exposing telemetry from multiple `--in-memory`
      > instances while using `DPDK 21.11.1`. The recommended version to use in
      > conjunction with `in_memory` plugin option is `DPDK 21.11.2` or higher.
    introduced: 
    tags: []
  - name: Amazon ECS
    id: ecs
    description: |
      Amazon ECS, Fargate compatible, input plugin which uses the Amazon ECS
      metadata and stats
      [v2](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-metadata-endpoint-v2.html)
      or
      [v3](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-metadata-endpoint-v3.html)
      API endpoints to gather stats on running containers in a Task.

      The telegraf container must be run in the same Task as the workload it is
      inspecting.

      This is similar to (and reuses a few pieces of) the
      [Docker](/telegraf/v1/plugins/#input-docker) input plugin, with some ECS
      specific modifications for AWS metadata and stats formats.

      The amazon-ecs-agent (though it _is_ a container running on the host) is
      not present in the metadata/stats endpoints.
    introduced: 
    tags: []
  - name: Elasticsearch
    id: elasticsearch
    description: |
      The [elasticsearch](https://www.elastic.co/) plugin queries endpoints to
      obtain [Node
      Stats](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-nodes-stats.html)
      and optionally
      [Cluster-Health](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-health.html)
      metrics.

      In addition, the following optional queries are only made by the master
      node: [Cluster
      Stats](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-stats.html)
      [Indices
      Stats](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-stats.html)
      [Shard
      Stats](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-stats.html)

      Specific Elasticsearch endpoints that are queried:

      - Node: either /_nodes/stats or /_nodes/_local/stats depending on 'local'
      configuration setting
      - Cluster Heath: /_cluster/health?level=indices
      - Cluster Stats: /_cluster/stats
      - Indices Stats: /_all/_stats
      - Shard Stats: /_all/_stats?level=shards

      Note that specific statistics information can change between
      Elasticsearch versions. In general, this plugin attempts to stay as
      version-generic as possible by tagging high-level categories only and
      using a generic json parser to make unique field names of whatever
      statistics names are provided at the mid-low level.
    introduced: 
    tags: []
  - name: Elasticsearch Query
    id: elasticsearch_query
    description: |
      This [elasticsearch](https://www.elastic.co/) query plugin queries
      endpoints to obtain metrics from data stored in an Elasticsearch cluster.

      The following is supported:

      - return number of hits for a search query
      - calculate the avg/max/min/sum for a numeric field, filtered by a query,
      aggregated per tag
      - count number of terms for a particular field
    introduced: 
    tags: []
  - name: Ethtool
    id: ethtool
    description: |
      The ethtool input plugin pulls ethernet device stats. Fields pulled will
      depend on the network device and driver.
    introduced: 
    tags: []
  - name: Event Hub Consumer
    id: eventhub_consumer
    description: |
      This plugin provides a consumer for use with Azure Event Hubs and Azure
      IoT Hub.
    introduced: 
    tags: []
  - name: Exec
    id: exec
    description: |
      The `exec` plugin executes all the `commands` in parallel on every
      interval and parses metrics from their output in any one of the accepted
      Input Data Formats.

      This plugin can be used to poll for custom metrics from any source.
    introduced: 
    tags: []
  - name: Execd
    id: execd
    description: |
      The `execd` plugin runs an external program as a long-running daemon. The
      programs must output metrics in any one of the accepted [Input Data
      Formats](/telegraf/v1/data_formats/input) on the process's STDOUT, and is
      expected to stay running. If you'd instead like the process to collect
      metrics and then exit, check out the [inputs.exec](../exec/README.md)
      plugin.

      The `signal` can be configured to send a signal the running daemon on
      each collection interval. This is used for when you want to have Telegraf
      notify the plugin when it's time to run collection. STDIN is recommended,
      which writes a new line to the process's STDIN.

      STDERR from the process will be relayed to Telegraf's logging facilities.
      By default all messages on `stderr` will be logged as errors. However,
      you can log to other levels by prefixing your message with `E!` for
      error, `W!` for warning, `I!` for info, `D!` for debugging and `T!` for
      trace levels followed by a space and the actual message. For example
      outputting `I! A log message` will create a `info` log line in your
      Telegraf logging output.
    introduced: 
    tags: []
  - name: Fail2ban
    id: fail2ban
    description: |
      The fail2ban plugin gathers the count of failed and banned ip addresses
      using [fail2ban](https://www.fail2ban.org).

      This plugin runs the `fail2ban-client` command which generally requires
      root access. Acquiring the required permissions can be done using several
      methods:

      - Use sudo
    introduced: 
    tags: []
  - name: Fibaro
    id: fibaro
    description: |
      The Fibaro plugin makes HTTP calls to the Fibaro controller API to gather
      values of hooked devices. Those values could be true (1) or false (0) for
      switches, percentage for dimmers, temperature, etc.

      By default, this plugin supports HC2 devices. To support HC3 devices,
      please use the device type config option.
    introduced: 
    tags: []
  - name: File
    id: file
    description: |
      The file plugin parses the **complete** contents of a file **every
      interval** using the selected [input data
      format](/telegraf/v1/data_formats/input).

      **Note:** If you wish to parse only newly appended lines use the
      [tail](/telegraf/v1/plugins/#input-tail) input plugin instead.
    introduced: 
    tags: []
  - name: Filecount
    id: filecount
    description: |
      Reports the number and total size of files in specified directories.
    introduced: 
    tags: []
  - name: Filestat
    id: filestat
    description: |
      The filestat plugin gathers metrics about file existence, size, and other
      stats.
    introduced: 
    tags: []
  - name: Fireboard
    id: fireboard
    description: |
      The fireboard plugin gathers the real time temperature data from
      fireboard thermometers. In order to use this input plugin, you'll need to
      sign up to use the [Fireboard REST
      API](https://docs.fireboard.io/reference/restapi.html).
    introduced: 
    tags: []
  - name: Fluentd
    id: fluentd
    description: |
      The fluentd plugin gathers metrics from plugin endpoint provided by
      [in_monitor plugin](). This plugin understands data provided by
      /api/plugin.json resource (/api/config.json is not covered).

      You might need to adjust your fluentd configuration, in order to reduce
      series cardinality in case your fluentd restarts frequently. Every time
      fluentd starts, `plugin_id` value is given a new random value. According
      to [fluentd documentation](), you are able to add `@id` parameter for
      each plugin to avoid this behaviour and define custom `plugin_id`.

      example configuration with `@id` parameter for http plugin:
    introduced: 
    tags: []
  - name: GitHub
    id: github
    description: |
      Gather repository information from [GitHub](https://www.github.com)
      hosted repositories.

      **Note:** Telegraf also contains the
      [webhook](/telegraf/v1/plugins/#input-github) input which can be used as
      an alternative method for collecting repository information.
    introduced: 
    tags: []
  - name: gNMI (gRPC Network Management Interface)
    id: gnmi
    description: |
      This plugin consumes telemetry data based on the
      [gNMI](https://github.com/openconfig/reference/blob/master/rpc/gnmi/gnmi-specification.md)
      Subscribe method. TLS is supported for authentication and encryption.
      This input plugin is vendor-agnostic and is supported on any platform
      that supports the gNMI spec.

      For Cisco devices:

      It has been optimized to support gNMI telemetry as produced by Cisco IOS
      XR (64-bit) version 6.5.1, Cisco NX-OS 9.3 and Cisco IOS XE 16.12 and
      later.

      Please check the troubleshooting section in case of problems, e.g. when
      getting an *empty metric-name warning*!
    introduced: 
    tags: []
  - name: Google Cloud Storage
    id: google_cloud_storage
    description: |
      The Google Cloud Storage plugin will collect metrics on the given Google
      Cloud Storage Buckets.
    introduced: 
    tags: []
  - name: GrayLog
    id: graylog
    description: |
      The Graylog plugin can collect data from remote Graylog service URLs.

      Plugin currently support two type of end points:-

      - multiple (e.g.
      `http://[graylog-server-ip]:9000/api/system/metrics/multiple`)
      - namespace (e.g.
      `http://[graylog-server-ip]:9000/api/system/metrics/namespace/{namespace}`)

      End Point can be a mix of one multiple end point and several namespaces
      end points

      Note: if namespace end point specified metrics array will be ignored for
      that call.
    introduced: 
    tags: []
  - name: HAProxy
    id: haproxy
    description: |
      The [HAProxy](http://www.haproxy.org/) input plugin gathers
      [statistics](https://cbonte.github.io/haproxy-dconv/1.9/intro.html#3.3.16)
      using the [stats
      socket](https://cbonte.github.io/haproxy-dconv/1.8/configuration.html#3.1-stats%20socket)
      or [HTTP statistics
      page](https://cbonte.github.io/haproxy-dconv/1.9/management.html#9) of a
      HAProxy server.
    introduced: 
    tags: []
  - name: HDDtemp
    id: hddtemp
    description: |
      This plugin reads data from hddtemp daemon.

      Hddtemp should be installed and its daemon running.
    introduced: 
    tags: []
  - name: HTTP
    id: http
    description: |
      The HTTP input plugin collects metrics from one or more HTTP(S)
      endpoints. The endpoint should have metrics formatted in one of the
      supported input data formats. Each data format has its own unique set of
      configuration options which can be added to the input configuration.
    introduced: 
    tags: []
  - name: HTTP Listener v2
    id: http_listener_v2
    description: |
      HTTP Listener v2 is a service input plugin that listens for metrics sent
      via HTTP. Metrics may be sent in any supported [data
      format](/telegraf/v1/data_formats/input). For metrics in [InfluxDB Line
      Protocol](https://docs.influxdata.com/influxdb/cloud/reference/syntax/line-protocol/)
      it's recommended to use the [`influxdb_listener`]() or
      [`influxdb_v2_listener`]() instead.

      **Note:** The plugin previously known as `http_listener` has been renamed
      `influxdb_listener`. If you would like Telegraf to act as a proxy/relay
      for InfluxDB it is recommended to use [`influxdb_listener`]() or
      [`influxdb_v2_listener`]().
    introduced: 
    tags: []
  - name: HTTP Response
    id: http_response
    description: |
      This input plugin checks HTTP/HTTPS connections.
    introduced: 
    tags: []
  - name: Hugepages
    id: hugepages
    description: |
      Transparent Huge Pages (THP) is a Linux memory management system that
      reduces the overhead of Translation Lookaside Buffer (TLB) lookups on
      machines with large amounts of memory by using larger memory pages.

      Consult [the
      website](https://www.kernel.org/doc/html/latest/admin-guide/mm/hugetlbpage.html)
      for more details.
    introduced: 
    tags: []
  - name: Icinga2
    id: icinga2
    description: |
      This plugin gather services & hosts status using Icinga2 Remote API.

      The icinga2 plugin uses the icinga2 remote API to gather status on
      running services and hosts. You can read Icinga2's documentation for
      their remote API
      [here](https://docs.icinga.com/icinga2/latest/doc/module/icinga2/chapter/icinga2-api).
    introduced: 
    tags: []
  - name: InfiniBand
    id: infiniband
    description: |
      This plugin gathers statistics for all InfiniBand devices and ports on
      the system. These are the counters that can be found in
      `/sys/class/infiniband/<dev>/port/<port>/counters/`

      **Supported Platforms**: Linux
    introduced: 
    tags: []
  - name: InfluxDB
    id: influxdb
    description: |
      The InfluxDB plugin will collect metrics on the given InfluxDB v1 servers
      from the `/debug/vars` endpoint. Read the
      [documentation](https://docs.influxdata.com/platform/monitoring/influxdata-platform/tools/measurements-internal/)
      for detailed information about `influxdb` metrics. For InfluxDB v2 and
      the `metrics` endpoint please see the section below.

      This plugin can also gather metrics from endpoints that expose
      InfluxDB-formatted endpoints. See below for more information.
    introduced: 
    tags: []
  - name: InfluxDB Listener
    id: influxdb_listener
    description: |
      InfluxDB Listener is a service input plugin that listens for requests
      sent according to the [InfluxDB HTTP
      API](https://docs.influxdata.com/influxdb/v1.8/guides/write_data/). The
      intent of the plugin is to allow Telegraf to serve as a proxy/router for
      the `/write` endpoint of the InfluxDB HTTP API.

      **Note:** This plugin was previously known as `http_listener`. If you
      wish to send general metrics via HTTP it is recommended to use the
      [`http_listener_v2`]() instead.

      The `/write` endpoint supports the `precision` query parameter and can be
      set to one of `ns`, `u`, `ms`, `s`, `m`, `h`. All other parameters are
      ignored and defer to the output plugins configuration.

      When chaining Telegraf instances using this plugin, CREATE DATABASE
      requests receive a 200 OK response with message body `{"results":[]}` but
      they are not relayed. The output configuration of the Telegraf instance
      which ultimately submits data to InfluxDB determines the destination
      database.
    introduced: 
    tags: []
  - name: InfluxDB V2 Listener
    id: influxdb_v2_listener
    description: |
      InfluxDB V2 Listener is a service input plugin that listens for requests
      sent according to the [InfluxDB HTTP
      API](https://docs.influxdata.com/influxdb/latest/api/). The intent of the
      plugin is to allow Telegraf to serve as a proxy/router for the
      `/api/v2/write` endpoint of the InfluxDB HTTP API.

      The `/api/v2/write` endpoint supports the `precision` query parameter and
      can be set to one of `ns`, `us`, `ms`, `s`. All other parameters are
      ignored and defer to the output plugins configuration.

      Telegraf minimum version: Telegraf 1.16.0
    introduced: 
    tags: []
  - name: Intel Baseband Accelerator
    id: intel_baseband
    description: |
      Intel Baseband Accelerator Input Plugin collects metrics from both
      dedicated and integrated Intel devices that provide Wireless Baseband
      hardware acceleration. These devices play a key role in accelerating 5G
      and 4G Virtualized Radio Access Networks (vRAN) workloads, increasing the
      overall compute capacity of a commercial, off-the-shelf platforms.

      Intel Baseband devices integrate various features critical for 5G and LTE
      (Long Term Evolution) networks, including e.g.:

      - Forward Error Correction (FEC) processing,
      - 4G Turbo FEC processing,
      - 5G Low Density Parity Check (LDPC)
      - a Fast Fourier Transform (FFT) block providing DFT/iDFT processing
      offload for the 5G Sounding Reference Signal (SRS)

      Supported hardware:

      - Intel® vRAN Boost integrated accelerators:4th Gen Intel® Xeon®
      Scalable processor with Intel® vRAN Boost (also known as Sapphire Rapids
      Edge Enhanced / SPR-EE)
      - External expansion cards connected to the PCI bus:Intel® vRAN Dedicated
      Accelerator ACC100 SoC (code named Mount Bryce)
    introduced: 
    tags: []
  - name: Intel® Dynamic Load Balancer (Intel® DLB) 
    id: intel_dlb
    description: |
      The `Intel DLB` plugin collects metrics exposed by applications built
      with [Data Plane Development Kit](https://www.dpdk.org/) which is an
      extensive set of open source libraries designed for accelerating packet
      processing workloads, plugin is also using bifurcated driver. More
      specifically it's targeted for applications that use Intel DLB as
      eventdev devices accessed via bifurcated driver (allowing access from
      kernel and user-space).
    introduced: 
    tags: []
  - name: Intel® Platform Monitoring Technology (Intel® PMT)
    id: intel_pmt
    description: |
      This plugin collects metrics via the Linux kernel driver for Intel®
      Platform Monitoring Technology (Intel® PMT). Intel® PMT is an
      architecture capable of enumerating and accessing hardware monitoring
      capabilities on a supported device.

      Support has been added to the mainline Linux kernel under the platform
      driver (`drivers/platform/x86/intel/pmt`) which exposes the Intel PMT
      telemetry space as a sysfs entry at `/sys/class/intel_pmt/`. Each
      discovered telemetry aggregator is exposed as a directory (with a `telem`
      prefix) containing a `guid` identifying the unique PMT space. This file
      is associated with a set of XML specification files which can be found in
      the [Intel-PMT Repository].

      This plugin discovers and parses the telemetry data exposed by the kernel
      driver using the specification inside the XML files. Furthermore, the
      plugin then reads low level samples/counters and evaluates high level
      samples/counters according to transformation formulas, and then reports
      the collected values.
    introduced: 
    tags: []
  - name: Intel Performance Monitoring Unit
    id: intel_pmu
    description: |
      This input plugin exposes Intel PMU (Performance Monitoring Unit) metrics
      available through [Linux
      Perf](https://perf.wiki.kernel.org/index.php/Main_Page) subsystem.

      PMU metrics gives insight into performance and health of IA processor's
      internal components, including core and uncore units. With the number of
      cores increasing and processor topology getting more complex the insight
      into those metrics is vital to assure the best CPU performance and
      utilization.

      Performance counters are CPU hardware registers that count hardware
      events such as instructions executed, cache-misses suffered, or branches
      mispredicted. They form a basis for profiling applications to trace
      dynamic control flow and identify hotspots.
    introduced: 
    tags: []
  - name: Intel PowerStat
    id: intel_powerstat
    description: |
      This input plugin monitors power statistics on Intel-based platforms and
      assumes presence of Linux based OS.

      Not all CPUs are supported, please see the software and hardware
      dependencies sections below to ensure platform support.

      Main use cases are power saving and workload migration. Telemetry
      frameworks allow users to monitor critical platform level metrics. Key
      source of platform telemetry is power domain that is beneficial for MANO
      Monitoring&Analytics systems to take preventive/corrective actions based
      on platform busyness, CPU temperature, actual CPU utilization and power
      statistics.
    introduced: 
    tags: []
  - name: Intel RDT
    id: intel_rdt
    description: |
      The `intel_rdt` plugin collects information provided by monitoring
      features of the Intel Resource Director Technology (Intel(R) RDT). Intel
      RDT provides the hardware framework to monitor and control the
      utilization of shared resources (ex: last level cache, memory bandwidth).
    introduced: 
    tags: []
  - name: Telegraf Internal
    id: internal
    description: |
      The `internal` plugin collects metrics about the telegraf agent itself.

      Note that some metrics are aggregates across all instances of one type of
      plugin.
    introduced: 
    tags: []
  - name: Internet Speed Monitor
    id: internet_speed
    description: |
      The `Internet Speed Monitor` collects data about the internet speed on
      the system.

      On some systems, the default settings may cause speed tests to fail; if
      this affects you then try enabling `memory_saving_mode`. This reduces the
      memory requirements for the test, and may reduce the runtime of the test.
      However, please be aware that this may also reduce the accuracy of the
      test for fast (>30Mb/s) connections. This setting enables the upstream
      [Memory Saving
      Mode](https://github.com/showwin/speedtest-go#memory-saving-mode)
    introduced: 
    tags: []
  - name: Interrupts
    id: interrupts
    description: |
      The interrupts plugin gathers metrics about IRQs from `/proc/interrupts`
      and `/proc/softirqs`.
    introduced: 
    tags: []
  - name: IPMI Sensor
    id: ipmi_sensor
    description: |
      Get bare metal metrics using the command line utility
      [`ipmitool`](https://github.com/ipmitool/ipmitool).

      If no servers are specified, the plugin will query the local machine
      sensor stats via the following command:

      or with the version 2 schema:

      When one or more servers are specified, the plugin will use the following
      command to collect remote host sensor stats:

      Any of the following parameters will be added to the aforementioned query
      if they're configured:
    introduced: 
    tags: []
  - name: Ipset
    id: ipset
    description: |
      The ipset plugin gathers packets and bytes counters from Linux ipset. It
      uses the output of the command "ipset save". Ipsets created without the
      "counters" option are ignored.

      Results are tagged with:

      - ipset name
      - ipset entry

      There are 3 ways to grant telegraf the right to run ipset:

      - Run as root (strongly discouraged)
      - Use sudo
      - Configure systemd to run telegraf with CAP_NET_ADMIN and CAP_NET_RAW
      capabilities.
    introduced: 
    tags: []
  - name: Iptables
    id: iptables
    description: |
      The iptables plugin gathers packets and bytes counters for rules within a
      set of table and chain from the Linux's iptables firewall.

      Rules are identified through associated comment. **Rules without comment
      are ignored**. Indeed we need a unique ID for the rule and the rule
      number is not a constant: it may vary when rules are inserted/deleted at
      start-up or by automatic tools (interactive firewalls, fail2ban, ...).
      Also when the rule set is becoming big (hundreds of lines) most people
      are interested in monitoring only a small part of the rule set.

      Before using this plugin **you must ensure that the rules you want to
      monitor are named with a unique comment**. Comments are added using the
      `-m comment --comment "my comment"` iptables options.

      The iptables command requires CAP_NET_ADMIN and CAP_NET_RAW capabilities.
      You have several options to grant telegraf to run iptables:

      * Run telegraf as root. This is strongly discouraged.
      * Configure systemd to run telegraf with CAP_NET_ADMIN and CAP_NET_RAW.
      This is the simplest and recommended option.
      * Configure sudo to grant telegraf to run iptables. This is the most
      restrictive option, but require sudo setup.
    introduced: 
    tags: []
  - name: IPVS
    id: ipvs
    description: |
      The IPVS input plugin uses the linux kernel netlink socket interface to
      gather metrics about ipvs virtual and real servers.

      **Supported Platforms:** Linux
    introduced: 
    tags: []
  - name: Jenkins
    id: jenkins
    description: |
      The jenkins plugin gathers information about the nodes and jobs running
      in a jenkins instance.

      This plugin does not require a plugin on jenkins and it makes use of
      Jenkins API to retrieve all the information needed.
    introduced: 
    tags: []
  - name: Jolokia2 Agent
    id: jolokia2_agent
    description: |
      The `jolokia2_agent` input plugin reads JMX metrics from one or more
      [Jolokia agent](https://jolokia.org/agent/jvm.html) REST endpoints.
    introduced: 
    tags: []
  - name: Jolokia2 Proxy
    id: jolokia2_proxy
    description: |
      The `jolokia2_proxy` input plugin reads JMX metrics from one or more
      _targets_ by interacting with a [Jolokia
      proxy](https://jolokia.org/features/proxy.html) REST endpoint.
    introduced: 
    tags: []
  - name: JTI OpenConfig Telemetry
    id: jti_openconfig_telemetry
    description: |
      This plugin reads Juniper Networks implementation of OpenConfig telemetry
      data from listed sensors using Junos Telemetry Interface. Refer to
      [openconfig.net](http://openconfig.net/) for more details about
      OpenConfig and [Junos Telemetry Interface
      (JTI)](https://www.juniper.net/documentation/en_US/junos/topics/concept/junos-telemetry-interface-oveview.html).
    introduced: 
    tags: []
  - name: Kafka Consumer
    id: kafka_consumer
    description: |
      The [Kafka](https://kafka.apache.org) consumer plugin reads from Kafka
      and creates metrics using one of the supported [input data
      formats](/telegraf/v1/data_formats/input).
    introduced: 
    tags: []
  - name: Kapacitor
    id: kapacitor
    description: |
      The Kapacitor plugin collects metrics from the given Kapacitor instances.
    introduced: 
    tags: []
  - name: Kernel
    id: kernel
    description: |
      This plugin is only available on Linux.

      The kernel plugin gathers info about the kernel that doesn't fit into
      other plugins. In general, it is the statistics available in `/proc/stat`
      that are not covered by other plugins as well as the value of
      `/proc/sys/kernel/random/entropy_avail` and optionally, Kernel Samepage
      Merging and Pressure Stall Information.

      The metrics are documented in `man 5 proc` under the `/proc/stat`
      section, as well as `man 4 random` under the `/proc interfaces` section
      (for `entropy_avail`).

      Kernel Samepage Merging is generally documented in [kernel
      documentation](https://www.kernel.org/doc/html/latest/accounting/psi.html)
      and the available metrics exposed via sysfs are documented in [admin
      guide](https://www.kernel.org/doc/html/latest/admin-guide/mm/ksm.html#ksm-daemon-sysfs-interface).

      Pressure Stall Information is exposed through `/proc/pressure` and is
      documented in [kernel
      documentation](https://www.kernel.org/doc/html/latest/accounting/psi.html).
      Kernel version 4.20 or later is required. Examples of PSI:
    introduced: 
    tags: []
  - name: Kernel VMStat
    id: kernel_vmstat
    description: |
      The kernel_vmstat plugin gathers virtual memory statistics by reading
      /proc/vmstat. For a full list of available fields see the /proc/vmstat
      section of the [proc man
      page](http://man7.org/linux/man-pages/man5/proc.5.html). For a better
      idea of what each field represents, see the [vmstat man
      page](http://linux.die.net/man/8/vmstat).
    introduced: 
    tags: []
  - name: Kibana
    id: kibana
    description: |
      The `kibana` plugin queries the [Kibana](https://www.elastic.co/) API to
      obtain the service status.

      - Telegraf minimum version: 1.8
      - Kibana minimum tested version: 6.0
    introduced: 
    tags: []
  - name: Kinesis Consumer
    id: kinesis_consumer
    description: |
      The [Kinesis](https://aws.amazon.com/kinesis/) consumer plugin reads from
      a Kinesis data stream and creates metrics using one of the supported
      [input data formats](/telegraf/v1/data_formats/input).
    introduced: 
    tags: []
  - name: KNX
    id: knx_listener
    description: |
      The KNX input plugin that listens for messages on the KNX home-automation
      bus. This plugin connects to the KNX bus via a KNX-IP interface.
      Information about supported KNX message datapoint types can be found at
      the underlying "knx-go" project site
      (<https://github.com/vapourismo/knx-go>).
    introduced: 
    tags: []
  - name: Kubernetes Inventory
    id: kube_inventory
    description: |
      This plugin generates metrics derived from the state of the following
      Kubernetes resources:

      - daemonsets
      - deployments
      - endpoints
      - ingress
      - nodes
      - persistentvolumes
      - persistentvolumeclaims
      - pods (containers)
      - services
      - statefulsets
      - resourcequotas

      Kubernetes is a fast moving project, with a new minor release every 3
      months. As such, we will aim to maintain support only for versions that
      are supported by the major cloud providers; this is roughly 4 release / 2
      years.

      **This plugin supports Kubernetes 1.11 and later.**
    introduced: 
    tags: []
  - name: Kubernetes
    id: kubernetes
    description: |
      The Kubernetes plugin talks to the Kubelet API and gathers metrics about
      the running pods and containers for a single host. It is assumed that
      this plugin is running as part of a `daemonset` within a kubernetes
      installation. This means that telegraf is running on every node within
      the cluster. Therefore, you should configure this plugin to talk to its
      locally running kubelet.

      Kubernetes is a fast moving project, with a new minor release every 3
      months. As such, this plugin aims to maintain support only for versions
      that are supported by the major cloud providers, namely, 4 release over 2
      years.
    introduced: 
    tags: []
  - name: Arista LANZ Consumer
    id: lanz
    description: |
      This plugin provides a consumer for use with Arista Networks’ Latency
      Analyzer (LANZ)

      Metrics are read from a stream of data via TCP through port 50001 on the
      switches management IP. The data is in Protobuffers format. For more
      information on Arista LANZ

      - <https://www.arista.com/en/um-eos/eos-latency-analyzer-lanz>

      This plugin uses Arista's sdk.

      - <https://github.com/aristanetworks/goarista>
    introduced: 
    tags: []
  - name: LDAP
    id: ldap
    description: |
      This plugin gathers metrics from LDAP servers' monitoring (`cn=Monitor`)
      backend. Currently this plugin supports
      [OpenLDAP](https://www.openldap.org/) and
      [389ds](https://www.port389.org/) servers.
    introduced: 
    tags: []
  - name: LeoFS
    id: leofs
    description: |
      The LeoFS plugin gathers metrics of LeoGateway, LeoManager, and
      LeoStorage using SNMP. See [LeoFS Documentation / System Administration /
      System
      Monitoring](https://leo-project.net/leofs/docs/admin/system_admin/monitoring/).
    introduced: 
    tags: []
  - name: Libvirt
    id: libvirt
    description: |
      The `libvirt` plugin collects statistics about virtualized guests on a
      system by using virtualization libvirt API, created by RedHat's Emerging
      Technology group. Metrics are gathered directly from the hypervisor on a
      host system, which means that Telegraf doesn't have to be installed and
      configured on a guest system.
    introduced: 
    tags: []
  - name: Linux CPU
    id: linux_cpu
    description: |
      The `linux_cpu` plugin gathers CPU metrics exposed on Linux-based
      systems.
    introduced: 
    tags: []
  - name: Linux Sysctl FS
    id: linux_sysctl_fs
    description: |
      The linux_sysctl_fs input provides Linux system level file metrics. The
      documentation on these fields can be found at
      <https://www.kernel.org/doc/Documentation/sysctl/fs.txt>.

      Example output:
    introduced: 
    tags: []
  - name: Logparser
    id: logparser
    description: |
      **Deprecated in Telegraf 1.15: Please use the
      [tail](/telegraf/v1/plugins/#input-tail) plugin along with the [`grok`
      data format]()**

      The `logparser` plugin streams and parses the given logfiles. Currently
      it has the capability of parsing "grok" patterns from logfiles, which
      also supports regex patterns.

      The `tail` plugin now provides all the functionality of the `logparser`
      plugin. Most options can be translated directly to the `tail` plugin:

      - For options in the `[inputs.logparser.grok]` section, the equivalent
      option will have add the `grok_` prefix when using them in the `tail`
      input.
      - The grok `measurement` option can be replaced using the standard plugin
      `name_override` option.

      This plugin also supports metric filtering and some additional common
      options.
    introduced: 
    tags: []
  - name: Logstash
    id: logstash
    description: |
      This plugin reads metrics exposed by [Logstash Monitoring
      API](https://www.elastic.co/guide/en/logstash/current/monitoring-logstash.html).

      Logstash 5 and later is supported.
    introduced: 
    tags: []
  - name: Lustre
    id: lustre2
    description: |
      The [Lustre](http://lustre.org/)® file system is an open-source,
      parallel file system that supports many requirements of leadership class
      HPC simulation environments.

      This plugin monitors the Lustre file system using its entries in the proc
      filesystem.
    introduced: 
    tags: []
  - name: LVM
    id: lvm
    description: |
      The Logical Volume Management (LVM) input plugin collects information
      about physical volumes, volume groups, and logical volumes.
    introduced: 
    tags: []
  - name: Mailchimp
    id: mailchimp
    description: |
      Pulls campaign reports from the [Mailchimp
      API](https://developer.mailchimp.com/).
    introduced: 
    tags: []
  - name: MarkLogic
    id: marklogic
    description: |
      The MarkLogic Telegraf plugin gathers health status metrics from one or
      more host.
    introduced: 
    tags: []
  - name: Mcrouter
    id: mcrouter
    description: |
      This plugin gathers statistics data from a Mcrouter server.
    introduced: 
    tags: []
  - name: mdstat
    id: mdstat
    description: |
      The mdstat plugin gathers statistics about any Linux MD RAID arrays
      configured on the host by reading /proc/mdstat. For a full list of
      available fields see the /proc/mdstat section of the [proc man
      page](http://man7.org/linux/man-pages/man5/proc.5.html). For a better
      idea of what each field represents, see the [mdstat man
      page](https://raid.wiki.kernel.org/index.php/Mdstat).

      Stat collection based on Prometheus' [mdstat collection
      library](https://github.com/prometheus/procfs/blob/master/mdstat.go).
    introduced: 
    tags: []
  - name: Memory
    id: mem
    description: |
      The mem plugin collects system memory metrics.

      For a more complete explanation of the difference between *used* and
      *actual_used* RAM, see [Linux ate my ram](http://www.linuxatemyram.com/).
    introduced: 
    tags: []
  - name: Memcached
    id: memcached
    description: |
      This plugin gathers statistics data from a Memcached server.
    introduced: 
    tags: []
  - name: Mesos
    id: mesos
    description: |
      This input plugin gathers metrics from Mesos. For more information,
      please check the [Mesos Observability
      Metrics](http://mesos.apache.org/documentation/latest/monitoring/) page.
    introduced: 
    tags: []
  - name: Minecraft
    id: minecraft
    description: |
      The `minecraft` plugin connects to a Minecraft server using the RCON
      protocol to collects scores from the server
      [scoreboard](http://minecraft.gamepedia.com/Scoreboard).

      This plugin is known to support Minecraft Java Edition versions 1.11 -
      1.14. When using an version of Minecraft earlier than 1.13, be aware that
      the values for some criterion has changed and may need to be modified.
    introduced: 
    tags: []
  - name: Mock Data
    id: mock
    description: |
      The mock input plugin generates random data based on a selection of
      different algorithms. For example, it can produce random data between a
      set of values, fake stock data, sine waves, and step-wise values.

      Additionally, users can set the measurement name and tags used to
      whatever is required to mock their situation.
    introduced: 
    tags: []
  - name: Modbus
    id: modbus
    description: |
      The Modbus plugin collects Discrete Inputs, Coils, Input Registers and
      Holding Registers via Modbus TCP or Modbus RTU/ASCII.
    introduced: 
    tags: []
  - name: MongoDB
    id: mongodb
    description: |
      See the [MongoDB Software Lifecycle
      Schedules](https://www.mongodb.com/support-policy/lifecycles) for
      supported versions.
    introduced: 
    tags: []
  - name: Monit
    id: monit
    description: |
      The `monit` plugin gathers metrics and status information about local
      processes, remote hosts, file, file systems, directories and network
      interfaces managed and watched over by [Monit](https://mmonit.com/).

      The use this plugin you should first enable the [HTTPD TCP
      port](https://mmonit.com/monit/documentation/monit.html#TCP-PORT) in
      Monit.

      Minimum Version of Monit tested with is 5.16.
    introduced: 
    tags: []
  - name: MQTT Consumer
    id: mqtt_consumer
    description: |
      The [MQTT](https://mqtt.org) consumer plugin reads from the specified
      MQTT topics and creates metrics using one of the supported [input data
      formats](/telegraf/v1/data_formats/input).
    introduced: 
    tags: []
  - name: Multifile
    id: multifile
    description: |
      The multifile input plugin allows Telegraf to combine data from multiple
      files into a single metric, creating one field or tag per file. This is
      often useful creating custom metrics from the `/sys` or `/proc`
      filesystems.

      > Note: If you wish to parse metrics from a single file formatted in one
      > of the supported [input data formats](/telegraf/v1/data_formats/input),
      > you should use the [file](/telegraf/v1/plugins/#input-file) input plugin
      > instead.
    introduced: 
    tags: []
  - name: MySQL
    id: mysql
    description: |
      This plugin gathers the statistic data from MySQL server

      * Global statuses
      * Global variables
      * Slave statuses
      * Binlog size
      * Process list
      * User Statistics
      * Info schema auto increment columns
      * InnoDB metrics
      * Table I/O waits
      * Index I/O waits
      * Perf Schema table lock waits
      * Perf Schema event waits
      * Perf Schema events statements
      * File events statistics
      * Table schema statistics

      In order to gather metrics from the performance schema, it must first be
      enabled in mySQL configuration. See the performance schema [quick
      start](https://dev.mysql.com/doc/refman/8.0/en/performance-schema-quick-start.html).
    introduced: 
    tags: []
  - name: NATS
    id: nats
    description: |
      The [NATS](http://www.nats.io/about/) monitoring plugin gathers metrics
      from the NATS [monitoring http
      server](https://docs.nats.io/running-a-nats-service/nats_admin/monitoring).
    introduced: 
    tags: []
  - name: NATS Consumer
    id: nats_consumer
    description: |
      The [NATS](https://www.nats.io/about/) consumer plugin reads from the
      specified NATS subjects and creates metrics using one of the supported
      [input data formats](/telegraf/v1/data_formats/input).

      A [Queue
      Group](https://www.nats.io/documentation/concepts/nats-queueing/) is used
      when subscribing to subjects so multiple instances of telegraf can read
      from a NATS cluster in parallel.

      There are three methods of (optionally) authenticating with NATS:
      [username/password](https://docs.nats.io/using-nats/developer/connecting/userpass),
      [a NATS creds
      file](https://docs.nats.io/using-nats/developer/connecting/creds) (NATS
      2.0), or an [nkey seed
      file](https://docs.nats.io/using-nats/developer/connecting/nkey) (NATS
      2.0).
    introduced: 
    tags: []
  - name: Neptune Apex
    id: neptune_apex
    description: |
      The Neptune Apex controller family allows an aquarium hobbyist to monitor
      and control their tanks based on various probes. The data is taken
      directly from the `/cgi-bin/status.xml` at the interval specified in the
      telegraf.conf configuration file.

      The [Neptune Apex](https://www.neptunesystems.com/) input plugin collects
      real-time data from the Apex's status.xml page.
    introduced: 
    tags: []
  - name: Net
    id: net
    description: |
      This plugin gathers metrics about network interface and protocol usage
      (Linux only).
    introduced: 
    tags: []
  - name: Network Response
    id: net_response
    description: |
      The input plugin test UDP/TCP connections response time and can optional
      verify text in the response.
    introduced: 
    tags: []
  - name: Netflow
    id: netflow
    description: |
      The `netflow` plugin acts as a collector for Netflow v5, Netflow v9 and
      IPFIX flow information. The Layer 4 protocol numbers are gathered from
      the [official IANA
      assignments](https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml).
      The internal field mappings for Netflow v5 fields are defined according
      to [Cisco's Netflow v5
      documentation](https://www.cisco.com/c/en/us/td/docs/net_mgmt/netflow_collection_engine/3-6/user/guide/format.html#wp1006186),
      Netflow v9 fields are defined according to [Cisco's Netflow v9
      documentation](https://www.cisco.com/en/US/technologies/tk648/tk362/technologies_white_paper09186a00800a3db9.html)
      and the [ASA
      extensions](https://www.cisco.com/c/en/us/td/docs/security/asa/special/netflow/asa_netflow.html).
      Definitions for IPFIX are according to [IANA assignment
      document](https://www.iana.org/assignments/ipfix/ipfix.xhtml#ipfix-nat-type).
    introduced: 
    tags: []
  - name: Netstat
    id: netstat
    description: |
      This plugin collects TCP connections state and UDP socket counts by using
      `lsof`.
    introduced: 
    tags: []
  - name: NFS Client
    id: nfsclient
    description: |
      The NFS Client input plugin collects data from /proc/self/mountstats. By
      default, only a limited number of general system-level metrics are
      collected, including basic read/write counts. If `fullstat` is set, a
      great deal of additional metrics are collected, detailed below.

      __NOTE__ Many of the metrics, even if tagged with a mount point, are
      really _per-server_. Thus, if you mount these two shares:
      `nfs01:/vol/foo/bar` and `nfs01:/vol/foo/baz`, there will be two near
      identical entries in /proc/self/mountstats. This is a limitation of the
      metrics exposed by the kernel, not the telegraf plugin.
    introduced: 
    tags: []
  - name: Nginx
    id: nginx
    description: |
      This plugin gathers basic status from the open source web server Nginx.
      Nginx Plus is a commercial version. For more information about the
      differences between Nginx (F/OSS) and Nginx Plus, see the Nginx
      [documentation](https://www.nginx.com/blog/whats-difference-nginx-foss-nginx-plus/).
    introduced: 
    tags: []
  - name: Nginx Plus
    id: nginx_plus
    description: |
      Nginx Plus is a commercial version of the open source web server Nginx.
      The use this plugin you will need a license. For more information about
      the differences between Nginx (F/OSS) and Nginx Plus, see the Nginx
      [documentation](https://www.nginx.com/blog/whats-difference-nginx-foss-nginx-plus/).

      Structures for Nginx Plus have been built based on history of [status
      module documentation]().
    introduced: 
    tags: []
  - name: Nginx Plus API
    id: nginx_plus_api
    description: |
      Nginx Plus is a commercial version of the open source web server Nginx.
      The use this plugin you will need a license. For more information about
      the differences between Nginx (F/OSS) and Nginx Plus, see the Nginx
      [documentation](https://www.nginx.com/blog/whats-difference-nginx-foss-nginx-plus/).
    introduced: 
    tags: []
  - name: Nginx Stream STS
    id: nginx_sts
    description: |
      This plugin gathers Nginx status using external virtual host traffic
      status module - <https://github.com/vozlt/nginx-module-sts>. This is an
      Nginx module that provides access to stream host status information. It
      contains the current status such as servers, upstreams, caches. This is
      similar to the live activity monitoring of Nginx plus. For module
      configuration details please see its
      [documentation](https://github.com/vozlt/nginx-module-sts#synopsis).

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Nginx Upstream Check
    id: nginx_upstream_check
    description: |
      Read the status output of the [nginx_upstream_check](). This module can
      periodically check the servers in the Nginx's upstream with configured
      request and interval to determine if the server is still available. If
      checks are failed the server is marked as "down" and will not receive any
      requests until the check will pass and a server will be marked as "up"
      again.

      The status page displays the current status of all upstreams and servers
      as well as number of the failed and successful checks. This information
      can be exported in JSON format and parsed by this input.
    introduced: 
    tags: []
  - name: Nginx Virtual Host Traffic (VTS)
    id: nginx_vts
    description: |
      This plugin gathers Nginx status using external virtual host traffic
      status module - <https://github.com/vozlt/nginx-module-vts>. This is an
      Nginx module that provides access to virtual host status information. It
      contains the current status such as servers, upstreams, caches. This is
      similar to the live activity monitoring of Nginx plus. For module
      configuration details please see its
      [documentation](https://github.com/vozlt/nginx-module-vts#synopsis).
    introduced: 
    tags: []
  - name: Hashicorp Nomad
    id: nomad
    description: |
      The Nomad plugin must grab metrics from every Nomad agent of the cluster.
      Telegraf may be present in every node and connect to the agent locally.
      In this case should be something like `http://127.0.0.1:4646`.

      > Tested on Nomad 1.1.6
    introduced: 
    tags: []
  - name: NSD
    id: nsd
    description: |
      This plugin gathers stats from
      [NSD](https://www.nlnetlabs.nl/projects/nsd/about) - an authoritative DNS
      name server.
    introduced: 
    tags: []
  - name: NSQ
    id: nsq
    description: |
      This plugin gathers metrics from [NSQ](https://nsq.io/).

      See the [NSQD API docs](https://nsq.io/components/nsqd.html) for
      endpoints that the plugin can read.
    introduced: 
    tags: []
  - name: NSQ Consumer
    id: nsq_consumer
    description: |
      The [NSQ](https://nsq.io) consumer plugin reads from NSQD and creates
      metrics using one of the supported [input data
      formats](/telegraf/v1/data_formats/input).
    introduced: 
    tags: []
  - name: Nstat
    id: nstat
    description: |
      Plugin collects network metrics from `/proc/net/netstat`,
      `/proc/net/snmp` and `/proc/net/snmp6` files
    introduced: 
    tags: []
  - name: ntpq
    id: ntpq
    description: |
      Get standard NTP query metrics, requires ntpq executable.

      Below is the documentation of the various headers returned from the NTP
      query command when running `ntpq -p`.

      - remote – The remote peer or server being synced to. “LOCAL” is
      this local host (included in case there are no remote peers or servers
      available);
      - refid – Where or what the remote peer or server is itself synchronised
      to;
      - st (stratum) – The remote peer or server Stratum
      - t (type) – Type (u: unicast or manycast client, b: broadcast or
      multicast client, l: local reference clock, s: symmetric peer, A: manycast
      server, B: broadcast server, M: multicast server, see “Automatic Server
      Discovery“);
      - when – When last polled (seconds ago, “h” hours ago, or “d”
      days ago);
      - poll – Polling frequency: rfc5905 suggests this ranges in NTPv4 from 4
      (16s) to 17 (36h) (log2 seconds), however observation suggests the actual
      displayed value is seconds for a much smaller range of 64 (26) to 1024
      (210) seconds;
      - reach – An 8-bit left-shift shift register value recording polls (bit
      set = successful, bit reset = fail) displayed in octal;
      - delay – Round trip communication delay to the remote peer or server
      (milliseconds);
      - offset – Mean offset (phase) in the times reported between this local
      host and the remote peer or server (RMS, milliseconds);
      - jitter – Mean deviation (jitter) in the time reported for that remote
      peer or server (RMS of difference of multiple time samples, milliseconds);
    introduced: 
    tags: []
  - name: Nvidia System Management Interface (SMI)
    id: nvidia_smi
    description: |
      This plugin uses a query on the
      [`nvidia-smi`](https://developer.nvidia.com/nvidia-system-management-interface)
      binary to pull GPU stats including memory and GPU usage, temp and other.
    introduced: 
    tags: []
  - name: OPC UA Client Reader
    id: opcua
    description: |
      The `opcua` plugin retrieves data from OPC UA Server devices.

      Telegraf minimum version: Telegraf 1.16 Plugin minimum tested version:
      1.16
    introduced: 
    tags: []
  - name: OPC UA Client Listener
    id: opcua_listener
    description: |
      The `opcua_listener` plugin subscribes to data from OPC UA Server
      devices.

      Telegraf minimum version: Telegraf 1.25 Plugin minimum tested version:
      1.25
    introduced: 
    tags: []
  - name: OpenLDAP
    id: openldap
    description: |
      This plugin gathers metrics from OpenLDAP's cn=Monitor backend.
    introduced: 
    tags: []
  - name: OpenNTPD
    id: openntpd
    description: |
      Get standard NTP query metrics from [OpenNTPD](http://www.openntpd.org/)
      using the ntpctl command.

      Below is the documentation of the various headers returned from the NTP
      query command when running `ntpctl -s peers`.

      - remote – The remote peer or server being synced to.
      - wt – the peer weight
      - tl – the peer trust level
      - st (stratum) – The remote peer or server Stratum
      - next – number of seconds until the next poll
      - poll – polling interval in seconds
      - delay – Round trip communication delay to the remote peer or server
      (milliseconds);
      - offset – Mean offset (phase) in the times reported between this local
      host and the remote peer or server (RMS, milliseconds);
      - jitter – Mean deviation (jitter) in the time reported for that remote
      peer or server (RMS of difference of multiple time samples, milliseconds);
    introduced: 
    tags: []
  - name: OpenSearch Query
    id: opensearch_query
    description: |
      This [OpenSearch](https://opensearch.org/) plugin queries endpoints to
      derive metrics from data stored in an OpenSearch cluster.

      The following is supported:

      - return number of hits for a search query
      - calculate the `avg`/`max`/`min`/`sum` for a numeric field, filtered by a
      query, aggregated per tag
      - `value_count` returns the number of documents for a particular field
      - `stats` (returns `sum`, `min`, `max`, `avg`, and `value_count` in one
      query)
      - extended_stats (`stats` plus stats such as sum of squares, variance, and
      standard deviation)
      - `percentiles` returns the 1st, 5th, 25th, 50th, 75th, 95th, and 99th
      percentiles
    introduced: 
    tags: []
  - name: OpenSMTPD
    id: opensmtpd
    description: |
      This plugin gathers stats from [OpenSMTPD - a FREE implementation of the
      server-side SMTP protocol](https://www.opensmtpd.org/)
    introduced: 
    tags: []
  - name: OpenStack
    id: openstack
    description: |
      Collects the metrics from following services of OpenStack:

      * CINDER(Block Storage)
      * GLANCE(Image service)
      * HEAT(Orchestration)
      * KEYSTONE(Identity service)
      * NEUTRON(Networking)
      * NOVA(Compute Service)

      At present this plugin requires the following APIs:

      * blockstorage v3
      * compute v2
      * identity v3
      * networking v2
      * orchestration v1
    introduced: 
    tags: []
  - name: OpenTelemetry
    id: opentelemetry
    description: |
      This plugin receives traces, metrics and logs from
      [OpenTelemetry](https://opentelemetry.io) clients and agents via gRPC.
    introduced: 
    tags: []
  - name: OpenWeatherMap
    id: openweathermap
    description: |
      Collect current weather and forecast data from OpenWeatherMap.

      To use this plugin you will need an [api
      key](https://openweathermap.org/appid) (app_id).

      City identifiers can be found in the [city
      list](http://bulk.openweathermap.org/sample/city.list.json.gz).
      Alternately you can [search](https://openweathermap.org/find) by name;
      the `city_id` can be found as the last digits of the URL:
      <https://openweathermap.org/city/2643743>. Language identifiers can be
      found in the [lang list](https://openweathermap.org/current#multi).
      Documentation for condition ID, icon, and main is at [weather
      conditions](https://openweathermap.org/weather-conditions).
    introduced: 
    tags: []
  - name: P4 Runtime
    id: p4runtime
    description: |
      P4 is a language for programming the data plane of network devices, such
      as Programmable Switches or Programmable Network Interface Cards. The
      P4Runtime API is a control plane specification to manage the data plane
      elements of those devices dynamically by a P4 program.

      The `p4runtime` plugin gathers metrics about `Counter` values present in
      P4 Program loaded onto networking device. Metrics are collected through
      gRPC connection with [P4Runtime](https://github.com/p4lang/p4runtime)
      server.

      P4Runtime Plugin uses `PkgInfo.Name` field. If user wants to gather
      information about program name, please follow [6.2.1. Annotating P4 code
      with PkgInfo] instruction and apply changes to your P4 program.
    introduced: 
    tags: []
  - name: Passenger
    id: passenger
    description: |
      Gather [Phusion Passenger](https://www.phusionpassenger.com/) metrics
      using the `passenger-status` command line utility.
    introduced: 
    tags: []
  - name: PF
    id: pf
    description: |
      The pf plugin gathers information from the FreeBSD/OpenBSD pf firewall.
      Currently it can retrieve information about the state table: the number
      of current entries in the table, and counters for the number of searches,
      inserts, and removals to the table.

      The pf plugin retrieves this information by invoking the `pfstat`
      command. The `pfstat` command requires read access to the device file
      `/dev/pf`. You have several options to permit telegraf to run `pfctl`:

      * Run telegraf as root. This is strongly discouraged.
      * Change the ownership and permissions for /dev/pf such that the user
      telegraf runs at can read the /dev/pf device file. This is probably not
      that good of an idea either.
      * Configure sudo to grant telegraf to run `pfctl` as root. This is the
      most restrictive option, but require sudo setup.
      * Add "telegraf" to the "proxy" group as /dev/pf is owned by root:proxy.
    introduced: 
    tags: []
  - name: PgBouncer
    id: pgbouncer
    description: |
      The `pgbouncer` plugin provides metrics for your PgBouncer load balancer.

      More information about the meaning of these metrics can be found in the
      [PgBouncer Documentation](https://pgbouncer.github.io/usage.html).

      - PgBouncer minimum tested version: 1.5
    introduced: 
    tags: []
  - name: PHP-FPM
    id: phpfpm
    description: |
      Get phpfpm stats using either HTTP status page or fpm socket.
    introduced: 
    tags: []
  - name: Ping
    id: ping
    description: |
      Sends a ping message by executing the system ping command and reports the
      results.

      This plugin has two main methods of operation: `exec` and `native`. The
      recommended method is `native`, which has greater system compatibility
      and performance. However, for backwards compatibility the `exec` method
      is the default.

      When using `method = "exec"`, the systems ping utility is executed to
      send the ping packets.

      Most ping command implementations are supported, one notable exception
      being that there is currently no support for GNU Inetutils ping. You may
      instead use the iputils-ping implementation:

      When using `method = "native"` a ping is sent and the results are
      reported in native Go by the Telegraf process, eliminating the need to
      execute the system `ping` command.
    introduced: 
    tags: []
  - name: Postfix
    id: postfix
    description: |
      The postfix plugin reports metrics on the postfix queues.

      For each of the active, hold, incoming, maildrop, and deferred queues
      (<http://www.postfix.org/QSHAPE_README.html#queues>), it will report the
      queue length (number of items), size (bytes used by items), and age (age
      of oldest item in seconds).
    introduced: 
    tags: []
  - name: PostgreSQL
    id: postgresql
    description: |
      The `postgresql` plugin provides metrics for your PostgreSQL Server
      instance. Recorded metrics are lightweight and use Dynamic Management
      Views supplied by PostgreSQL.
    introduced: 
    tags: []
  - name: PostgreSQL Extensible
    id: postgresql_extensible
    description: |
      This postgresql plugin provides metrics for your postgres database. It
      has been designed to parse SQL queries in the plugin section of your
      `telegraf.conf`.

      The example below has two queries are specified, with the following
      parameters:

      * The SQL query itself
      * The minimum PostgreSQL version supported (the numeric display visible in
      pg_settings)
      * A boolean to define if the query has to be run against some specific
      database (defined in the `databases` variable of the plugin section)
      * The name of the measurement
      * A list of the columns to be defined as tags
    introduced: 
    tags: []
  - name: PowerDNS
    id: powerdns
    description: |
      The powerdns plugin gathers metrics about PowerDNS using unix socket.
    introduced: 
    tags: []
  - name: PowerDNS Recursor
    id: powerdns_recursor
    description: |
      The `powerdns_recursor` plugin gathers metrics about PowerDNS Recursor
      using the unix controlsocket.
    introduced: 
    tags: []
  - name: Processes
    id: processes
    description: |
      This plugin gathers info about the total number of processes and groups
      them by status (zombie, sleeping, running, etc.)

      On linux this plugin requires access to procfs (/proc), on other OSes it
      requires access to execute `ps`.

      **Supported Platforms**: Linux, FreeBSD, Darwin
    introduced: 
    tags: []
  - name: Procstat
    id: procstat
    description: |
      The procstat plugin can be used to monitor the system resource usage of
      one or more processes. The procstat_lookup metric displays the query
      information, specifically the number of PIDs returned on a search

      Processes can be selected for monitoring using one of several methods:

      - pidfile
      - exe
      - pattern
      - user
      - systemd_unit
      - cgroup
      - supervisor_unit
      - win_service
    introduced: 
    tags: []
  - name: Prometheus
    id: prometheus
    description: |
      The prometheus input plugin gathers metrics from HTTP servers exposing
      metrics in Prometheus format.
    introduced: 
    tags: []
  - name: Proxmox
    id: proxmox
    description: |
      The proxmox plugin gathers metrics about containers and VMs using the
      Proxmox API.

      Telegraf minimum version: Telegraf 1.16.0
    introduced: 
    tags: []
  - name: PuppetAgent
    id: puppetagent
    description: |
      The puppetagent plugin collects variables outputted from the
      'last_run_summary.yaml' file usually located in `/var/lib/puppet/state/`
      [PuppetAgent
      Runs](https://puppet.com/blog/puppet-monitoring-how-to-monitor-success-or-failure-of-puppet-runs/).
    introduced: 
    tags: []
  - name: RabbitMQ
    id: rabbitmq
    description: |
      Reads metrics from RabbitMQ servers via the [Management
      Plugin](https://www.rabbitmq.com/management.html).

      For additional details reference the [RabbitMQ Management HTTP Stats]().
    introduced: 
    tags: []
  - name: Radius
    id: radius
    description: |
      The Radius plugin collects radius authentication response times.
    introduced: 
    tags: []
  - name: Raindrops
    id: raindrops
    description: |
      The [raindrops](http://raindrops.bogomips.org/) plugin reads from
      specified raindops
      [middleware](http://raindrops.bogomips.org/Raindrops/Middleware.html) URI
      and adds stats to InfluxDB.
    introduced: 
    tags: []
  - name: RAS Daemon
    id: ras
    description: |
      This plugin is only available on Linux (only for `386`, `amd64`, `arm`
      and `arm64` architectures).

      The `RAS` plugin gathers and counts errors provided by
      [RASDaemon](https://github.com/mchehab/rasdaemon).
    introduced: 
    tags: []
  - name: RavenDB
    id: ravendb
    description: |
      Reads metrics from RavenDB servers via monitoring endpoints APIs.

      Requires RavenDB Server 5.2+.
    introduced: 
    tags: []
  - name: Redfish
    id: redfish
    description: |
      The `redfish` plugin gathers metrics and status information about CPU
      temperature, fanspeed, Powersupply, voltage, hostname and Location
      details (datacenter, placement, rack and room) of hardware servers for
      which [DMTF's Redfish](https://redfish.dmtf.org/) is enabled.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Redis
    id: redis
    description: |
      The Redis input plugin gathers metrics from one or many Redis servers.
    introduced: 
    tags: []
  - name: Redis Sentinel
    id: redis_sentinel
    description: |
      A plugin for Redis Sentinel to monitor multiple Sentinel instances that
      are monitoring multiple Redis servers and replicas.
    introduced: 
    tags: []
  - name: RethinkDB
    id: rethinkdb
    description: |
      Collect metrics from [RethinkDB](https://www.rethinkdb.com/).
    introduced: 
    tags: []
  - name: Riak
    id: riak
    description: |
      The Riak plugin gathers metrics from one or more riak instances.
    introduced: 
    tags: []
  - name: Riemann Listener
    id: riemann_listener
    description: |
      The Riemann Listener is a simple input plugin that listens for messages
      from client that use riemann clients using riemann-protobuff format.
    introduced: 
    tags: []
  - name: Siemens S7
    id: s7comm
    description: |
      This plugin reads metrics from Siemens PLCs via the S7 protocol.
    introduced: 
    tags: []
  - name: Salesforce
    id: salesforce
    description: |
      The Salesforce plugin gathers metrics about the limits in your Salesforce
      organization and the remaining usage. It fetches its data from the
      [limits endpoint]() of Salesforce's REST API.
    introduced: 
    tags: []
  - name: LM Sensors
    id: sensors
    description: |
      Collect [lm-sensors](https://en.wikipedia.org/wiki/Lm_sensors) metrics -
      requires the lm-sensors package installed.

      This plugin collects sensor metrics with the `sensors` executable from
      the lm-sensor package.
    introduced: 
    tags: []
  - name: SFlow
    id: sflow
    description: |
      The SFlow Input Plugin provides support for acting as an SFlow V5
      collector in accordance with the specification from
      [sflow.org](https://sflow.org/).

      Currently only Flow Samples of Ethernet / IPv4 & IPv4 TCP & UDP headers
      are turned into metrics. Counters and other header samples are ignored.
    introduced: 
    tags: []
  - name: Slab
    id: slab
    description: |
      This plugin collects details on how much memory each entry in Slab cache
      is consuming. For example, it collects the consumption of `kmalloc-1024`
      and `xfs_inode`. Since this information is obtained by parsing
      `/proc/slabinfo` file, only Linux is supported. The specification of
      `/proc/slabinfo` has not changed since [Linux v2.6.12 (April
      2005)](https://github.com/torvalds/linux/blob/1da177e4/mm/slab.c#L2848-L2861),
      so it can be regarded as sufficiently stable. The memory usage is
      equivalent to the `CACHE_SIZE` column of `slabtop` command. If the
      HOST_PROC environment variable is set, Telegraf will use its value
      instead of `/proc`

      **Note: `/proc/slabinfo` is usually restricted to read as root user. Make
      sure telegraf can execute `sudo` without password.**
    introduced: 
    tags: []
  - name: SLURM
    id: slurm
    description: |
      This plugin gather diag, jobs, nodes, partitions and reservation metrics
      by leveraging SLURM's REST API as provided by the `slurmrestd` daemon.

      This plugin targets the `openapi/v0.0.38` OpenAPI plugin as defined in
      SLURM's documentation. That particular plugin should be configured when
      starting the `slurmrestd` daemon up. For more information, be sure to
      check SLURM's documentation [here](https://slurm.schedmd.com/rest.html).

      A great wealth of information can also be found on the repository of the
      Go module implementing the API client,
      [pcolladosoto/goslurm](https://github.com/pcolladosoto/goslurm).
    introduced: 
    tags: []
  - name: S.M.A.R.T.
    id: smart
    description: |
      Get metrics using the command line utility `smartctl` for S.M.A.R.T.
      (Self-Monitoring, Analysis and Reporting Technology) storage devices.
      SMART is a monitoring system included in computer hard disk drives (HDDs)
      and solid-state drives (SSDs) that detects and reports on various
      indicators of drive reliability, with the intent of enabling the
      anticipation of hardware failures. See smartmontools
      (<https://www.smartmontools.org/>).

      SMART information is separated between different measurements:
      `smart_device` is used for general information, while `smart_attribute`
      stores the detailed attribute information if `attributes = true` is
      enabled in the plugin configuration.

      If no devices are specified, the plugin will scan for SMART devices via
      the following command:

      Metrics will be reported from the following `smartctl` command:

      This plugin supports _smartmontools_ version 5.41 and above, but v. 5.41
      and v. 5.42 might require setting `nocheck`, see the comment in the
      sample configuration. Also, NVMe capabilities were introduced in version
      6.5.

      To enable SMART on a storage device run:
    introduced: 
    tags: []
  - name: smartctl JSON
    id: smartctl
    description: |
      Get metrics using the command line utility `smartctl` for S.M.A.R.T.
      (Self-Monitoring, Analysis and Reporting Technology) storage devices.
      SMART is a monitoring system included in computer hard disk drives
      (HDDs), solid-state drives (SSDs), and nVME drives that detects and
      reports on various indicators of drive reliability, with the intent of
      enabling the anticipation of hardware failures.

      This version of the plugin requires support of the JSON flag from the
      `smartctl` command. This flag was added in 7.0 (2019) and further
      enhanced in subsequent releases.

      See smartmontools (<https://www.smartmontools.org/>) for more
      information.
    introduced: 
    tags: []
  - name: SNMP
    id: snmp
    description: |
      The `snmp` input plugin uses polling to gather metrics from SNMP agents.
      Support for gathering individual OIDs as well as complete SNMP tables is
      included.
    introduced: 
    tags: []
  - name: SNMP Trap
    id: snmp_trap
    description: |
      The SNMP Trap plugin is a service input plugin that receives SNMP
      notifications (traps and inform requests).

      Notifications are received on plain UDP. The port to listen is
      configurable.
    introduced: 
    tags: []
  - name: Socket Listener
    id: socket_listener
    description: |
      The Socket Listener is a service input plugin that listens for messages
      from streaming (tcp, unix) or datagram (udp, unixgram) protocols.

      The plugin expects messages in the Telegraf Input Data Formats.
    introduced: 
    tags: []
  - name: SocketStat
    id: socketstat
    description: |
      The socketstat plugin gathers indicators from established connections,
      using iproute2's `ss` command.

      The `ss` command does not require specific privileges.

      **WARNING: The output format will produce series with very high
      cardinality.** You should either store those by an engine which doesn't
      suffer from it, use a short retention policy or do appropriate filtering.
    introduced: 
    tags: []
  - name: Solr
    id: solr
    description: |
      The [solr](http://lucene.apache.org/solr/) plugin collects stats via the
      [MBean Request Handler]().

      More about [performance
      statistics](https://cwiki.apache.org/confluence/display/solr/Performance+Statistics+Reference).

      Tested from 3.5 to 9.3
    introduced: 
    tags: []
  - name: SQL
    id: sql
    description: |
      This plugin reads metrics from performing SQL queries against a SQL
      server. Different server types are supported and their settings might
      differ (especially the connection parameters). Please check the list of
      supported SQL drivers options.
    introduced: 
    tags: []
  - name: SQL Server
    id: sqlserver
    description: |
      The `sqlserver` plugin provides metrics for your SQL Server instance.
      Recorded metrics are lightweight and use Dynamic Management Views
      supplied by SQL Server.
    introduced: 
    tags: []
  - name: Stackdriver Google Cloud Monitoring
    id: stackdriver
    description: |
      Query data from Google Cloud Monitoring (formerly Stackdriver) using the
      [Cloud Monitoring API v3](https://cloud.google.com/monitoring/api/v3/).

      This plugin accesses APIs which are
      [chargeable](https://cloud.google.com/stackdriver/pricing#stackdriver_monitoring_services);
      you might incur costs.
    introduced: 
    tags: []
  - name: StatsD
    id: statsd
    description: |
      The StatsD input plugin gathers metrics from a Statsd server.
    introduced: 
    tags: []
  - name: Supervisor
    id: supervisor
    description: |
      This plugin gathers information about processes that running under
      supervisor using XML-RPC API.

      Minimum tested version of supervisor: 3.3.2
    introduced: 
    tags: []
  - name: Suricata
    id: suricata
    description: |
      This plugin reports internal performance counters of the Suricata IDS/IPS
      engine, such as captured traffic volume, memory usage, uptime, flow
      counters, and much more. It provides a socket for the Suricata log output
      to write JSON stats output to, and processes the incoming data to fit
      Telegraf's format. It can also report for triggered Suricata IDS/IPS
      alerts.
    introduced: 
    tags: []
  - name: Swap
    id: swap
    description: |
      The swap plugin collects system swap metrics. This plugin ONLY supports
      Linux.

      For more information on what swap memory is, read [All about Linux swap
      space](https://www.linux.com/news/all-about-linux-swap-space).
    introduced: 
    tags: []
  - name: Synproxy
    id: synproxy
    description: |
      The synproxy plugin gathers the synproxy counters. Synproxy is a Linux
      netfilter module used for SYN attack mitigation. The use of synproxy is
      documented in `man iptables-extensions` under the SYNPROXY section.
    introduced: 
    tags: []
  - name: Syslog
    id: syslog
    description: |
      The syslog plugin listens for syslog messages transmitted over a Unix
      Domain socket, [UDP](https://tools.ietf.org/html/rfc5426),
      [TCP](https://tools.ietf.org/html/rfc6587), or
      [TLS](https://tools.ietf.org/html/rfc5425); with or without the octet
      counting framing.

      Syslog messages should be formatted according to [RFC
      5424](https://tools.ietf.org/html/rfc5424) (syslog protocol) or [RFC
      3164](https://tools.ietf.org/html/rfc3164) (BSD syslog protocol).
    introduced: 
    tags: []
  - name: sysstat
    id: sysstat
    description: |
      Collect [sysstat](https://github.com/sysstat/sysstat) metrics - requires
      the sysstat package installed.

      This plugin collects system metrics with the sysstat collector utility
      `sadc` and parses the created binary data file with the `sadf` utility.
    introduced: 
    tags: []
  - name: System
    id: system
    description: |
      The system plugin gathers general stats on system load, uptime, and
      number of users logged in. It is similar to the unix `uptime` command.

      Number of CPUs is obtained from the /proc/cpuinfo file.
    introduced: 
    tags: []
  - name: Systemd-Units
    id: systemd_units
    description: |
      This plugin gathers the status of systemd-units on Linux, using systemd's
      DBus interface.

      Please note: At least systemd v230 is required!
    introduced: 
    tags: []
  - name: Tacacs
    id: tacacs
    description: |
      The Tacacs plugin collects successful tacacs authentication response
      times from tacacs servers such as Aruba ClearPass, FreeRADIUS or tac_plus
      (TACACS+). It is primarily meant to monitor how long it takes for the
      server to fully handle an auth request, including all potential dependent
      calls (for example to AD servers, or other sources of truth for auth the
      tacacs server uses).
    introduced: 
    tags: []
  - name: Tail
    id: tail
    description: |
      The tail plugin "tails" a logfile and parses each log message.

      By default, the tail plugin acts like the following unix tail command:

      - `-F` means that it will follow the _name_ of the given file, so that it
      will be compatible with log-rotated files, and that it will retry on
      inaccessible files.
      - `--lines=0` means that it will start at the end of the file (unless the
      `from_beginning` option is set).

      see <http://man7.org/linux/man-pages/man1/tail.1.html> for more details.

      The plugin expects messages in one of the Telegraf Input Data Formats.
    introduced: 
    tags: []
  - name: Teamspeak 3
    id: teamspeak
    description: |
      This plugin uses the Teamspeak 3 ServerQuery interface of the Teamspeak
      server to collect statistics of one or more virtual servers. If you are
      querying an external Teamspeak server, make sure to add the host which is
      running Telegraf to query_ip_allowlist.txt in the Teamspeak Server
      directory. For information about how to configure the server take a look
      the [Teamspeak 3 ServerQuery Manual]().
    introduced: 
    tags: []
  - name: Temperature
    id: temp
    description: |
      The temp input plugin gather metrics on system temperature. This plugin
      is meant to be multi platform and uses platform specific collection
      methods.

      Currently supports Linux and Windows.
    introduced: 
    tags: []
  - name: Tengine
    id: tengine
    description: |
      The tengine plugin gathers metrics from the [Tengine Web
      Server](http://tengine.taobao.org/) via the
      [reqstat](http://tengine.taobao.org/document/http_reqstat.html) module.
    introduced: 
    tags: []
  - name: Tomcat
    id: tomcat
    description: |
      The Tomcat plugin collects statistics available from the tomcat manager
      status page from the `http://<host>/manager/status/all?XML=true URL.`
      (`XML=true` will return only xml data).

      See the [Tomcat
      documentation](https://tomcat.apache.org/tomcat-9.0-doc/manager-howto.html#Server_Status)
      for details of these statistics.
    introduced: 
    tags: []
  - name: Trig
    id: trig
    description: |
      The `trig` plugin is for demonstration purposes and inserts sine and
      cosine
    introduced: 
    tags: []
  - name: Twemproxy
    id: twemproxy
    description: |
      The `twemproxy` plugin gathers statistics from
      [Twemproxy](https://github.com/twitter/twemproxy) servers.
    introduced: 
    tags: []
  - name: Unbound
    id: unbound
    description: |
      This plugin gathers stats from [Unbound](https://www.unbound.net/) - a
      validating, recursive, and caching DNS resolver.
    introduced: 
    tags: []
  - name: UPSD
    id: upsd
    description: |
      This plugin reads data of one or more Uninterruptible Power Supplies from
      an `upsd` daemon using its NUT network protocol.
    introduced: 
    tags: []
  - name: uWSGI
    id: uwsgi
    description: |
      The uWSGI input plugin gathers metrics about uWSGI using its [Stats
      Server](https://uwsgi-docs.readthedocs.io/en/latest/StatsServer.html).
    introduced: 
    tags: []
  - name: Varnish
    id: varnish
    description: |
      This plugin gathers stats from [Varnish HTTP
      Cache](https://varnish-cache.org/)
    introduced: 
    tags: []
  - name: Hashicorp Vault
    id: vault
    description: |
      The Vault plugin could grab metrics from every Vault agent of the
      cluster. Telegraf may be present in every node and connect to the agent
      locally. In this case should be something like `http://127.0.0.1:8200`.

      > Tested on vault 1.8.5
    introduced: 
    tags: []
  - name: VMware vSphere
    id: vsphere
    description: |
      The VMware vSphere plugin uses the vSphere API to gather metrics from
      multiple vCenter servers.

      * Clusters
      * Hosts
      * Resource Pools
      * VMs
      * Datastores
      * vSAN
    introduced: 
    tags: []
  - name: Webhooks
    id: webhooks
    description: |
      This is a Telegraf service plugin that start a http server and register
      multiple webhook listeners.

      Change the config file to point to the InfluxDB server you are using and
      adjust the settings to match your environment. Once that is complete:
    introduced: 
    tags: []
  - name: Windows Eventlog
    id: win_eventlog
    description: |
      Telegraf's win_eventlog input plugin gathers metrics from the windows
      event log.
    introduced: 
    tags: []
  - name: Windows Performance Counters
    id: win_perf_counters
    description: |
      This document presents the input plugin to read Performance Counters on
      Windows operating systems.

      The configuration is parsed and then tested for validity, such as whether
      the Object, Instance and Counter exist on Telegraf startup.

      Counter paths are refreshed periodically, see the CountersRefreshInterval
      configuration parameter for more info.

      In case of query for all instances `["*"]`, the plugin does not return
      the instance `_Total` by default. See IncludeTotal for more info.
    introduced: 
    tags: []
  - name: Windows Services
    id: win_services
    description: |
      Reports information about Windows service status.

      Monitoring some services may require running Telegraf with administrator
      privileges.
    introduced: 
    tags: []
  - name: Windows Management Instrumentation
    id: win_wmi
    description: |
      This document presents the input plugin to read WMI classes on Windows
      operating systems. With the win_wmi plugin, it is possible to capture and
      filter virtually any configuration or metric value exposed through the
      Windows Management Instrumentation
      ([WMI](https://learn.microsoft.com/en-us/windows/win32/wmisdk/wmi-start-page))
      service. At minimum, the telegraf service user must have permission to
      [read](https://learn.microsoft.com/en-us/windows/win32/wmisdk/access-to-wmi-namespaces)
      the WMI namespace that is being queried.
    introduced: 
    tags: []
  - name: Wireguard
    id: wireguard
    description: |
      The Wireguard input plugin collects statistics on the local Wireguard
      server using the [`wgctrl`](https://github.com/WireGuard/wgctrl-go)
      library. It reports gauge metrics for Wireguard interface device(s) and
      its peers.
    introduced: 
    tags: []
  - name: Wireless
    id: wireless
    description: |
      The wireless plugin gathers metrics about wireless link quality by
      reading the `/proc/net/wireless` file. This plugin currently supports
      linux only.
    introduced: 
    tags: []
  - name: x509 Certificate
    id: x509_cert
    description: |
      This plugin provides information about X509 certificate accessible via
      local file, tcp, udp, https or smtp protocol.

      When using a UDP address as a certificate source, the server must support
      [DTLS](https://en.wikipedia.org/wiki/Datagram_Transport_Layer_Security).
    introduced: 
    tags: []
  - name: XtremIO
    id: xtremio
    description: |
      The `xtremio` plugin gathers metrics from a Dell EMC XtremIO Storage
      Array's V3 Rest API. Documentation can be found
      [here](https://dl.dell.com/content/docu96624_xtremio-storage-array-x1-and-x2-cluster-types-with-xms-6-3-0-to-6-3-3-and-xios-4-0-15-to-4-0-31-and-6-0-0-to-6-3-3-restful-api-3-x-guide.pdf?language=en_us).
    introduced: 
    tags: []
  - name: ZFS
    id: zfs
    description: |
      This ZFS plugin provides metrics from your ZFS filesystems. It supports
      ZFS on Linux and FreeBSD. It gets ZFS stat from `/proc/spl/kstat/zfs` on
      Linux and from `sysctl`, 'zfs' and `zpool` on FreeBSD.
    introduced: 
    tags: []
  - name: Zipkin
    id: zipkin
    description: |
      This plugin implements the Zipkin http server to gather trace and timing
      data needed to troubleshoot latency problems in microservice
      architectures.

      __Please Note:__ This plugin is experimental; Its data schema may be
      subject to change based on its main usage cases and the evolution of the
      OpenTracing standard.
    introduced: 
    tags: []
  - name: Zookeeper
    id: zookeeper
    description: |
      The zookeeper plugin collects variables outputted from the 'mntr' command
      [Zookeeper
      Admin](https://zookeeper.apache.org/doc/current/zookeeperAdmin.html).

      If in Zookeper, the Prometheus Metric provider is enabled, instead use
      the `prometheus` input plugin. By default, the Prometheus metrics are
      exposed at `http://<ip>:7000/metrics` URL. Using the `prometheus` input
      plugin provides a native solution to read and process Prometheus metrics,
      while this plugin is specific to using `mntr` to collect the Java
      Properties format.
    introduced: 
    tags: []
  - name: Cisco GNMI Telemetry
    id: cisco_telemetry_gnmi
    description: |
      Cisco GNMI Telemetry input plugin consumes telemetry data similar to the
      GNMI specification. This GRPC-based protocol can utilize TLS for
      authentication and encryption. This plugin has been developed to support
      GNMI telemetry as produced by Cisco IOS XR (64-bit) version 6.5.1 and
      later.

      > [!NOTE]
      > The `inputs.cisco_telemetry_gnmi` plugin was renamed to [`gmni`]() in
      > v1.15.0 to better reflect its general support for gNMI devices.
    introduced: v1.11.0
    deprecated: v1.15.0
    removal: v1.35.0
    tags: [networking, freebsd, linux, macos, windows]
  - name: HTTP Listener
    id: http_listener
    description: |
      This service input plugin that listens for requests sent according to the
      [InfluxDB HTTP
      API](https://docs.influxdata.com/influxdb/v1.8/guides/write_data/). The
      intent of the plugin is to allow Telegraf to serve as a proxy/router for
      the `/write` endpoint of the InfluxDB HTTP API.

      > [!NOTE]
      > This plugin was renamed to [`influxdb_listener`]() in v1.9 and is
      > deprecated since then. If you wish to receive general metrics via HTTP
      > it is recommended to use the [`http_listener_v2`]() plugin instead.
    introduced: v1.30.0
    deprecated: v1.9.0
    removal: v1.35.0
    tags: [servers, web, freebsd, linux, macos, windows]
output:
  - name: Amon
    id: amon
    description: |
      This plugin writes to [Amon](https://www.amon.cx) and requires an
      `serverkey` and `amoninstance` URL which can be obtained
      [here](https://www.amon.cx/docs/monitoring/) for the account.

      If the point value being sent cannot be converted to a float64, the
      metric is skipped.

      Metrics are grouped by converting any `_` characters to `.` in the Point
      Name.
    introduced: 
    tags: []
  - name: AMQP
    id: amqp
    description: |
      This plugin writes to a AMQP 0-9-1 Exchange, a prominent implementation
      of this protocol being [RabbitMQ](https://www.rabbitmq.com/).

      This plugin does not bind the exchange to a queue.

      For an introduction to AMQP see:

      - [amqp: concepts](https://www.rabbitmq.com/tutorials/amqp-concepts.html)
      - [rabbitmq: getting started](https://www.rabbitmq.com/getstarted.html)
    introduced: 
    tags: []
  - name: Application Insights
    id: application_insights
    description: |
      This plugin writes telegraf metrics to [Azure Application
      Insights](https://azure.microsoft.com/en-us/services/application-insights/).
    introduced: 
    tags: []
  - name: Azure Data Explorer
    id: azure_data_explorer
    description: |
      Azure Data Explorer is a distributed, columnar store, purpose built for
      any type of logs, metrics and time series data.

      This plugin writes data collected by any of the Telegraf input plugins to
      [Azure Data
      Explorer](https://docs.microsoft.com/en-us/azure/data-explorer), [Azure
      Synapse Data
      Explorer](https://docs.microsoft.com/en-us/azure/synapse-analytics/data-explorer/data-explorer-overview),
      and [Real time analytics in
      Fabric](https://learn.microsoft.com/en-us/fabric/real-time-analytics/overview).
    introduced: 
    tags: []
  - name: Azure Monitor
    id: azure_monitor
    description: |
      **The Azure Monitor custom metrics service is currently in preview and
      not available in a subset of Azure regions.**

      This plugin will send custom metrics to Azure Monitor. Azure Monitor has
      a metric resolution of one minute. To handle this in Telegraf, the Azure
      Monitor output plugin will automatically aggregates metrics into one
      minute buckets, which are then sent to Azure Monitor on every flush
      interval.

      The metrics from each input plugin will be written to a separate Azure
      Monitor namespace, prefixed with `Telegraf/` by default. The field name
      for each metric is written as the Azure Monitor metric name. All field
      values are written as a summarized set that includes: min, max, sum,
      count. Tags are written as a dimension on each Azure Monitor metric.
    introduced: 
    tags: []
  - name: Google BigQuery
    id: bigquery
    description: |
      This plugin writes to the [Google Cloud
      BigQuery](https://cloud.google.com/bigquery) and requires
      [authentication](https://cloud.google.com/bigquery/docs/authentication)
      with Google Cloud using either a service account or user credentials.

      Be aware that this plugin accesses APIs that are
      [chargeable](https://cloud.google.com/bigquery/pricing) and might incur
      costs.
    introduced: 
    tags: []
  - name: Clarify
    id: clarify
    description: |
      This plugin writes to [Clarify](https://clarify.io). To use this plugin
      you will need to obtain a set of
      [credentials](https://docs.clarify.io/users/admin/integrations/credentials).
    introduced: 
    tags: []
  - name: Google Cloud PubSub
    id: cloud_pubsub
    description: |
      The GCP PubSub plugin publishes metrics to a [Google Cloud
      PubSub](https://cloud.google.com/pubsub) topic as one of the supported
      [output data formats](/telegraf/v1/data_formats/output).
    introduced: 
    tags: []
  - name: Amazon CloudWatch
    id: cloudwatch
    description: |
      This plugin will send metrics to Amazon CloudWatch.
    introduced: 
    tags: []
  - name: Amazon CloudWatch Logs
    id: cloudwatch_logs
    description: |
      This plugin will send logs to Amazon CloudWatch.
    introduced: 
    tags: []
  - name: CrateDB
    id: cratedb
    description: |
      This plugin writes to [CrateDB](https://crate.io/) via its [PostgreSQL
      protocol](https://crate.io/docs/crate/reference/protocols/postgres.html).
    introduced: 
    tags: []
  - name: Datadog
    id: datadog
    description: |
      This plugin writes to the [Datadog Metrics
      API](https://docs.datadoghq.com/api/v1/metrics/#submit-metrics) and
      requires an `apikey` which can be obtained
      [here](https://app.datadoghq.com/account/settings#api) for the account.
      This plugin supports the v1 API.
    introduced: 
    tags: []
  - name: discard
    id: discard
    description: |
      This output plugin simply drops all metrics that are sent to it. It is
      only meant to be used for testing purposes.
    introduced: 
    tags: []
  - name: Dynatrace
    id: dynatrace
    description: |
      This plugin sends Telegraf metrics to
      [Dynatrace](https://www.dynatrace.com) via the [Dynatrace Metrics API
      V2](https://docs.dynatrace.com/docs/shortlink/api-metrics-v2). It may be
      run alongside the Dynatrace OneAgent for automatic authentication or it
      may be run standalone on a host without a OneAgent by specifying a URL
      and API Token. More information on the plugin can be found in the
      [Dynatrace
      documentation](https://docs.dynatrace.com/docs/shortlink/api-metrics-v2-post-datapoints).
      All metrics are reported as gauges, unless they are specified to be delta
      counters using the `additional_counters` or
      `additional_counters_patterns` config option (see below). See the
      [Dynatrace Metrics ingestion protocol
      documentation](https://docs.dynatrace.com/docs/shortlink/metric-ingestion-protocol)
      for details on the types defined there.
    introduced: 
    tags: []
  - name: Elasticsearch
    id: elasticsearch
    description: |
      This plugin writes to [Elasticsearch](https://www.elastic.co) via HTTP
      using Elastic (<http://olivere.github.io/elastic/).>

      It supports Elasticsearch releases from 5.x up to 7.x.
    introduced: 
    tags: []
  - name: Azure Event Hubs
    id: event_hubs
    description: |
      This plugin for [Azure Event
      Hubs](https://azure.microsoft.com/en-gb/services/event-hubs/) will send
      metrics to a single Event Hub within an Event Hubs namespace. Metrics are
      sent as message batches, each message payload containing one metric
      object. The messages do not specify a partition key, and will thus be
      automatically load-balanced (round-robin) across all the Event Hub
      partitions.
    introduced: 
    tags: []
  - name: Exec
    id: exec
    description: |
      This plugin sends telegraf metrics to an external application over stdin.

      The command should be defined similar to docker's `exec` form:

      On non-zero exit stderr will be logged at error level.

      For better performance, consider execd, which runs continuously.
    introduced: 
    tags: []
  - name: Execd
    id: execd
    description: |
      The `execd` plugin runs an external program as a daemon.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: File
    id: file
    description: |
      This plugin writes telegraf metrics to files
    introduced: 
    tags: []
  - name: Graphite
    id: graphite
    description: |
      This plugin writes to
      [Graphite](http://graphite.readthedocs.org/en/latest/index.html) via raw
      TCP.

      For details on the translation between Telegraf Metrics and Graphite
      output, see the [Graphite Data Format](/telegraf/v1/data_formats/output).
    introduced: 
    tags: []
  - name: Graylog
    id: graylog
    description: |
      This plugin writes to a Graylog instance using the
      "[GELF](https://docs.graylog.org/en/3.1/pages/gelf.html#gelf-payload-specification)"
      format.
    introduced: 
    tags: []
  - name: GroundWork
    id: groundwork
    description: |
      This plugin writes to a [GroundWork
      Monitor](https://www.gwos.com/product/groundwork-monitor/) instance.
      Plugin only supports GW8+
    introduced: 
    tags: []
  - name: Health
    id: health
    description: |
      The health plugin provides a HTTP health check resource that can be
      configured to return a failure status code based on the value of a
      metric.

      When the plugin is healthy it will return a 200 response; when unhealthy
      it will return a 503 response. The default state is healthy, one or more
      checks must fail in order for the resource to enter the failed state.
    introduced: 
    tags: []
  - name: HTTP
    id: http
    description: |
      This plugin sends metrics in a HTTP message encoded using one of the
      output data formats. For data_formats that support batching, metrics are
      sent in batch format by default.
    introduced: 
    tags: []
  - name: InfluxDB v1.x
    id: influxdb
    description: |
      The InfluxDB output plugin writes metrics to the [InfluxDB v1.x] HTTP or
      UDP service.
    introduced: 
    tags: []
  - name: InfluxDB v2.x
    id: influxdb_v2
    description: |
      The InfluxDB output plugin writes metrics to the [InfluxDB v2.x] HTTP
      service.
    introduced: 
    tags: []
  - name: Instrumental
    id: instrumental
    description: |
      This plugin writes to the [Instrumental Collector
      API](https://instrumentalapp.com/docs/tcp-collector) and requires a
      Project-specific API token.

      Instrumental accepts stats in a format very close to Graphite, with the
      only difference being that the type of stat (gauge, increment) is the
      first token, separated from the metric itself by whitespace. The
      `increment` type is only used if the metric comes in as a counter through
      `[[input.statsd]]`.
    introduced: 
    tags: []
  - name: IoTDB
    id: iotdb
    description: |
      This output plugin saves Telegraf metrics to an Apache IoTDB backend,
      supporting session connection and data insertion.
    introduced: 
    tags: []
  - name: Kafka
    id: kafka
    description: |
      This plugin writes to a [Kafka
      Broker](http://kafka.apache.org/07/quickstart.html) acting a Kafka
      Producer.
    introduced: 
    tags: []
  - name: Amazon Kinesis
    id: kinesis
    description: |
      This is an experimental plugin that is still in the early stages of
      development. It will batch up all of the Points in one Put request to
      Kinesis. This should save the number of API requests by a considerable
      level.
    introduced: 
    tags: []
  - name: Librato
    id: librato
    description: |
      This plugin writes to the [Librato Metrics
      API](http://dev.librato.com/v1/metrics#metrics) and requires an
      `api_user` and `api_token` which can be obtained
      [here](https://metrics.librato.com/account/api_tokens) for the account.

      The `source_tag` option in the Configuration file is used to send
      contextual information from Point Tags to the API.

      If the point value being sent cannot be converted to a float64, the
      metric is skipped.

      Currently, the plugin does not send any associated Point Tags.
    introduced: 
    tags: []
  - name: Logz.io
    id: logzio
    description: |
      This plugin sends metrics to Logz.io over HTTPs.
    introduced: 
    tags: []
  - name: Loki
    id: loki
    description: |
      This plugin sends logs to Loki, using metric name and tags as labels, log
      line will content all fields in `key="value"` format which is easily
      parsable with `logfmt` parser in Loki.

      Logs within each stream are sorted by timestamp before being sent to
      Loki.
    introduced: 
    tags: []
  - name: MongoDB
    id: mongodb
    description: |
      This plugin sends metrics to MongoDB and automatically creates the
      collections as time series collections when they don't already exist.
      **Please note:** Requires MongoDB 5.0+ for Time Series Collections
    introduced: 
    tags: []
  - name: MQTT Producer
    id: mqtt
    description: |
      This plugin writes to a [MQTT Broker](http://http://mqtt.org/) acting as
      a mqtt Producer. It supports MQTT protocols `3.1.1` and `5`.
    introduced: 
    tags: []
  - name: NATS
    id: nats
    description: |
      This plugin writes to a (list of) specified NATS instance(s).
    introduced: 
    tags: []
  - name: Nebius Cloud Monitoring
    id: nebius_cloud_monitoring
    description: |
      This plugin will send custom metrics to [Nebuis Cloud
      Monitoring](https://nebius.com/il/services/monitoring).
    introduced: 
    tags: []
  - name: New Relic
    id: newrelic
    description: |
      This plugins writes to New Relic Insights using the [Metrics
      API](https://docs.newrelic.com/docs/data-ingest-apis/get-data-new-relic/metric-api/introduction-metric-api).

      To use this plugin you must first obtain an [Insights API
      Key](https://docs.newrelic.com/docs/apis/get-started/intro-apis/types-new-relic-api-keys#user-api-key).

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: NSQ
    id: nsq
    description: |
      This plugin writes to a specified NSQD instance, usually local to the
      producer. It requires a `server` name and a `topic` name.
    introduced: 
    tags: []
  - name: OpenSearch
    id: opensearch
    description: |
      This plugin writes to [OpenSearch](https://opensearch.org/) via HTTP

      It supports OpenSearch releases from 1 and 2. Future comparability with
      1.x is not guaranteed and instead will focus on 2.x support. Consider
      using the existing Elasticsearch plugin for 1.x.
    introduced: 
    tags: []
  - name: OpenTelemetry
    id: opentelemetry
    description: |
      This plugin sends metrics to [OpenTelemetry](https://opentelemetry.io)
      servers and agents via gRPC.
    introduced: 
    tags: []
  - name: OpenTSDB
    id: opentsdb
    description: |
      This plugin writes to an OpenTSDB instance using either the "telnet" or
      Http mode.

      Using the Http API is the recommended way of writing metrics since
      OpenTSDB 2.0 To use Http mode, set useHttp to true in config. You can
      also control how many metrics is sent in each http request by setting
      batchSize in config.

      See [the docs](http://opentsdb.net/docs/build/html/api_http/put.html) for
      details.
    introduced: 
    tags: []
  - name: Parquet
    id: parquet
    description: |
      This plugin writes metrics to parquet files. By default, the parquet
      output groups metrics by metric name and write those metrics all to the
      same file. If a metric schema does not match then metrics are dropped.

      To lean more about Parquet check out the [Parquet
      docs](https://parquet.apache.org/docs/) as well as a blog post on
      [Querying
      Parquet](https://www.influxdata.com/blog/querying-parquet-millisecond-latency/).
    introduced: 
    tags: []
  - name: PostgreSQL
    id: postgresql
    description: |
      This output plugin writes metrics to PostgreSQL (or compatible database).
      The plugin manages the schema, automatically updating missing columns.
    introduced: 
    tags: []
  - name: Prometheus
    id: prometheus_client
    description: |
      This plugin starts a [Prometheus](https://prometheus.io/) Client, it
      exposes all metrics on `/metrics` (default) to be polled by a Prometheus
      server.
    introduced: 
    tags: []
  - name: RedisTimeSeries Producer
    id: redistimeseries
    description: |
      The RedisTimeSeries output plugin writes metrics to the RedisTimeSeries
      server.
    introduced: 
    tags: []
  - name: Remote File
    id: remotefile
    description: |
      This plugin writes telegraf metrics to files in remote locations using
      the [rclone library](https://rclone.org). Currently the following
      backends are supported:

      - `local`: [Local filesystem](https://rclone.org/local/)
      - `s3`: [Amazon S3 storage providers](https://rclone.org/s3/)
      - `sftp`: [Secure File Transfer Protocol](https://rclone.org/sftp/)
    introduced: 
    tags: []
  - name: Riemann
    id: riemann
    description: |
      This plugin writes to [Riemann](http://riemann.io/) via TCP or UDP.
    introduced: 
    tags: []
  - name: Sensu Go
    id: sensu
    description: |
      This plugin writes metrics events to [Sensu Go](https://sensu.io) via its
      HTTP events API.
    introduced: 
    tags: []
  - name: SignalFx
    id: signalfx
    description: |
      The SignalFx output plugin sends metrics to
      [SignalFx](https://docs.signalfx.com/en/latest/).
    introduced: 
    tags: []
  - name: Socket Writer
    id: socket_writer
    description: |
      The socket writer plugin can write to a UDP, TCP, or unix socket.

      It can output data in any of the [supported output
      formats](/telegraf/v1/data_formats/output).
    introduced: 
    tags: []
  - name: SQL
    id: sql
    description: |
      The SQL output plugin saves Telegraf metric data to an SQL database.

      The plugin uses a simple, hard-coded database schema. There is a table
      for each metric type and the table name is the metric name. There is a
      column per field and a column per tag. There is an optional column for
      the metric timestamp.

      A row is written for every input metric. This means multiple metrics are
      never merged into a single row, even if they have the same metric name,
      tags, and timestamp.

      The plugin uses Golang's generic "database/sql" interface and third party
      drivers. See the driver-specific section below for a list of supported
      drivers and details. Additional drivers may be added in future Telegraf
      releases.
    introduced: 
    tags: []
  - name: Stackdriver Google Cloud Monitoring
    id: stackdriver
    description: |
      This plugin writes to the [Google Cloud Monitoring
      API](https://cloud.google.com/monitoring/api/v3/) (formerly Stackdriver)
      and requires
      [authentication](https://cloud.google.com/docs/authentication/getting-started)
      with Google Cloud using either a service account or user credentials

      This plugin accesses APIs which are
      [chargeable](https://cloud.google.com/stackdriver/pricing#google-clouds-operations-suite-pricing);
      you might incur costs.

      Requires `project` to specify where Stackdriver metrics will be delivered
      to.

      By default, Metrics are grouped by the `namespace` variable and metric
      key - eg: `custom.googleapis.com/telegraf/system/load5`. However, this is
      not the best practice. Setting `metric_name_format = "official"` will
      produce a more easily queried format of:
      `metric_type_prefix/[namespace_]name_key/kind`. If the global namespace
      is not set, it is omitted as well.

      [Resource type](https://cloud.google.com/monitoring/api/resources) is
      configured by the `resource_type` variable (default `global`).

      Additional resource labels can be configured by `resource_labels`. By
      default the required `project_id` label is always set to the `project`
      variable.
    introduced: 
    tags: []
  - name: STOMP Producer
    id: stomp
    description: |
      This plugin writes to a [Active MQ Broker](http://activemq.apache.org/)
      for STOMP <http://stomp.github.io>.

      It also support Amazon MQ <https://aws.amazon.com/amazon-mq/>
    introduced: 
    tags: []
  - name: Sumo Logic
    id: sumologic
    description: |
      This plugin sends metrics to [Sumo Logic HTTP
      Source](https://help.sumologic.com/03Send-Data/Sources/02Sources-for-Hosted-Collectors/HTTP-Source/Upload-Metrics-to-an-HTTP-Source)
      in HTTP messages, encoded using one of the output data formats.

      Telegraf minimum version: Telegraf 1.16.0

      Currently metrics can be sent using one of the following data formats,
      supported by Sumologic HTTP Source:

      * `graphite` - for Content-Type of `application/vnd.sumologic.graphite`
      * `carbon2` - for Content-Type of `application/vnd.sumologic.carbon2`
      * `prometheus` - for Content-Type of
      `application/vnd.sumologic.prometheus`
    introduced: 
    tags: []
  - name: Syslog
    id: syslog
    description: |
      The syslog output plugin sends syslog messages transmitted over
      [UDP](https://tools.ietf.org/html/rfc5426) or
      [TCP](https://tools.ietf.org/html/rfc6587) or
      [TLS](https://tools.ietf.org/html/rfc5425), with or without the octet
      counting framing.

      Syslog messages are formatted according to [RFC
      5424](https://tools.ietf.org/html/rfc5424). Per this RFC there are
      limitations to the field sizes when sending messages. See the [Syslog
      Message Format](https://datatracker.ietf.org/doc/html/rfc5424#section-6)
      section of the RFC. Sending messages beyond these sizes may get dropped
      by a strict receiver silently.
    introduced: 
    tags: []
  - name: Timestream
    id: timestream
    description: |
      The Timestream output plugin writes metrics to the [Amazon Timestream]
      service.
    introduced: 
    tags: []
  - name: Warp10
    id: warp10
    description: |
      The `warp10` output plugin writes metrics to [Warp
      10](https://www.warp10.io).
    introduced: 
    tags: []
  - name: Wavefront
    id: wavefront
    description: |
      This plugin writes to a [Wavefront](https://www.wavefront.com) instance
      or a Wavefront Proxy instance over HTTP or HTTPS.
    introduced: 
    tags: []
  - name: Websocket
    id: websocket
    description: |
      This plugin can write to a WebSocket endpoint.

      It can output data in any of the [supported output
      formats](/telegraf/v1/data_formats/output).
    introduced: 
    tags: []
  - name: Yandex Cloud Monitoring
    id: yandex_cloud_monitoring
    description: |
      This plugin will send custom metrics to [Yandex Cloud
      Monitoring](https://cloud.yandex.com/services/monitoring).
    introduced: 
    tags: []
  - name: Zabbix
    id: zabbix
    description: |
      This plugin send metrics to [Zabbix](https://www.zabbix.com/) via
      [traps](https://www.zabbix.com/documentation/current/en/manual/appendix/items/trapper).

      It has been tested with versions
      [3.0](https://www.zabbix.com/documentation/3.0/en/manual/appendix/items/trapper)
      ,
      [4.0](https://www.zabbix.com/documentation/4.0/en/manual/appendix/items/trapper)
      and
      [6.0](https://www.zabbix.com/documentation/6.0/en/manual/appendix/items/trapper)
      .

      It should work with newer versions as long as Zabbix does not change the
      protocol.
    introduced: 
    tags: []
aggregator:
  - name: BasicStats
    id: basicstats
    description: |
      The BasicStats aggregator plugin gives count, diff, max, min, mean,
      non_negative_diff, sum, s2(variance), stdev for a set of values, emitting
      the aggregate every `period` seconds.
    introduced: 
    tags: []
  - name: Derivative
    id: derivative
    description: |
      The Derivative Aggregator Plugin estimates the derivative for all fields
      of the aggregated metrics.
    introduced: 
    tags: []
  - name: Final
    id: final
    description: |
      The final aggregator emits the last metric of a contiguous series. A
      contiguous series is defined as a series which receives updates within
      the time period in `series_timeout`. The contiguous series may be longer
      than the time interval defined by `period`.

      This is useful for getting the final value for data sources that produce
      discrete time series such as procstat, cgroup, kubernetes etc.

      When a series has not been updated within the time defined in
      `series_timeout`, the last metric is emitted with the `_final` appended.
    introduced: 
    tags: []
  - name: Histogram
    id: histogram
    description: |
      The histogram aggregator plugin creates histograms containing the counts
      of field values within a range.

      If `cumulative` is set to true, values added to a bucket are also added
      to the larger buckets in the distribution. This creates a [cumulative
      histogram](https://en.wikipedia.org/wiki/Histogram#/media/File:Cumulative_vs_normal_histogram.svg).
      Otherwise, values are added to only one bucket, which creates an
      [ordinary histogram]()

      Like other Telegraf aggregators, the metric is emitted every `period`
      seconds. By default bucket counts are not reset between periods and will
      be non-strictly increasing while Telegraf is running. This behavior can
      be changed by setting the `reset` parameter to true.
    introduced: 
    tags: []
  - name: Merge
    id: merge
    description: |
      Merge metrics together into a metric with multiple fields into the most
      memory and network transfer efficient form.

      Use this plugin when fields are split over multiple metrics, with the
      same measurement, tag set and timestamp. By merging into a single metric
      they can be handled more efficiently by the output.
    introduced: 
    tags: []
  - name: MinMax
    id: minmax
    description: |
      The minmax aggregator plugin aggregates min & max values of each field it
      sees, emitting the aggrate every `period` seconds.
    introduced: 
    tags: []
  - name: Quantile
    id: quantile
    description: |
      The quantile aggregator plugin aggregates specified quantiles for each
      numeric field per metric it sees and emits the quantiles every `period`.
    introduced: 
    tags: []
  - name: Starlark
    id: starlark
    description: |
      The `starlark` aggregator allows to implement a custom aggregator plugin
      with a Starlark script. The Starlark script needs to be composed of the
      three methods defined in the Aggregator plugin interface which are `add`,
      `push` and `reset`.

      The Starlark Aggregator plugin calls the Starlark function `add` to add
      the metrics to the aggregator, then calls the Starlark function `push` to
      push the resulting metrics into the accumulator and finally calls the
      Starlark function `reset` to reset the entire state of the plugin.

      The Starlark functions can use the global function `state` to keep
      temporary the metrics to aggregate.

      The Starlark language is a dialect of Python, and will be familiar to
      those who have experience with the Python language. However, there are
      major differences. Existing Python code is unlikely to work unmodified.
      The execution environment is sandboxed, and it is not possible to do I/O
      operations such as reading from files or sockets.

      The **[Starlark
      specification](https://github.com/google/starlark-go/blob/d1966c6b9fcd/doc/spec.md)**
      has details about the syntax and available functions.
    introduced: 
    tags: []
  - name: ValueCounter
    id: valuecounter
    description: |
      The valuecounter plugin counts the occurrence of values in fields and
      emits the counter once every 'period' seconds.

      A use case for the valuecounter plugin is when you are processing a HTTP
      access log (with the logparser input) and want to count the HTTP status
      codes.

      The fields which will be counted must be configured with the `fields`
      configuration directive. When no `fields` is provided the plugin will not
      count any fields. The results are emitted in fields in the format:
      `originalfieldname_fieldvalue = count`.

      Counting fields with a high number of potential values may produce
      significant amounts of new fields and memory usage, take care to only
      count fields with a limited set of values.
    introduced: 
    tags: []
processor:
  - name: AWS EC2 Metadata
    id: aws_ec2
    description: |
      AWS EC2 Metadata processor plugin appends metadata gathered from [AWS
      IMDS](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html)
      to metrics associated with EC2 instances.
    introduced: 
    tags: []
  - name: Clone
    id: clone
    description: |
      The clone processor plugin create a copy of each metric passing through
      it, preserving untouched the original metric and allowing modifications
      in the copied one.

      The modifications allowed are the ones supported by input plugins and
      aggregators:

      * name_override
      * name_prefix
      * name_suffix
      * tags

      Select the metrics to modify using the standard metric filtering.
    introduced: 
    tags: []
  - name: Converter
    id: converter
    description: |
      The converter processor is used to change the type of tag or field
      values. In addition to changing field types it can convert between fields
      and tags.

      Values that cannot be converted are dropped.

      **Note:** When converting tags to fields, take care to ensure the series
      is still uniquely identifiable. Fields with the same series key
      (measurement + tags) will overwrite one another.

      **Note on large strings being converted to numeric types:** When
      converting a string value to a numeric type, precision may be lost if the
      number is too large. The largest numeric type this plugin supports is
      `float64`, and if a string 'number' exceeds its size limit, accuracy may
      be lost.

      **Note on multiple measurement or timestamps:** Users can provide
      multiple tags or fields to use as the measurement name or timestamp.
      However, note that the order in the array is not guaranteed!
    introduced: 
    tags: []
  - name: Date
    id: date
    description: |
      Use the `date` processor to add the metric timestamp as a human readable
      tag.

      A common use is to add a tag that can be used to group by month or year.

      A few example usecases include:

      1) consumption data for utilities on per month basis
      1) bandwidth capacity per month
      1) compare energy production or sales on a yearly or monthly basis
    introduced: 
    tags: []
  - name: Dedup
    id: dedup
    description: |
      Filter metrics whose field values are exact repetitions of the previous
      values. This plugin will store its state between runs if the `statefile`
      option in the agent config section is set.
    introduced: 
    tags: []
  - name: Defaults
    id: defaults
    description: |
      The _Defaults_ processor allows you to ensure certain fields will always
      exist with a specified default value on your metric(s).

      There are three cases where this processor will insert a configured
      default field.

      1. The field is nil on the incoming metric
      1. The field is not nil, but its value is an empty string.
      1. The field is not nil, but its value is a string of one or more empty
      spaces.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Enum
    id: enum
    description: |
      The Enum Processor allows the configuration of value mappings for metric
      tags or fields. The main use-case for this is to rewrite status codes
      such as _red_, _amber_ and _green_ by numeric values such as 0, 1, 2. The
      plugin supports string, int, float64 and bool types for the field values.
      Multiple tags or fields can be configured with separate value mappings
      for each. Default mapping values can be configured to be used for all
      values, which are not contained in the value_mappings. The processor
      supports explicit configuration of a destination tag or field. By default
      the source tag or field is overwritten.
    introduced: 
    tags: []
  - name: Execd
    id: execd
    description: |
      The `execd` processor plugin runs an external program as a separate
      process and pipes metrics in to the process's STDIN and reads processed
      metrics from its STDOUT. The programs must accept influx line protocol on
      standard in (STDIN) and output metrics in influx line protocol to
      standard output (STDOUT).

      Program output on standard error is mirrored to the telegraf log.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Filepath
    id: filepath
    description: |
      The `filepath` processor plugin maps certain go functions from
      [path/filepath](https://golang.org/pkg/path/filepath/) onto tag and field
      values. Values can be modified in place or stored in another key.

      Implemented functions are:

      * [Base](https://golang.org/pkg/path/filepath/#Base) (accessible through
      `[[processors.filepath.basename]]`)
      * [Rel](https://golang.org/pkg/path/filepath/#Rel) (accessible through
      `[[processors.filepath.rel]]`)
      * [Dir](https://golang.org/pkg/path/filepath/#Dir) (accessible through
      `[[processors.filepath.dir]]`)
      * [Clean](https://golang.org/pkg/path/filepath/#Clean) (accessible through
      `[[processors.filepath.clean]]`)
      * [ToSlash](https://golang.org/pkg/path/filepath/#ToSlash) (accessible
      through `[[processors.filepath.toslash]]`)

      On top of that, the plugin provides an extra function to retrieve the
      final path component without its extension. This function is accessible
      through the `[[processors.filepath.stem]]` configuration item.

      Please note that, in this implementation, these functions are processed
      in the order that they appear above( except for `stem` that is applied in
      the first place).

      Specify the `tag` and/or `field` that you want processed in each section
      and optionally a `dest` if you want the result stored in a new tag or
      field.

      If you plan to apply multiple transformations to the same `tag`/`field`,
      bear in mind the processing order stated above.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Filter
    id: filter
    description: |
      The filter processor plugin allows to specify a set of rules for metrics
      with the ability to _keep_ or _drop_ those metrics. It does _not_ change
      the metric. As such a user might want to apply this processor to remove
      metrics from the processing/output stream. __NOTE:__ The filtering is
      _not_ output specific, but will apply to the metrics processed by this
      processor.
    introduced: 
    tags: []
  - name: Network Interface Name
    id: ifname
    description: |
      The `ifname` plugin looks up network interface names using SNMP.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Lookup
    id: lookup
    description: |
      The Lookup Processor allows to use one or more files containing a
      lookup-table for annotating incoming metrics. The lookup is _static_ as
      the files are only used on startup. The main use-case for this is to
      annotate metrics with additional tags e.g. dependent on their source.
      Multiple tags can be added depending on the lookup-table _files_.

      The lookup key can be generated using a Golang template with the ability
      to access the metric name via `{{.Name}}`, the tag values via `{{.Tag
      "mytag"}}`, with `mytag` being the tag-name and field-values via
      `{{.Field "myfield"}}`, with `myfield` being the field-name. Non-existing
      tags and field will result in an empty string or `nil` respectively. In
      case the key cannot be found, the metric is passed-through unchanged. By
      default all matching tags are added and existing tag-values are
      overwritten.

      Please note: The plugin only supports the addition of tags and thus all
      mapped tag-values need to be strings!
    introduced: 
    tags: []
  - name: Noise
    id: noise
    description: |
      The _Noise_ processor is used to add noise to numerical field values. For
      each field a noise is generated using a defined probability density
      function and added to the value. The function type can be configured as
      _Laplace_, _Gaussian_ or _Uniform_. Depending on the function, various
      parameters need to be configured:
    introduced: 
    tags: []
  - name: Override
    id: override
    description: |
      The override processor plugin allows overriding all modifications that
      are supported by input plugins and aggregators:

      * name_override
      * name_prefix
      * name_suffix
      * tags

      All metrics passing through this processor will be modified accordingly.
      Select the metrics to modify using the standard metric filtering options.

      Values of *name_override*, *name_prefix*, *name_suffix* and already
      present *tags* with conflicting keys will be overwritten. Absent *tags*
      will be created.

      Use-case of this plugin encompass ensuring certain tags or naming
      conventions are adhered to irrespective of input plugin configurations,
      e.g. by `taginclude`.
    introduced: 
    tags: []
  - name: Parser
    id: parser
    description: |
      This plugin parses defined fields or tags containing the specified data
      format and creates new metrics based on the contents of the field or tag.
    introduced: 
    tags: []
  - name: Pivot
    id: pivot
    description: |
      You can use the `pivot` processor to rotate single valued metrics into a
      multi field metric. This transformation often results in data that is
      more easily to apply mathematical operators and comparisons between, and
      flatten into a more compact representation for write operations with some
      output data formats.

      To perform the reverse operation use the [unpivot] processor.
    introduced: 
    tags: []
  - name: Port Name Lookup
    id: port_name
    description: |
      Use the `port_name` processor to convert a tag or field containing a
      well-known port number to the registered service name.

      Tag or field can contain a number ("80") or number and protocol separated
      by slash ("443/tcp"). If protocol is not provided it defaults to tcp but
      can be changed with the default_protocol setting. An additional tag or
      field can be specified for the protocol.

      If the source was found in tag, the service name will be added as a tag.
      If the source was found in a field, the service name will also be a
      field.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Printer
    id: printer
    description: |
      The printer processor plugin simple prints every metric passing through
      it.
    introduced: 
    tags: []
  - name: Regex
    id: regex
    description: |
      This plugin transforms tag and field _values_ as well as renaming tags,
      fields and metrics using regex patterns. Tag and field _values_ can be
      transformed using named-groups in a batch fashion.

      The regex processor **only operates on string fields**. It will not work
      on any other data types, like an integer or float.
    introduced: 
    tags: []
  - name: Rename
    id: rename
    description: |
      The `rename` processor renames measurements, fields, and tags.
    introduced: 
    tags: []
  - name: Reverse DNS
    id: reverse_dns
    description: |
      The `reverse_dns` processor does a reverse-dns lookup on tags (or fields)
      with IPs in them.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: S2 Geo
    id: s2geo
    description: |
      Use the `s2geo` processor to add tag with S2 cell ID token of specified
      [cell level](). The tag is used in `experimental/geo` Flux package
      functions. The `lat` and `lon` fields values should contain WGS-84
      coordinates in decimal degrees.
    introduced: 
    tags: []
  - name: Scale
    id: scale
    description: |
      The scale processor filters for a set of fields, and scales the
      respective values from an input range into the given output range
      according to this formula:

      Alternatively, you can apply a factor and offset to the input according
      to this formula

      Input fields are converted to floating point values if possible.
      Otherwise, fields that cannot be converted are ignored and keep their
      original value.

      **Please note:** Neither the input nor the output values are clipped to
      their respective ranges!
    introduced: 
    tags: []
  - name: SNMP Lookup
    id: snmp_lookup
    description: |
      The `snmp_lookup` plugin looks up extra tags using SNMP and caches them.

      Telegraf minimum version: Telegraf 1.30.0
    introduced: 
    tags: []
  - name: Split
    id: split
    description: |
      This plugin splits a metric up into one or more metrics based on a
      template the user provides. The timestamp of the new metric is based on
      the source metric. Templates can overlap, where a field or tag, is used
      across templates and as a result end up in multiple metrics.

      **NOTE**: If drop original is changed to true, then the plugin can result
      in dropping all metrics when no match is found! Please ensure to test
      templates before putting into production *and* use metric filtering to
      avoid data loss.

      Some outputs are sensitive to the number of metric series that are
      produced. Multiple metrics of the same series (i.e. identical name, tag
      key-values and field name) with the same timestamp might result in
      squashing those points to the latest metric produced.
    introduced: 
    tags: []
  - name: Starlark
    id: starlark
    description: |
      The `starlark` processor calls a Starlark function for each matched
      metric, allowing for custom programmatic metric processing.

      The Starlark language is a dialect of Python, and will be familiar to
      those who have experience with the Python language. However, there are
      major differences. Existing Python code is unlikely to work unmodified.
      The execution environment is sandboxed, and it is not possible to do I/O
      operations such as reading from files or sockets.

      The **[Starlark
      specification](https://github.com/google/starlark-go/blob/d1966c6b9fcd/doc/spec.md)**
      has details about the syntax and available functions.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Strings
    id: strings
    description: |
      The `strings` plugin maps certain go string functions onto measurement,
      tag, and field values. Values can be modified in place or stored in
      another key.

      Implemented functions are:

      - lowercase
      - uppercase
      - titlecase
      - trim
      - trim_left
      - trim_right
      - trim_prefix
      - trim_suffix
      - replace
      - left
      - base64decode
      - valid_utf8

      Please note that in this implementation these are processed in the order
      that they appear above.

      Specify the `measurement`, `tag`, `tag_key`, `field`, or `field_key` that
      you want processed in each section and optionally a `dest` if you want
      the result stored in a new tag or field. You can specify lots of
      transformations on data with a single strings processor.

      If you'd like to apply the change to every `tag`, `tag_key`, `field`,
      `field_key`, or `measurement`, use the value `"*"` for each respective
      field. Note that the `dest` field will be ignored if `"*"` is used.

      If you'd like to apply multiple processings to the same `tag_key` or
      `field_key`, note the process order stated above. See the second example
      below for an example.
    introduced: 
    tags: []
  - name: Tag Limit
    id: tag_limit
    description: |
      Use the `tag_limit` processor to ensure that only a certain number of
      tags are preserved for any given metric, and to choose the tags to
      preserve when the number of tags appended by the data source is over the
      limit.

      This can be useful when dealing with output systems (e.g. Stackdriver)
      that impose hard limits on the number of tags/labels per metric or where
      high levels of cardinality are computationally and/or financially
      expensive.
    introduced: 
    tags: []
  - name: Template
    id: template
    description: |
      The `template` processor applies a Go template to metrics to generate a
      new tag. The primary use case of this plugin is to create a tag that can
      be used for dynamic routing to multiple output plugins or using an output
      specific routing option.

      The template has access to each metric's measurement name, tags, fields,
      and timestamp using the interface in `/template_metric.go`.

      Read the full [Go Template
      Documentation](https://golang.org/pkg/text/template/).
    introduced: 
    tags: []
  - name: Timestamp
    id: timestamp
    description: |
      Use the timestamp processor to parse fields containing timestamps into
      timestamps of other formats.
    introduced: 
    tags: []
  - name: TopK
    id: topk
    description: |
      The TopK processor plugin is a filter designed to get the top series over
      a period of time. It can be tweaked to calculate the top metrics via
      different aggregation functions.

      This processor goes through these steps when processing a batch of
      metrics:

      1. Groups measurements in buckets based on their tags and name
      1. Every N seconds, for each bucket, for each selected field: aggregate
      all the measurements using a given aggregation function (min, sum, mean,
      etc) and the field.
      1. For each computed aggregation: order the buckets by the aggregation,
      then returns all measurements in the top `K` buckets

      Notes:

      * The deduplicates metrics
      * The name of the measurement is always used when grouping it
      * Depending on the amount of metrics on each bucket, more than `K` series
      may be returned
      * If a measurement does not have one of the selected fields, it is dropped
      from the aggregation
    introduced: 
    tags: []
  - name: Unpivot
    id: unpivot
    description: |
      You can use the `unpivot` processor to rotate a multi field series into
      single valued metrics. This transformation often results in data that is
      more easy to aggregate across fields.

      To perform the reverse operation use the [pivot] processor.
    introduced: 
    tags: []
