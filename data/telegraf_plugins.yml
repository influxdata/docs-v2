input:
  - name: ActiveMQ
    id: activemq
    description: |
      This plugin gathers queue, topics and subscribers metrics using the
      Console API [ActiveMQ](https://activemq.apache.org/) message broker
      daemon.
    introduced: v1.8.0
    tags: [messaging, freebsd, linux, macos, windows]
  - name: Aerospike
    id: aerospike
    description: |
      This plugin queries [Aerospike](https://www.aerospike.com) server(s) for
      node statistics and statistics on all configured namespaces.

      > [!CAUTION]
      > As of version 1.30 the Aerospike plugin has been deprecated in favor of
      > the prometheus plugin and the officially supported [Aerospike Prometheus
      > Exporter](https://aerospike.com/docs/monitorstack/configure/configure-exporter)

      For details on the measurements mean, please consult the [Aerospike
      Metrics Reference
      Docs](https://www.aerospike.com/docs/reference/metrics).

      > [!NOTE]
      > Metric names will have dashes (`-`) replaced as underscores (`_`) to
      > make querying more consistently and easy.

      All metrics are attempted to be cast to integers, then booleans, then
      strings in order.
    introduced: v0.2.0
    deprecated: v1.30.0
    removal: v1.40.0
    tags: [server, freebsd, linux, macos, windows]
  - name: Alibaba Cloud Monitor Service (Aliyun)
    id: aliyuncms
    description: |
      This plugin gathers statistics from the [Alibaba / Aliyun cloud
      monitoring service](https://www.alibabacloud.com). In the following we
      will use `Aliyun` instead of `Alibaba` as it's the default naming across
      the web console and docs.
    introduced: v1.19.0
    tags: [cloud, freebsd, linux, macos, windows]
  - name: AMD ROCm System Management Interface (SMI)
    id: amd_rocm_smi
    description: |
      This plugin gathers statistics including memory and GPU usage,
      temperatures etc from [AMD ROCm platform](https://rocm.docs.amd.com/)
      GPUs.

      > [!IMPORTANT]
      > The [`rocm-smi` binary]() is required and needs to be installed on the
      > system.
    introduced: v1.20.0
    tags: [hardware, system, freebsd, linux, macos, windows]
  - name: AMQP Consumer
    id: amqp_consumer
    description: |
      This plugin consumes messages from an Advanced Message Queuing Protocol
      v0.9.1 broker. A prominent implementation of this protocol is
      [RabbitMQ](https://www.rabbitmq.com).

      Metrics are read from a topic exchange using the configured queue and
      binding key. The message payloads must be formatted in one of the
      supported [data formats](/telegraf/v1/data_formats/input).

      For an introduction check the [AMQP concepts
      page](https://www.rabbitmq.com/tutorials/amqp-concepts.html) and the
      [RabbitMQ getting started
      guide](https://www.rabbitmq.com/getstarted.html).
    introduced: v1.3.0
    tags: [messaging, freebsd, linux, macos, windows]
  - name: Apache
    id: apache
    description: |
      This plugin collects performance information from [Apache HTTP
      Servers](https://httpd.apache.org) using the [`mod_status` module]().
      Typically, this module is configured to expose a page at the
      `/server-status?auto` endpoint the server.

      The [ExtendedStatus
      option](https://httpd.apache.org/docs/current/mod/core.html#extendedstatus)
      must be enabled in order to collect all available fields. For information
      about configuration of your server check the [module
      documentation](https://httpd.apache.org/docs/current/mod/mod_status.html).
    introduced: v1.8.0
    tags: [server, web, freebsd, linux, macos, windows]
  - name: APC UPSD
    id: apcupsd
    description: |
      This plugin gathers data from one or more [apcupsd
      daemon](https://sourceforge.net/projects/apcupsd/) over the NIS network
      protocol. To query a server, the daemon must be running and be
      accessible.
    introduced: v1.12.0
    tags: [hardware, server, freebsd, linux, macos, windows]
  - name: Apache Aurora
    id: aurora
    description: |
      This plugin gathers metrics from [Apache
      Aurora](https://aurora.apache.org) schedulers. For monitoring
      recommendations check the [Monitoring your Aurora
      cluster](https://aurora.apache.org/documentation/latest/operations/monitoring)
      article.
    introduced: v1.7.0
    tags: [applications, server, freebsd, linux, macos, windows]
  - name: Azure Monitor
    id: azure_monitor
    description: |
      This plugin gathers metrics of Azure resources using the [Azure
      Monitor](https://docs.microsoft.com/en-us/azure/azure-monitor) API. The
      plugin requires a `client_id`, `client_secret` and `tenant_id` for
      authentication via access token. The `subscription_id` is required for
      accessing Azure resources.

      Check the [supported metrics
      page](https://docs.microsoft.com/en-us/azure/azure-monitor/essentials/metrics-supported)
      for available resource types and their metrics.

      > [!IMPORTANT]
      > The Azure API has a read limit of 12,000 requests per hour. Please make
      > sure you don't exceed this limit with the total number of metrics you
      > are in the configured interval.
    introduced: v1.25.0
    tags: [cloud, freebsd, linux, macos, windows]
  - name: Azure Queue Storage
    id: azure_storage_queue
    description: |
      This plugin gathers queue sizes from the [Azure Queue
      Storage](https://learn.microsoft.com/en-us/azure/storage/queues) service,
      storing a large numbers of messages.
    introduced: v1.13.0
    tags: [cloud, freebsd, linux, macos, windows]
  - name: Bcache
    id: bcache
    description: |
      This plugin gathers statistics for the [block layer
      cache](https://docs.kernel.org/admin-guide/bcache.html) from the
      `stats_total` directory and `dirty_data` file.
    introduced: v0.2.0
    tags: [system, linux]
  - name: Beanstalkd
    id: beanstalkd
    description: |
      This plugin collects server statistics as well as tube statistics from a
      [Beanstalkd work queue](https://beanstalkd.github.io/) as reported by the
      `stats` and `stats-tube` server commands.
    introduced: v1.8.0
    tags: [messaging, freebsd, linux, macos, windows]
  - name: Beat
    id: beat
    description: |
      This plugin will collect metrics from a
      [Beats](https://www.elastic.co/beats) instances. It is known to work with
      Filebeat and Kafkabeat.
    introduced: v1.18.0
    tags: [applications, freebsd, linux, macos, windows]
  - name: BIND 9 Nameserver
    id: bind
    description: |
      This plugin collects metrics from [BIND 9
      nameservers](https://www.isc.org/bind) using the XML or JSON endpoint.

      For _XML_, version 2 statistics (BIND 9.6 to 9.9) and version 3
      statistics (BIND 9.9+) are supported. Version 3 statistics are the
      default and only XML format in BIND 9.10+.

      > [!NOTE]
      > For BIND 9.9 to support version 3 statistics, it must be built with the
      > `--enable-newstats` compile flag, and the statistics must be
      > specifically requested via the correct URL.

      For _JSON_, version 1 statistics (BIND 9.10+) are supported. As of
      writing, some distros still do not enable support for JSON statistics in
      their BIND packages.
    introduced: v1.11.0
    tags: [server, freebsd, linux, macos, windows]
  - name: Bond
    id: bond
    description: |
      This plugin collects metrics for both the network bond interface as well
      as its slave interfaces using `/proc/net/bonding/*` files.
    introduced: v1.5.0
    tags: [system, freebsd, linux, macos, windows]
  - name: Burrow
    id: burrow
    description: |
      This plugin collect Kafka topic, consumer and partition status from the
      [Burrow - Kafka Consumer Lag
      Checking](https://github.com/linkedin/Burrow) companion via [HTTP
      API](https://github.com/linkedin/Burrow/wiki/HTTP-Endpoint). Burrow v1.x
      versions are supported.
    introduced: v1.7.0
    tags: [messaging, freebsd, linux, macos, windows]
  - name: Ceph Storage
    id: ceph
    description: |
      This plugin collects performance metrics from MON and OSD nodes in a
      [Ceph storage cluster](https://ceph.com). Support for Telegraf has been
      introduced in the v13.x Mimic release where data is sent to a socket (see
      [their documnetation](https://docs.ceph.com/en/latest/mgr/telegraf)).
    introduced: v0.13.1
    tags: [system, freebsd, linux, macos, windows]
  - name: Control Group
    id: cgroup
    description: |
      This plugin gathers statistics per [control group
      (cgroup)](https://docs.kernel.org/admin-guide/cgroup-v2.html).

      > [!NOTE]
      > Consider restricting paths to the set of cgroups you are interested in
      > if you have a large number of cgroups, to avoid cardinality issues.

      The plugin supports the _single value format_ in the form

      the _new line separated values format_ in the form

      the _space separated values format_ in the form

      and the _space separated keys and value, separated by new line format_ in
      the form
    introduced: v1.0.0
    tags: [system, linux]
  - name: chrony
    id: chrony
    description: |
      This plugin queries metrics from a [chrony NTP
      server](https://chrony-project.org). For details on the meaning of the
      gathered fields please check the [chronyc
      manual](https://chrony-project.org/doc/4.4/chronyc.html).
    introduced: v0.13.1
    tags: [system, freebsd, linux, macos, windows]
  - name: Cisco Model-Driven Telemetry (MDT)
    id: cisco_telemetry_mdt
    description: |
      This plugin consumes [Cisco model-driven telemetry
      (MDT)](https://www.cisco.com/c/en/us/products/collateral/switches/catalyst-9300-series-switches/model-driven-telemetry-wp.html)
      data from Cisco IOS XR, IOS XE and NX-OS platforms via TCP or GRPC.
      GRPC-based transport can utilize TLS for authentication and encryption.
      Telemetry data is expected to be GPB-KV (self-describing-gpb) encoded.

      The GRPC dialout transport is supported on various IOS XR (64-bit) 6.1.x
      and later, IOS XE 16.10 and later, as well as NX-OS 7.x and later
      platforms. The TCP dialout transport is supported on IOS XR (32-bit and
      64-bit) 6.1.x and later.
    introduced: v1.11.0
    tags: [applications, freebsd, linux, macos, windows]
  - name: ClickHouse
    id: clickhouse
    description: |
      This plugin gathers statistics data from a [ClickHouse
      server](https://github.com/ClickHouse/ClickHouse). Users on Clickhouse
      Cloud will not see the Zookeeper metrics as they may not have permissions
      to query those tables.
    introduced: v1.14.0
    tags: [server, freebsd, linux, macos, windows]
  - name: Google Cloud PubSub
    id: cloud_pubsub
    description: |
      This plugin consumes messages from the [Google Cloud
      PubSub](https://cloud.google.com/pubsub) service and creates metrics
      using one of the supported [data
      formats](/telegraf/v1/data_formats/input).
    introduced: v1.10.0
    tags: [cloud, messaging, freebsd, linux, macos, windows]
  - name: Google Cloud PubSub Push
    id: cloud_pubsub_push
    description: |
      This plugin listens for messages sent via an HTTP POST from [Google Cloud
      PubSub](https://cloud.google.com/pubsub) and expects messages in Google's
      Pub/Sub _JSON format_. The plugin allows Telegraf to serve as an endpoint
      of push service.

      Google's PubSub service will __only__ send over HTTPS/TLS so this plugin
      must be behind a valid proxy or must be configured to use TLS by setting
      the `tls_cert` and `tls_key` accordingly.

      Enable mutually authenticated TLS and authorize client connections by
      signing certificate authority by including a list of allowed CA
      certificate file names in `tls_allowed_cacerts`.
    introduced: v1.10.0
    tags: [cloud, messaging, freebsd, linux, macos, windows]
  - name: Amazon CloudWatch Statistics
    id: cloudwatch
    description: |
      This plugin will gather metric statistics from [Amazon
      CloudWatch](https://aws.amazon.com/cloudwatch).
    introduced: v0.12.1
    tags: [cloud, freebsd, linux, macos, windows]
  - name: Amazon CloudWatch Metric Streams
    id: cloudwatch_metric_streams
    description: |
      This plugin listens for metrics sent via HTTP by [Cloudwatch metric
      streams](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Metric-Streams.html)
      implementing the required [response
      specifications](https://docs.aws.amazon.com/firehose/latest/dev/httpdeliveryrequestresponse.html).

      > [!IMPORTANT]
      > Using this plugin can incure costs, see the _Metric Streams example_ in
      > [CloudWatch pricing](https://aws.amazon.com/cloudwatch/pricing).
    introduced: v1.24.0
    tags: [cloud, freebsd, linux, macos, windows]
  - name: Netfilter Conntrack
    id: conntrack
    description: |
      This plugin collects metrics from [Netfilter's conntrack
      tools](https://conntrack-tools.netfilter.org/). There are two collection
      mechanisms for this plugin:

      1. Extracting information from `/proc/net/stat/nf_conntrack` files if the
      `collect` option is set accordingly for finding CPU specific values.
      1. Using specific files and directories by specifying the `dirs` option.
      At runtime, conntrack exposes many of those connection statistics within
      `/proc/sys/net`. Depending on your kernel version, these files can be
      found in either `/proc/sys/net/ipv4/netfilter` or
      `/proc/sys/net/netfilter` and will be prefixed with either `ip` or `nf`.

      In order to simplify configuration in a heterogeneous environment, a
      superset of directory and filenames can be specified. Any locations that
      doesn't exist is ignored.
    introduced: v1.0.0
    tags: [system, linux]
  - name: Hashicorp Consul
    id: consul
    description: |
      This plugin will collect statistics about all health checks registered in
      [Consul](https://www.consul.io) using the [Consul
      API](https://www.consul.io/docs/agent/http/health.html#health_state). The
      plugin will not report any [telemetry
      metrics](https://www.consul.io/docs/agent/telemetry.html) but Consul can
      report those statistics using the StatsD protocol if needed.
    introduced: v1.0.0
    tags: [server, freebsd, linux, macos, windows]
  - name: Hashicorp Consul Agent
    id: consul_agent
    description: |
      This plugin collects metrics from a [Consul
      agent](https://developer.hashicorp.com/consul/commands/agent). Telegraf
      may be present in every node and connect to the agent locally. Tested on
      Consul v1.10.
    introduced: v1.22.0
    tags: [server, freebsd, linux, macos, windows]
  - name: Couchbase
    id: couchbase
    description: |
      This plugin collects metrics from
      [Couchbase](https://www.couchbase.com/), a distributed NoSQL database.
      Metrics are collected for each node, as well as detailed metrics for each
      bucket, for a given couchbase server.
    introduced: v0.12.0
    tags: [server, freebsd, linux, macos, windows]
  - name: Apache CouchDB
    id: couchdb
    description: |
      This plugin gathers metrics from [Apache
      CouchDB](https://couchdb.apache.org/) instances using the
      [stats](http://docs.couchdb.org/en/1.6.1/api/server/common.html?highlight=stats#get--_stats)
      endpoint.
    introduced: v0.10.3
    tags: [server, freebsd, linux, macos, windows]
  - name: CPU
    id: cpu
    description: |
      This plugin gather metrics on the system's CPUs.
    introduced: v0.1.5
    tags: [system, freebsd, linux, macos, windows]
  - name: Counter-Strike Global Offensive (CSGO)
    id: csgo
    description: |
      This plugin gather metrics from [Counter-Strike: Global
      Offensive](https://www.counter-strike.net/) servers.
    introduced: v1.18.0
    tags: [server, freebsd, linux, macos, windows]
  - name: Bosch Rexroth ctrlX Data Layer
    id: ctrlx_datalayer
    description: |
      This plugin gathers data from the [ctrlX Data
      Layer](https://ctrlx-automation.com) a communication middleware running
      on Bosch Rexroth's [ctrlX CORE devices](https://ctrlx-core.com). The
      platform is used for professional automation applications like industrial
      automation, building automation, robotics, IoT Gateways or as classical
      PLC.
    introduced: v1.27.0
    tags: [iot, messaging, freebsd, linux, macos, windows]
  - name: Mesosphere Distributed Cloud OS
    id: dcos
    description: |
      This input plugin gathers metrics from a [Distributed Cloud
      OS](https://dcos.io/) cluster's [metrics
      component](https://docs.mesosphere.com/1.10/metrics/).

      > [!WARNING]
      > Depending on the workload of your DC/OS cluster, this plugin can quickly
      > create a high number of series which, when unchecked, can cause high
      > load on your database!
    introduced: v1.5.0
    tags: [containers, freebsd, linux, macos, windows]
  - name: Directory Monitor
    id: directory_monitor
    description: |
      This plugin monitors a single directory (traversing sub-directories), and
      processes each file placed in the directory. The plugin will gather all
      files in the directory at the configured interval, and parse the ones
      that haven't been picked up yet.

      > [!NOTE]
      > Files should not be used by another process or the plugin may fail.
      > Furthermore, files should not be written _live_ to the monitored
      > directory. If you absolutely must write files directly, they must be
      > guaranteed to finish writing before `directory_duration_threshold`.
    introduced: v1.18.0
    tags: [system, freebsd, linux, macos, windows]
  - name: Disk
    id: disk
    description: |
      This plugin gathers metrics about disk usage.

      > [!NOTE]
      > The `used_percent` field is calculated by `used / (used + free)` and
      > _not_ `used / total` as the unix `df` command does it. See [wikipedia -
      > df](https://en.wikipedia.org/wiki/Df_(Unix)) for more details.
    introduced: v0.1.1
    tags: [system, freebsd, linux, macos, windows]
  - name: DiskIO
    id: diskio
    description: |
      This plugin gathers metrics about disk traffic and timing.
    introduced: v0.10.0
    tags: [system, freebsd, linux, macos, windows]
  - name: Disque
    id: disque
    description: |
      This plugin gathers data from a
      [Disque](https://github.com/antirez/disque) instance, an experimental
      distributed, in-memory, message broker.
    introduced: v0.10.0
    tags: [messaging, freebsd, linux, macos, windows]
  - name: Device Mapper Cache
    id: dmcache
    description: |
      This plugin provide a native collection for dmsetup based statistics for
      [dm-cache](https://docs.kernel.org/admin-guide/device-mapper/cache.html).

      > [!NOTE]
      > This plugin requires super-user permissions! Please make sure, Telegraf
      > is able to run `sudo /sbin/dmsetup status --target cache` without
      > requiring a password.
    introduced: v1.3.0
    tags: [system, linux]
  - name: DNS Query
    id: dns_query
    description: |
      This plugin gathers information about DNS queries such as response time
      and result codes.
    introduced: v1.4.0
    tags: [network, system, freebsd, linux, macos, windows]
  - name: Docker
    id: docker
    description: |
      This plugin uses the [Docker Engine
      API](https://docs.docker.com/engine/api) to gather metrics on running
      docker containers.

      > [!NOTE]
      > Please make sure Telegraf has sufficient permissions to access the
      > configured endpoint!
    introduced: v0.1.9
    tags: [containers, freebsd, linux, macos, windows]
  - name: Docker Log
    id: docker_log
    description: |
      This plugin uses the [Docker Engine
      API](https://docs.docker.com/engine/api) to gather logs from running
      docker containers.

      > [!NOTE]
      > This plugin works only for containers with the `local` or `json-file` or
      > `journald` logging driver. Please make sure Telegraf has sufficient
      > permissions to access the configured endpoint!
    introduced: v1.12.0
    tags: [containers, logging, freebsd, linux, macos, windows]
  - name: Dovecot
    id: dovecot
    description: |
      This plugin uses the Dovecot [v2.1 stats
      protocol](https://doc.dovecot.org/configuration_manual/stats/old_statistics/#old-statistics)
      to gather metrics on configured domains of
      [Dovecot](https://www.dovecot.org/) servers. You should still be able to
      use this protocol on newer versions of Dovecot.
    introduced: v0.10.3
    tags: [server, freebsd, linux, macos, windows]
  - name: Data Plane Development Kit (DPDK)
    id: dpdk
    description: |
      This plugin collects metrics exposed by applications built with the [Data
      Plane Development Kit](https://www.dpdk.org) which is an extensive set of
      open source libraries designed for accelerating packet processing
      workloads.

      > [!NOTE]
      > Since DPDK will most likely run with root privileges, the telemetry
      > socket exposed by DPDK will also require root access. Please adjust
      > permissions accordingly!

      Refer to the [Telemetry User
      Guide](https://doc.dpdk.org/guides/howto/telemetry.html) for details and
      examples on how to use DPDK in your application.

      > [!IMPORTANT]
      > This plugin uses the `v2` interface to read telemetry > data from
      > applications and required DPDK version `v20.05` or higher. Some metrics
      > might require later versions. The recommended version, especially in
      > conjunction with the `in_memory` option is `DPDK 21.11.2` or higher.
    introduced: v1.19.0
    tags: [applications, networking, linux]
  - name: Amazon Elastic Container Service
    id: ecs
    description: |
      This plugin gathers statistics on running containers in a Task from the
      [Amazon Elastic Container Service](https://aws.amazon.com/ecs/) using the
      [Amazon ECS
      metadata](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-metadata-endpoint.html)
      and the
      [v2](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-metadata-endpoint-v2.html)
      or
      [v3](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-metadata-endpoint-v3.html)
      statistics API endpoints.

      > [!IMPORTANT]
      > The telegraf container must be run in the same Task as the workload it
      > is inspecting.

      The amazon-ecs-agent (though it _is_ a container running on the host) is
      not present in the metadata/stats endpoints.
    introduced: v1.11.0
    tags: [cloud, freebsd, linux, macos, windows]
  - name: Elasticsearch
    id: elasticsearch
    description: |
      This plugin queries endpoints of a
      [Elasticsearch](https://www.elastic.co/) instance to obtain [node
      statistics](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-nodes-stats.html)
      and optionally
      [cluster-health](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-health.html)
      metrics. Additionally, the plugin is able to query
      [cluster](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-stats.html),
      [indices and
      shard](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-stats.html)
      statistics for the master node.

      > [!NOTE]
      > Specific statistics information can change between Elasticsearch
      > versions. In general, this plugin attempts to stay as version-generic as
      > possible by tagging high-level categories only and creating unique field
      > names of whatever statistics names are provided at the mid-low level.
    introduced: v0.1.5
    tags: [server, freebsd, linux, macos, windows]
  - name: Elasticsearch Query
    id: elasticsearch_query
    description: |
      This plugin allows to query an [Elasticsearch](https://www.elastic.co/)
      instance to obtain metrics from data stored in the cluster. The plugins
      supports counting the number of hits for a search query, calculating
      statistics for numeric fields, filtered by a query, aggregated per tag
      and to count the number of terms for a particular field.

      > [!IMPORTANT]
      > This plugins supports Elasticsearch 5.x and 6.x but is known to break on
      > 7.x or higher.
    introduced: v1.20.0
    tags: [datastore, freebsd, linux, macos, windows]
  - name: Ethtool
    id: ethtool
    description: |
      This plugin collects ethernet device statistics. The available
      information strongly depends on the network device and driver.
    introduced: v1.13.0
    tags: [networking, system, linux]
  - name: Azure Event Hub Consumer
    id: eventhub_consumer
    description: |
      This plugin allows consuming messages from [Azure Event
      Hubs](https://learn.microsoft.com/en-us/azure/event-hubs/event-hubs-about)
      and [Azure IoT Hub](https://azure.microsoft.com/en-us/products/iot-hub)
      instances.
    introduced: v1.14.0
    tags: [iot, messaging, freebsd, linux, macos, windows]
  - name: Exec
    id: exec
    description: |
      This plugin executes the given `commands` on every interval and parses
      metrics from their output in any one of the supported [data
      formats](/telegraf/v1/data_formats/input). This plugin can be used to
      poll for custom metrics from any source.
    introduced: v0.1.5
    tags: [system, freebsd, linux, macos, windows]
  - name: Execd
    id: execd
    description: |
      This plugin runs the given external program as a long-running daemon and
      collects the metrics in one of the supported [data
      formats](/telegraf/v1/data_formats/input) on the process's `stdout`. The
      program is expected to stay running and output data when receiving the
      configured `signal`.

      The `stderr` output of the process will be relayed to Telegraf's logging
      facilities and will be logged as _error_ by default. However, you can log
      to other levels by prefixing your message with `E!` for error, `W!` for
      warning, `I!` for info, `D!` for debugging and `T!` for trace levels
      followed by a space and the actual message. For example outputting `I! A
      log message` will create a `info` log line in your Telegraf logging
      output.
    introduced: v1.14.0
    tags: [system, freebsd, linux, macos, windows]
  - name: Fail2ban
    id: fail2ban
    description: |
      This plugin gathers the count of failed and banned IP addresses using
      [fail2ban](https://www.fail2ban.org) by running the `fail2ban-client`
      command.

      > [!NOTE]
      > The `fail2ban-client` requires root access, so please make sure to
      > either allow Telegraf to run that command using `sudo` without a
      > password or by running telegraf as root (not recommended).
    introduced: v1.4.0
    tags: [networking, system, freebsd, linux, macos, windows]
  - name: Fibaro
    id: fibaro
    description: |
      This plugin gathers data from devices connected to a
      [Fibaro](https://www.fibaro.com) controller. Those values could be true
      (1) or false (0) for switches, percentage for dimmers, temperature, etc.
      Both _Home Center 2_ and _Home Center 3_ devices are supported.
    introduced: v1.7.0
    tags: [iot, freebsd, linux, macos, windows]
  - name: File
    id: file
    description: |
      This plugin reads the __complete__ contents of the configured files in
      __every__ interval. The file content is split line-wise and parsed
      according to one of the supported [data
      formats](/telegraf/v1/data_formats/input).

      > [!TIP]
      > If you wish to only process newly appended lines use the
      > [tail](/telegraf/v1/plugins/#input-tail) input plugin instead.
    introduced: v1.8.0
    tags: [system, freebsd, linux, macos, windows]
  - name: Filecount
    id: filecount
    description: |
      This plugin reports the number and total size of files in specified
      directories.
    introduced: v1.8.0
    tags: [system, freebsd, linux, macos, windows]
  - name: File statistics
    id: filestat
    description: |
      This plugin gathers metrics about file existence, size, and other file
      statistics.
    introduced: v0.13.0
    tags: [system, freebsd, linux, macos, windows]
  - name: Fireboard
    id: fireboard
    description: |
      This plugin gathers real-time temperature data from
      [fireboard](https://www.fireboard.com) thermometers.

      > [!NOTE]
      > You will need to sign up to for the [Fireboard REST
      > API](https://docs.fireboard.io/reference/restapi.html) in order to use
      > this plugin.
    introduced: v1.12.0
    tags: [iot, freebsd, linux, macos, windows]
  - name: Fluentd
    id: fluentd
    description: |
      This plugin gathers internal metrics of a
      [fluentd](https://www.fluentd.org/) instance provided by fluentd's
      [monitor agent plugin](https://docs.fluentd.org/input/monitor_agent).
      Data provided by the `/api/plugin.json` resource, `/api/config.json` is
      not covered.

      > [!IMPORTANT]
      > This plugin might produce high-cardinality series as the `plugin_id`
      > value is random after each restart of fluentd. You might need to adjust
      > your fluentd configuration, in order to reduce series cardinality in
      > case your fluentd restarts frequently by adding the `@id` parameter to
      > each plugin. See [fluentd's
      > documentation](https://docs.fluentd.org/configuration/config-file#common-plugin-parameter)
      > for details.
    introduced: v1.4.0
    tags: [server, freebsd, linux, macos, windows]
  - name: GitHub
    id: github
    description: |
      Gather repository information from [GitHub](https://www.github.com)
      hosted repositories.

      **Note:** Telegraf also contains the
      [webhook](/telegraf/v1/plugins/#input-github) input which can be used as
      an alternative method for collecting repository information.
    introduced: 
    tags: []
  - name: gNMI (gRPC Network Management Interface)
    id: gnmi
    description: |
      This plugin consumes telemetry data based on the
      [gNMI](https://github.com/openconfig/reference/blob/master/rpc/gnmi/gnmi-specification.md)
      Subscribe method. TLS is supported for authentication and encryption.
      This input plugin is vendor-agnostic and is supported on any platform
      that supports the gNMI spec.

      For Cisco devices:

      It has been optimized to support gNMI telemetry as produced by Cisco IOS
      XR (64-bit) version 6.5.1, Cisco NX-OS 9.3 and Cisco IOS XE 16.12 and
      later.

      Please check the troubleshooting section in case of problems, e.g. when
      getting an *empty metric-name warning*!
    introduced: 
    tags: []
  - name: Google Cloud Storage
    id: google_cloud_storage
    description: |
      The Google Cloud Storage plugin will collect metrics on the given Google
      Cloud Storage Buckets.
    introduced: 
    tags: []
  - name: GrayLog
    id: graylog
    description: |
      The Graylog plugin can collect data from remote Graylog service URLs.

      Plugin currently support two type of end points:-

      - multiple (e.g.
      `http://[graylog-server-ip]:9000/api/system/metrics/multiple`)
      - namespace (e.g.
      `http://[graylog-server-ip]:9000/api/system/metrics/namespace/{namespace}`)

      End Point can be a mix of one multiple end point and several namespaces
      end points

      Note: if namespace end point specified metrics array will be ignored for
      that call.
    introduced: 
    tags: []
  - name: HAProxy
    id: haproxy
    description: |
      The [HAProxy](http://www.haproxy.org/) input plugin gathers
      [statistics](https://cbonte.github.io/haproxy-dconv/1.9/intro.html#3.3.16)
      using the [stats
      socket](https://cbonte.github.io/haproxy-dconv/1.8/configuration.html#3.1-stats%20socket)
      or [HTTP statistics
      page](https://cbonte.github.io/haproxy-dconv/1.9/management.html#9) of a
      HAProxy server.
    introduced: 
    tags: []
  - name: HDDtemp
    id: hddtemp
    description: |
      This plugin reads data from hddtemp daemon.

      Hddtemp should be installed and its daemon running.
    introduced: 
    tags: []
  - name: HTTP
    id: http
    description: |
      The HTTP input plugin collects metrics from one or more HTTP(S)
      endpoints. The endpoint should have metrics formatted in one of the
      supported input data formats. Each data format has its own unique set of
      configuration options which can be added to the input configuration.
    introduced: 
    tags: []
  - name: HTTP Listener v2
    id: http_listener_v2
    description: |
      The HTTP Listener v2 is a service input plugin that listens for metrics
      sent via HTTP. Metrics may be sent in any supported
      [data-format](/telegraf/v1/data_formats/input).

      > [!NOTE]
      > If you would like Telegraf to act as a proxy/relay for InfluxDB v1 or
      > InfluxDB v2 it is recommended to use the [`influxdb__listener`]() or
      > [`influxdb_v2_listener`]() plugin instead.
    introduced: v1.30.0
    tags: [servers, web, freebsd, linux, macos, windows]
  - name: HTTP Response
    id: http_response
    description: |
      This input plugin checks HTTP/HTTPS connections.
    introduced: 
    tags: []
  - name: Hugepages
    id: hugepages
    description: |
      Transparent Huge Pages (THP) is a Linux memory management system that
      reduces the overhead of Translation Lookaside Buffer (TLB) lookups on
      machines with large amounts of memory by using larger memory pages.

      Consult [the
      website](https://www.kernel.org/doc/html/latest/admin-guide/mm/hugetlbpage.html)
      for more details.
    introduced: 
    tags: []
  - name: Icinga2
    id: icinga2
    description: |
      This plugin gather services & hosts status using Icinga2 Remote API.

      The icinga2 plugin uses the icinga2 remote API to gather status on
      running services and hosts. You can read Icinga2's documentation for
      their remote API
      [here](https://docs.icinga.com/icinga2/latest/doc/module/icinga2/chapter/icinga2-api).
    introduced: 
    tags: []
  - name: InfiniBand
    id: infiniband
    description: |
      This plugin gathers statistics for all InfiniBand devices and ports on
      the system. These are the counters that can be found in
      `/sys/class/infiniband/<dev>/port/<port>/counters/`

      **Supported Platforms**: Linux
    introduced: 
    tags: []
  - name: InfluxDB
    id: influxdb
    description: |
      The InfluxDB plugin will collect metrics on the given InfluxDB v1 servers
      from the `/debug/vars` endpoint. Read the
      [documentation](https://docs.influxdata.com/platform/monitoring/influxdata-platform/tools/measurements-internal/)
      for detailed information about `influxdb` metrics. For InfluxDB v2 and
      the `metrics` endpoint please see the section below.

      This plugin can also gather metrics from endpoints that expose
      InfluxDB-formatted endpoints. See below for more information.
    introduced: 
    tags: []
  - name: InfluxDB Listener
    id: influxdb_listener
    description: |
      InfluxDB Listener is a service input plugin that listens for requests
      sent according to the [InfluxDB HTTP
      API](https://docs.influxdata.com/influxdb/v1.8/guides/write_data/). The
      intent of the plugin is to allow Telegraf to serve as a proxy/router for
      the `/write` endpoint of the InfluxDB HTTP API.

      **Note:** This plugin was previously known as `http_listener`. If you
      wish to send general metrics via HTTP it is recommended to use the
      [`http_listener_v2`]() instead.

      The `/write` endpoint supports the `precision` query parameter and can be
      set to one of `ns`, `u`, `ms`, `s`, `m`, `h`. All other parameters are
      ignored and defer to the output plugins configuration.

      When chaining Telegraf instances using this plugin, CREATE DATABASE
      requests receive a 200 OK response with message body `{"results":[]}` but
      they are not relayed. The output configuration of the Telegraf instance
      which ultimately submits data to InfluxDB determines the destination
      database.
    introduced: 
    tags: []
  - name: InfluxDB V2 Listener
    id: influxdb_v2_listener
    description: |
      InfluxDB V2 Listener is a service input plugin that listens for requests
      sent according to the [InfluxDB HTTP
      API](https://docs.influxdata.com/influxdb/latest/api/). The intent of the
      plugin is to allow Telegraf to serve as a proxy/router for the
      `/api/v2/write` endpoint of the InfluxDB HTTP API.

      The `/api/v2/write` endpoint supports the `precision` query parameter and
      can be set to one of `ns`, `us`, `ms`, `s`. All other parameters are
      ignored and defer to the output plugins configuration.

      Telegraf minimum version: Telegraf 1.16.0
    introduced: 
    tags: []
  - name: Intel Baseband Accelerator
    id: intel_baseband
    description: |
      Intel Baseband Accelerator Input Plugin collects metrics from both
      dedicated and integrated Intel devices that provide Wireless Baseband
      hardware acceleration. These devices play a key role in accelerating 5G
      and 4G Virtualized Radio Access Networks (vRAN) workloads, increasing the
      overall compute capacity of a commercial, off-the-shelf platforms.

      Intel Baseband devices integrate various features critical for 5G and LTE
      (Long Term Evolution) networks, including e.g.:

      - Forward Error Correction (FEC) processing,
      - 4G Turbo FEC processing,
      - 5G Low Density Parity Check (LDPC)
      - a Fast Fourier Transform (FFT) block providing DFT/iDFT processing
      offload for the 5G Sounding Reference Signal (SRS)

      Supported hardware:

      - Intel® vRAN Boost integrated accelerators:4th Gen Intel® Xeon®
      Scalable processor with Intel® vRAN Boost (also known as Sapphire Rapids
      Edge Enhanced / SPR-EE)
      - External expansion cards connected to the PCI bus:Intel® vRAN Dedicated
      Accelerator ACC100 SoC (code named Mount Bryce)
    introduced: 
    tags: []
  - name: Intel® Dynamic Load Balancer (Intel® DLB) 
    id: intel_dlb
    description: |
      The `Intel DLB` plugin collects metrics exposed by applications built
      with [Data Plane Development Kit](https://www.dpdk.org/) which is an
      extensive set of open source libraries designed for accelerating packet
      processing workloads, plugin is also using bifurcated driver. More
      specifically it's targeted for applications that use Intel DLB as
      eventdev devices accessed via bifurcated driver (allowing access from
      kernel and user-space).
    introduced: 
    tags: []
  - name: Intel® Platform Monitoring Technology (Intel® PMT)
    id: intel_pmt
    description: |
      This plugin collects metrics via the Linux kernel driver for Intel®
      Platform Monitoring Technology (Intel® PMT). Intel® PMT is an
      architecture capable of enumerating and accessing hardware monitoring
      capabilities on a supported device.

      Support has been added to the mainline Linux kernel under the platform
      driver (`drivers/platform/x86/intel/pmt`) which exposes the Intel PMT
      telemetry space as a sysfs entry at `/sys/class/intel_pmt/`. Each
      discovered telemetry aggregator is exposed as a directory (with a `telem`
      prefix) containing a `guid` identifying the unique PMT space. This file
      is associated with a set of XML specification files which can be found in
      the [Intel-PMT Repository].

      This plugin discovers and parses the telemetry data exposed by the kernel
      driver using the specification inside the XML files. Furthermore, the
      plugin then reads low level samples/counters and evaluates high level
      samples/counters according to transformation formulas, and then reports
      the collected values.
    introduced: 
    tags: []
  - name: Intel Performance Monitoring Unit
    id: intel_pmu
    description: |
      This input plugin exposes Intel PMU (Performance Monitoring Unit) metrics
      available through [Linux
      Perf](https://perf.wiki.kernel.org/index.php/Main_Page) subsystem.

      PMU metrics gives insight into performance and health of IA processor's
      internal components, including core and uncore units. With the number of
      cores increasing and processor topology getting more complex the insight
      into those metrics is vital to assure the best CPU performance and
      utilization.

      Performance counters are CPU hardware registers that count hardware
      events such as instructions executed, cache-misses suffered, or branches
      mispredicted. They form a basis for profiling applications to trace
      dynamic control flow and identify hotspots.
    introduced: 
    tags: []
  - name: Intel PowerStat
    id: intel_powerstat
    description: |
      This input plugin monitors power statistics on Intel-based platforms and
      assumes presence of Linux based OS.

      Not all CPUs are supported, please see the software and hardware
      dependencies sections below to ensure platform support.

      Main use cases are power saving and workload migration. Telemetry
      frameworks allow users to monitor critical platform level metrics. Key
      source of platform telemetry is power domain that is beneficial for MANO
      Monitoring&Analytics systems to take preventive/corrective actions based
      on platform busyness, CPU temperature, actual CPU utilization and power
      statistics.
    introduced: 
    tags: []
  - name: Intel RDT
    id: intel_rdt
    description: |
      The `intel_rdt` plugin collects information provided by monitoring
      features of the Intel Resource Director Technology (Intel(R) RDT). Intel
      RDT provides the hardware framework to monitor and control the
      utilization of shared resources (ex: last level cache, memory bandwidth).
    introduced: 
    tags: []
  - name: Telegraf Internal
    id: internal
    description: |
      The `internal` plugin collects metrics about the telegraf agent itself.

      Note that some metrics are aggregates across all instances of one type of
      plugin.
    introduced: 
    tags: []
  - name: Internet Speed Monitor
    id: internet_speed
    description: |
      The `Internet Speed Monitor` collects data about the internet speed on
      the system.

      On some systems, the default settings may cause speed tests to fail; if
      this affects you then try enabling `memory_saving_mode`. This reduces the
      memory requirements for the test, and may reduce the runtime of the test.
      However, please be aware that this may also reduce the accuracy of the
      test for fast (>30Mb/s) connections. This setting enables the upstream
      [Memory Saving
      Mode](https://github.com/showwin/speedtest-go#memory-saving-mode)
    introduced: 
    tags: []
  - name: Interrupts
    id: interrupts
    description: |
      The interrupts plugin gathers metrics about IRQs from `/proc/interrupts`
      and `/proc/softirqs`.
    introduced: 
    tags: []
  - name: IPMI Sensor
    id: ipmi_sensor
    description: |
      Get bare metal metrics using the command line utility
      [`ipmitool`](https://github.com/ipmitool/ipmitool).

      If no servers are specified, the plugin will query the local machine
      sensor stats via the following command:

      or with the version 2 schema:

      When one or more servers are specified, the plugin will use the following
      command to collect remote host sensor stats:

      Any of the following parameters will be added to the aforementioned query
      if they're configured:
    introduced: 
    tags: []
  - name: Ipset
    id: ipset
    description: |
      The ipset plugin gathers packets and bytes counters from Linux ipset. It
      uses the output of the command "ipset save". Ipsets created without the
      "counters" option are ignored.

      Results are tagged with:

      - ipset name
      - ipset entry

      There are 3 ways to grant telegraf the right to run ipset:

      - Run as root (strongly discouraged)
      - Use sudo
      - Configure systemd to run telegraf with CAP_NET_ADMIN and CAP_NET_RAW
      capabilities.
    introduced: 
    tags: []
  - name: Iptables
    id: iptables
    description: |
      The iptables plugin gathers packets and bytes counters for rules within a
      set of table and chain from the Linux's iptables firewall.

      Rules are identified through associated comment. **Rules without comment
      are ignored**. Indeed we need a unique ID for the rule and the rule
      number is not a constant: it may vary when rules are inserted/deleted at
      start-up or by automatic tools (interactive firewalls, fail2ban, ...).
      Also when the rule set is becoming big (hundreds of lines) most people
      are interested in monitoring only a small part of the rule set.

      Before using this plugin **you must ensure that the rules you want to
      monitor are named with a unique comment**. Comments are added using the
      `-m comment --comment "my comment"` iptables options.

      The iptables command requires CAP_NET_ADMIN and CAP_NET_RAW capabilities.
      You have several options to grant telegraf to run iptables:

      * Run telegraf as root. This is strongly discouraged.
      * Configure systemd to run telegraf with CAP_NET_ADMIN and CAP_NET_RAW.
      This is the simplest and recommended option.
      * Configure sudo to grant telegraf to run iptables. This is the most
      restrictive option, but require sudo setup.
    introduced: 
    tags: []
  - name: IPVS
    id: ipvs
    description: |
      The IPVS input plugin uses the linux kernel netlink socket interface to
      gather metrics about ipvs virtual and real servers.

      **Supported Platforms:** Linux
    introduced: 
    tags: []
  - name: Jenkins
    id: jenkins
    description: |
      The jenkins plugin gathers information about the nodes and jobs running
      in a jenkins instance.

      This plugin does not require a plugin on jenkins and it makes use of
      Jenkins API to retrieve all the information needed.
    introduced: 
    tags: []
  - name: Jolokia2 Agent
    id: jolokia2_agent
    description: |
      The `jolokia2_agent` input plugin reads JMX metrics from one or more
      [Jolokia agent](https://jolokia.org/agent/jvm.html) REST endpoints.
    introduced: 
    tags: []
  - name: Jolokia2 Proxy
    id: jolokia2_proxy
    description: |
      The `jolokia2_proxy` input plugin reads JMX metrics from one or more
      _targets_ by interacting with a [Jolokia
      proxy](https://jolokia.org/features/proxy.html) REST endpoint.
    introduced: 
    tags: []
  - name: JTI OpenConfig Telemetry
    id: jti_openconfig_telemetry
    description: |
      This plugin reads Juniper Networks implementation of OpenConfig telemetry
      data from listed sensors using Junos Telemetry Interface. Refer to
      [openconfig.net](http://openconfig.net/) for more details about
      OpenConfig and [Junos Telemetry Interface
      (JTI)](https://www.juniper.net/documentation/en_US/junos/topics/concept/junos-telemetry-interface-oveview.html).
    introduced: 
    tags: []
  - name: Kafka Consumer
    id: kafka_consumer
    description: |
      The [Kafka](https://kafka.apache.org) consumer plugin reads from Kafka
      and creates metrics using one of the supported [input data
      formats](/telegraf/v1/data_formats/input).
    introduced: 
    tags: []
  - name: Kapacitor
    id: kapacitor
    description: |
      The Kapacitor plugin collects metrics from the given Kapacitor instances.
    introduced: 
    tags: []
  - name: Kernel
    id: kernel
    description: |
      This plugin is only available on Linux.

      The kernel plugin gathers info about the kernel that doesn't fit into
      other plugins. In general, it is the statistics available in `/proc/stat`
      that are not covered by other plugins as well as the value of
      `/proc/sys/kernel/random/entropy_avail` and optionally, Kernel Samepage
      Merging and Pressure Stall Information.

      The metrics are documented in `man 5 proc` under the `/proc/stat`
      section, as well as `man 4 random` under the `/proc interfaces` section
      (for `entropy_avail`).

      Kernel Samepage Merging is generally documented in [kernel
      documentation](https://www.kernel.org/doc/html/latest/accounting/psi.html)
      and the available metrics exposed via sysfs are documented in [admin
      guide](https://www.kernel.org/doc/html/latest/admin-guide/mm/ksm.html#ksm-daemon-sysfs-interface).

      Pressure Stall Information is exposed through `/proc/pressure` and is
      documented in [kernel
      documentation](https://www.kernel.org/doc/html/latest/accounting/psi.html).
      Kernel version 4.20 or later is required. Examples of PSI:
    introduced: 
    tags: []
  - name: Kernel VMStat
    id: kernel_vmstat
    description: |
      The kernel_vmstat plugin gathers virtual memory statistics by reading
      /proc/vmstat. For a full list of available fields see the /proc/vmstat
      section of the [proc man
      page](http://man7.org/linux/man-pages/man5/proc.5.html). For a better
      idea of what each field represents, see the [vmstat man
      page](http://linux.die.net/man/8/vmstat).
    introduced: 
    tags: []
  - name: Kibana
    id: kibana
    description: |
      The `kibana` plugin queries the [Kibana](https://www.elastic.co/) API to
      obtain the service status.

      - Telegraf minimum version: 1.8
      - Kibana minimum tested version: 6.0
    introduced: 
    tags: []
  - name: Kinesis Consumer
    id: kinesis_consumer
    description: |
      The [Kinesis](https://aws.amazon.com/kinesis/) consumer plugin reads from
      a Kinesis data stream and creates metrics using one of the supported
      [input data formats](/telegraf/v1/data_formats/input).
    introduced: 
    tags: []
  - name: KNX
    id: knx_listener
    description: |
      The KNX input plugin that listens for messages on the KNX home-automation
      bus. This plugin connects to the KNX bus via a KNX-IP interface.
      Information about supported KNX message datapoint types can be found at
      the underlying "knx-go" project site
      (<https://github.com/vapourismo/knx-go>).
    introduced: 
    tags: []
  - name: Kubernetes Inventory
    id: kube_inventory
    description: |
      This plugin generates metrics derived from the state of the following
      Kubernetes resources:

      - daemonsets
      - deployments
      - endpoints
      - ingress
      - nodes
      - persistentvolumes
      - persistentvolumeclaims
      - pods (containers)
      - services
      - statefulsets
      - resourcequotas

      Kubernetes is a fast moving project, with a new minor release every 3
      months. As such, we will aim to maintain support only for versions that
      are supported by the major cloud providers; this is roughly 4 release / 2
      years.

      **This plugin supports Kubernetes 1.11 and later.**
    introduced: 
    tags: []
  - name: Kubernetes
    id: kubernetes
    description: |
      The Kubernetes plugin talks to the Kubelet API and gathers metrics about
      the running pods and containers for a single host. It is assumed that
      this plugin is running as part of a `daemonset` within a kubernetes
      installation. This means that telegraf is running on every node within
      the cluster. Therefore, you should configure this plugin to talk to its
      locally running kubelet.

      Kubernetes is a fast moving project, with a new minor release every 3
      months. As such, this plugin aims to maintain support only for versions
      that are supported by the major cloud providers, namely, 4 release over 2
      years.
    introduced: 
    tags: []
  - name: Arista LANZ Consumer
    id: lanz
    description: |
      This plugin provides a consumer for use with Arista Networks’ Latency
      Analyzer (LANZ)

      Metrics are read from a stream of data via TCP through port 50001 on the
      switches management IP. The data is in Protobuffers format. For more
      information on Arista LANZ

      - <https://www.arista.com/en/um-eos/eos-latency-analyzer-lanz>

      This plugin uses Arista's sdk.

      - <https://github.com/aristanetworks/goarista>
    introduced: 
    tags: []
  - name: LDAP
    id: ldap
    description: |
      This plugin gathers metrics from LDAP servers' monitoring (`cn=Monitor`)
      backend. Currently this plugin supports
      [OpenLDAP](https://www.openldap.org/) and
      [389ds](https://www.port389.org/) servers.
    introduced: 
    tags: []
  - name: LeoFS
    id: leofs
    description: |
      The LeoFS plugin gathers metrics of LeoGateway, LeoManager, and
      LeoStorage using SNMP. See [LeoFS Documentation / System Administration /
      System
      Monitoring](https://leo-project.net/leofs/docs/admin/system_admin/monitoring/).
    introduced: 
    tags: []
  - name: Libvirt
    id: libvirt
    description: |
      The `libvirt` plugin collects statistics about virtualized guests on a
      system by using virtualization libvirt API, created by RedHat's Emerging
      Technology group. Metrics are gathered directly from the hypervisor on a
      host system, which means that Telegraf doesn't have to be installed and
      configured on a guest system.
    introduced: 
    tags: []
  - name: Linux CPU
    id: linux_cpu
    description: |
      The `linux_cpu` plugin gathers CPU metrics exposed on Linux-based
      systems.
    introduced: 
    tags: []
  - name: Linux Sysctl FS
    id: linux_sysctl_fs
    description: |
      The linux_sysctl_fs input provides Linux system level file metrics. The
      documentation on these fields can be found at
      <https://www.kernel.org/doc/Documentation/sysctl/fs.txt>.

      Example output:
    introduced: 
    tags: []
  - name: Logparser
    id: logparser
    description: |
      **Deprecated in Telegraf 1.15: Please use the
      [tail](/telegraf/v1/plugins/#input-tail) plugin along with the [`grok`
      data format]()**

      The `logparser` plugin streams and parses the given logfiles. Currently
      it has the capability of parsing "grok" patterns from logfiles, which
      also supports regex patterns.

      The `tail` plugin now provides all the functionality of the `logparser`
      plugin. Most options can be translated directly to the `tail` plugin:

      - For options in the `[inputs.logparser.grok]` section, the equivalent
      option will have add the `grok_` prefix when using them in the `tail`
      input.
      - The grok `measurement` option can be replaced using the standard plugin
      `name_override` option.

      This plugin also supports metric filtering and some additional common
      options.
    introduced: 
    tags: []
  - name: Logstash
    id: logstash
    description: |
      This plugin reads metrics exposed by [Logstash Monitoring
      API](https://www.elastic.co/guide/en/logstash/current/monitoring-logstash.html).

      Logstash 5 and later is supported.
    introduced: 
    tags: []
  - name: Lustre
    id: lustre2
    description: |
      The [Lustre](http://lustre.org/)® file system is an open-source,
      parallel file system that supports many requirements of leadership class
      HPC simulation environments.

      This plugin monitors the Lustre file system using its entries in the proc
      filesystem.
    introduced: 
    tags: []
  - name: LVM
    id: lvm
    description: |
      The Logical Volume Management (LVM) input plugin collects information
      about physical volumes, volume groups, and logical volumes.
    introduced: 
    tags: []
  - name: Mailchimp
    id: mailchimp
    description: |
      Pulls campaign reports from the [Mailchimp
      API](https://developer.mailchimp.com/).
    introduced: 
    tags: []
  - name: MarkLogic
    id: marklogic
    description: |
      The MarkLogic Telegraf plugin gathers health status metrics from one or
      more host.
    introduced: 
    tags: []
  - name: Mcrouter
    id: mcrouter
    description: |
      This plugin gathers statistics data from a Mcrouter server.
    introduced: 
    tags: []
  - name: mdstat
    id: mdstat
    description: |
      The mdstat plugin gathers statistics about any Linux MD RAID arrays
      configured on the host by reading /proc/mdstat. For a full list of
      available fields see the /proc/mdstat section of the [proc man
      page](http://man7.org/linux/man-pages/man5/proc.5.html). For a better
      idea of what each field represents, see the [mdstat man
      page](https://raid.wiki.kernel.org/index.php/Mdstat).

      Stat collection based on Prometheus' [mdstat collection
      library](https://github.com/prometheus/procfs/blob/master/mdstat.go).
    introduced: 
    tags: []
  - name: Memory
    id: mem
    description: |
      The mem plugin collects system memory metrics.

      For a more complete explanation of the difference between *used* and
      *actual_used* RAM, see [Linux ate my ram](http://www.linuxatemyram.com/).
    introduced: 
    tags: []
  - name: Memcached
    id: memcached
    description: |
      This plugin gathers statistics data from a Memcached server.
    introduced: 
    tags: []
  - name: Mesos
    id: mesos
    description: |
      This input plugin gathers metrics from Mesos. For more information,
      please check the [Mesos Observability
      Metrics](http://mesos.apache.org/documentation/latest/monitoring/) page.
    introduced: 
    tags: []
  - name: Minecraft
    id: minecraft
    description: |
      The `minecraft` plugin connects to a Minecraft server using the RCON
      protocol to collects scores from the server
      [scoreboard](http://minecraft.gamepedia.com/Scoreboard).

      This plugin is known to support Minecraft Java Edition versions 1.11 -
      1.14. When using an version of Minecraft earlier than 1.13, be aware that
      the values for some criterion has changed and may need to be modified.
    introduced: 
    tags: []
  - name: Mock Data
    id: mock
    description: |
      The mock input plugin generates random data based on a selection of
      different algorithms. For example, it can produce random data between a
      set of values, fake stock data, sine waves, and step-wise values.

      Additionally, users can set the measurement name and tags used to
      whatever is required to mock their situation.
    introduced: 
    tags: []
  - name: Modbus
    id: modbus
    description: |
      The Modbus plugin collects Discrete Inputs, Coils, Input Registers and
      Holding Registers via Modbus TCP or Modbus RTU/ASCII.
    introduced: 
    tags: []
  - name: MongoDB
    id: mongodb
    description: |
      See the [MongoDB Software Lifecycle
      Schedules](https://www.mongodb.com/support-policy/lifecycles) for
      supported versions.
    introduced: 
    tags: []
  - name: Monit
    id: monit
    description: |
      The `monit` plugin gathers metrics and status information about local
      processes, remote hosts, file, file systems, directories and network
      interfaces managed and watched over by [Monit](https://mmonit.com/).

      The use this plugin you should first enable the [HTTPD TCP
      port](https://mmonit.com/monit/documentation/monit.html#TCP-PORT) in
      Monit.

      Minimum Version of Monit tested with is 5.16.
    introduced: 
    tags: []
  - name: MQTT Consumer
    id: mqtt_consumer
    description: |
      The [MQTT](https://mqtt.org) consumer plugin reads from the specified
      MQTT topics and creates metrics using one of the supported [input data
      formats](/telegraf/v1/data_formats/input).
    introduced: 
    tags: []
  - name: Multifile
    id: multifile
    description: |
      The multifile input plugin allows Telegraf to combine data from multiple
      files into a single metric, creating one field or tag per file. This is
      often useful creating custom metrics from the `/sys` or `/proc`
      filesystems.

      > Note: If you wish to parse metrics from a single file formatted in one
      > of the supported [input data formats](/telegraf/v1/data_formats/input),
      > you should use the [file](/telegraf/v1/plugins/#input-file) input plugin
      > instead.
    introduced: 
    tags: []
  - name: MySQL
    id: mysql
    description: |
      This plugin gathers the statistic data from MySQL server

      * Global statuses
      * Global variables
      * Slave statuses
      * Binlog size
      * Process list
      * User Statistics
      * Info schema auto increment columns
      * InnoDB metrics
      * Table I/O waits
      * Index I/O waits
      * Perf Schema table lock waits
      * Perf Schema event waits
      * Perf Schema events statements
      * File events statistics
      * Table schema statistics

      In order to gather metrics from the performance schema, it must first be
      enabled in mySQL configuration. See the performance schema [quick
      start](https://dev.mysql.com/doc/refman/8.0/en/performance-schema-quick-start.html).
    introduced: 
    tags: []
  - name: NATS
    id: nats
    description: |
      The [NATS](http://www.nats.io/about/) monitoring plugin gathers metrics
      from the NATS [monitoring http
      server](https://docs.nats.io/running-a-nats-service/nats_admin/monitoring).
    introduced: 
    tags: []
  - name: NATS Consumer
    id: nats_consumer
    description: |
      The [NATS](https://www.nats.io/about/) consumer plugin reads from the
      specified NATS subjects and creates metrics using one of the supported
      [input data formats](/telegraf/v1/data_formats/input).

      A [Queue
      Group](https://www.nats.io/documentation/concepts/nats-queueing/) is used
      when subscribing to subjects so multiple instances of telegraf can read
      from a NATS cluster in parallel.

      There are three methods of (optionally) authenticating with NATS:
      [username/password](https://docs.nats.io/using-nats/developer/connecting/userpass),
      [a NATS creds
      file](https://docs.nats.io/using-nats/developer/connecting/creds) (NATS
      2.0), or an [nkey seed
      file](https://docs.nats.io/using-nats/developer/connecting/nkey) (NATS
      2.0).
    introduced: 
    tags: []
  - name: Neoom Beaam
    id: neoom_beaam
    description: |
      This plugin reads metrics from the Neoom Beaam gateway using the [Beaam
      API](https://developer.neoom.com/reference/concepts-terms-1). Usually an
      access token is required which can be created in the Neoom web interface.
      Please follow the [developer instructions](https://neoom.com/developers)
      to create the token!
    introduced: 
    tags: []
  - name: Neptune Apex
    id: neptune_apex
    description: |
      The Neptune Apex controller family allows an aquarium hobbyist to monitor
      and control their tanks based on various probes. The data is taken
      directly from the `/cgi-bin/status.xml` at the interval specified in the
      telegraf.conf configuration file.

      The [Neptune Apex](https://www.neptunesystems.com/) input plugin collects
      real-time data from the Apex's status.xml page.
    introduced: 
    tags: []
  - name: Net
    id: net
    description: |
      This plugin gathers metrics about network interface and protocol usage
      (Linux only).
    introduced: 
    tags: []
  - name: Network Response
    id: net_response
    description: |
      The input plugin test UDP/TCP connections response time and can optional
      verify text in the response.
    introduced: 
    tags: []
  - name: Netflow
    id: netflow
    description: |
      The `netflow` plugin acts as a collector for Netflow v5, Netflow v9 and
      IPFIX flow information. The Layer 4 protocol numbers are gathered from
      the [official IANA
      assignments](https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml).
      The internal field mappings for Netflow v5 fields are defined according
      to [Cisco's Netflow v5
      documentation](https://www.cisco.com/c/en/us/td/docs/net_mgmt/netflow_collection_engine/3-6/user/guide/format.html#wp1006186),
      Netflow v9 fields are defined according to [Cisco's Netflow v9
      documentation](https://www.cisco.com/en/US/technologies/tk648/tk362/technologies_white_paper09186a00800a3db9.html)
      and the [ASA
      extensions](https://www.cisco.com/c/en/us/td/docs/security/asa/special/netflow/asa_netflow.html).
      Definitions for IPFIX are according to [IANA assignment
      document](https://www.iana.org/assignments/ipfix/ipfix.xhtml#ipfix-nat-type).
    introduced: 
    tags: []
  - name: Netstat
    id: netstat
    description: |
      This plugin collects TCP connections state and UDP socket counts by using
      `lsof`.
    introduced: 
    tags: []
  - name: NFS Client
    id: nfsclient
    description: |
      The NFS Client input plugin collects data from /proc/self/mountstats. By
      default, only a limited number of general system-level metrics are
      collected, including basic read/write counts. If `fullstat` is set, a
      great deal of additional metrics are collected, detailed below.

      __NOTE__ Many of the metrics, even if tagged with a mount point, are
      really _per-server_. Thus, if you mount these two shares:
      `nfs01:/vol/foo/bar` and `nfs01:/vol/foo/baz`, there will be two near
      identical entries in /proc/self/mountstats. This is a limitation of the
      metrics exposed by the kernel, not the telegraf plugin.
    introduced: 
    tags: []
  - name: Nginx
    id: nginx
    description: |
      This plugin gathers basic status from the open source web server Nginx.
      Nginx Plus is a commercial version. For more information about the
      differences between Nginx (F/OSS) and Nginx Plus, see the Nginx
      [documentation](https://www.nginx.com/blog/whats-difference-nginx-foss-nginx-plus/).
    introduced: 
    tags: []
  - name: Nginx Plus
    id: nginx_plus
    description: |
      Nginx Plus is a commercial version of the open source web server Nginx.
      The use this plugin you will need a license. For more information about
      the differences between Nginx (F/OSS) and Nginx Plus, see the Nginx
      [documentation](https://www.nginx.com/blog/whats-difference-nginx-foss-nginx-plus/).

      Structures for Nginx Plus have been built based on history of [status
      module documentation]().
    introduced: 
    tags: []
  - name: Nginx Plus API
    id: nginx_plus_api
    description: |
      Nginx Plus is a commercial version of the open source web server Nginx.
      The use this plugin you will need a license. For more information about
      the differences between Nginx (F/OSS) and Nginx Plus, see the Nginx
      [documentation](https://www.nginx.com/blog/whats-difference-nginx-foss-nginx-plus/).
    introduced: 
    tags: []
  - name: Nginx Stream STS
    id: nginx_sts
    description: |
      This plugin gathers Nginx status using external virtual host traffic
      status module - <https://github.com/vozlt/nginx-module-sts>. This is an
      Nginx module that provides access to stream host status information. It
      contains the current status such as servers, upstreams, caches. This is
      similar to the live activity monitoring of Nginx plus. For module
      configuration details please see its
      [documentation](https://github.com/vozlt/nginx-module-sts#synopsis).

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Nginx Upstream Check
    id: nginx_upstream_check
    description: |
      Read the status output of the [nginx_upstream_check](). This module can
      periodically check the servers in the Nginx's upstream with configured
      request and interval to determine if the server is still available. If
      checks are failed the server is marked as "down" and will not receive any
      requests until the check will pass and a server will be marked as "up"
      again.

      The status page displays the current status of all upstreams and servers
      as well as number of the failed and successful checks. This information
      can be exported in JSON format and parsed by this input.
    introduced: 
    tags: []
  - name: Nginx Virtual Host Traffic (VTS)
    id: nginx_vts
    description: |
      This plugin gathers Nginx status using external virtual host traffic
      status module - <https://github.com/vozlt/nginx-module-vts>. This is an
      Nginx module that provides access to virtual host status information. It
      contains the current status such as servers, upstreams, caches. This is
      similar to the live activity monitoring of Nginx plus. For module
      configuration details please see its
      [documentation](https://github.com/vozlt/nginx-module-vts#synopsis).
    introduced: 
    tags: []
  - name: Hashicorp Nomad
    id: nomad
    description: |
      The Nomad plugin must grab metrics from every Nomad agent of the cluster.
      Telegraf may be present in every node and connect to the agent locally.
      In this case should be something like `http://127.0.0.1:4646`.

      > Tested on Nomad 1.1.6
    introduced: 
    tags: []
  - name: NSD
    id: nsd
    description: |
      This plugin gathers stats from
      [NSD](https://www.nlnetlabs.nl/projects/nsd/about) - an authoritative DNS
      name server.
    introduced: 
    tags: []
  - name: NSQ
    id: nsq
    description: |
      This plugin gathers metrics from [NSQ](https://nsq.io/).

      See the [NSQD API docs](https://nsq.io/components/nsqd.html) for
      endpoints that the plugin can read.
    introduced: 
    tags: []
  - name: NSQ Consumer
    id: nsq_consumer
    description: |
      The [NSQ](https://nsq.io) consumer plugin reads from NSQD and creates
      metrics using one of the supported [input data
      formats](/telegraf/v1/data_formats/input).
    introduced: 
    tags: []
  - name: Nstat
    id: nstat
    description: |
      Plugin collects network metrics from `/proc/net/netstat`,
      `/proc/net/snmp` and `/proc/net/snmp6` files
    introduced: 
    tags: []
  - name: ntpq
    id: ntpq
    description: |
      Get standard NTP query metrics, requires ntpq executable.

      Below is the documentation of the various headers returned from the NTP
      query command when running `ntpq -p`.

      - remote – The remote peer or server being synced to. “LOCAL” is
      this local host (included in case there are no remote peers or servers
      available);
      - refid – Where or what the remote peer or server is itself synchronised
      to;
      - st (stratum) – The remote peer or server Stratum
      - t (type) – Type (u: unicast or manycast client, b: broadcast or
      multicast client, l: local reference clock, s: symmetric peer, A: manycast
      server, B: broadcast server, M: multicast server, see “Automatic Server
      Discovery“);
      - when – When last polled (seconds ago, “h” hours ago, or “d”
      days ago);
      - poll – Polling frequency: rfc5905 suggests this ranges in NTPv4 from 4
      (16s) to 17 (36h) (log2 seconds), however observation suggests the actual
      displayed value is seconds for a much smaller range of 64 (26) to 1024
      (210) seconds;
      - reach – An 8-bit left-shift shift register value recording polls (bit
      set = successful, bit reset = fail) displayed in octal;
      - delay – Round trip communication delay to the remote peer or server
      (milliseconds);
      - offset – Mean offset (phase) in the times reported between this local
      host and the remote peer or server (RMS, milliseconds);
      - jitter – Mean deviation (jitter) in the time reported for that remote
      peer or server (RMS of difference of multiple time samples, milliseconds);
    introduced: 
    tags: []
  - name: Nvidia System Management Interface (SMI)
    id: nvidia_smi
    description: |
      This plugin uses a query on the
      [`nvidia-smi`](https://developer.nvidia.com/nvidia-system-management-interface)
      binary to pull GPU stats including memory and GPU usage, temp and other.
    introduced: 
    tags: []
  - name: OPC UA Client Reader
    id: opcua
    description: |
      The `opcua` plugin retrieves data from OPC UA Server devices.

      Telegraf minimum version: Telegraf 1.16 Plugin minimum tested version:
      1.16
    introduced: 
    tags: []
  - name: OPC UA Client Listener
    id: opcua_listener
    description: |
      The `opcua_listener` plugin subscribes to data from OPC UA Server
      devices.

      Telegraf minimum version: Telegraf 1.25 Plugin minimum tested version:
      1.25
    introduced: 
    tags: []
  - name: OpenLDAP
    id: openldap
    description: |
      This plugin gathers metrics from OpenLDAP's cn=Monitor backend.
    introduced: 
    tags: []
  - name: OpenNTPD
    id: openntpd
    description: |
      Get standard NTP query metrics from [OpenNTPD](http://www.openntpd.org/)
      using the ntpctl command.

      Below is the documentation of the various headers returned from the NTP
      query command when running `ntpctl -s peers`.

      - remote – The remote peer or server being synced to.
      - wt – the peer weight
      - tl – the peer trust level
      - st (stratum) – The remote peer or server Stratum
      - next – number of seconds until the next poll
      - poll – polling interval in seconds
      - delay – Round trip communication delay to the remote peer or server
      (milliseconds);
      - offset – Mean offset (phase) in the times reported between this local
      host and the remote peer or server (RMS, milliseconds);
      - jitter – Mean deviation (jitter) in the time reported for that remote
      peer or server (RMS of difference of multiple time samples, milliseconds);
    introduced: 
    tags: []
  - name: OpenSearch Query
    id: opensearch_query
    description: |
      This [OpenSearch](https://opensearch.org/) plugin queries endpoints to
      derive metrics from data stored in an OpenSearch cluster.

      The following is supported:

      - return number of hits for a search query
      - calculate the `avg`/`max`/`min`/`sum` for a numeric field, filtered by a
      query, aggregated per tag
      - `value_count` returns the number of documents for a particular field
      - `stats` (returns `sum`, `min`, `max`, `avg`, and `value_count` in one
      query)
      - extended_stats (`stats` plus stats such as sum of squares, variance, and
      standard deviation)
      - `percentiles` returns the 1st, 5th, 25th, 50th, 75th, 95th, and 99th
      percentiles
    introduced: 
    tags: []
  - name: OpenSMTPD
    id: opensmtpd
    description: |
      This plugin gathers stats from [OpenSMTPD - a FREE implementation of the
      server-side SMTP protocol](https://www.opensmtpd.org/)
    introduced: 
    tags: []
  - name: OpenStack
    id: openstack
    description: |
      Collects the metrics from following services of OpenStack:

      * CINDER(Block Storage)
      * GLANCE(Image service)
      * HEAT(Orchestration)
      * KEYSTONE(Identity service)
      * NEUTRON(Networking)
      * NOVA(Compute Service)

      At present this plugin requires the following APIs:

      * blockstorage v3
      * compute v2
      * identity v3
      * networking v2
      * orchestration v1
    introduced: 
    tags: []
  - name: OpenTelemetry
    id: opentelemetry
    description: |
      This plugin receives traces, metrics and logs from
      [OpenTelemetry](https://opentelemetry.io) clients and agents via gRPC.
    introduced: 
    tags: []
  - name: OpenWeatherMap
    id: openweathermap
    description: |
      Collect current weather and forecast data from OpenWeatherMap.

      To use this plugin you will need an [api
      key](https://openweathermap.org/appid) (app_id).

      City identifiers can be found in the [city
      list](http://bulk.openweathermap.org/sample/city.list.json.gz).
      Alternately you can [search](https://openweathermap.org/find) by name;
      the `city_id` can be found as the last digits of the URL:
      <https://openweathermap.org/city/2643743>. Language identifiers can be
      found in the [lang list](https://openweathermap.org/current#multi).
      Documentation for condition ID, icon, and main is at [weather
      conditions](https://openweathermap.org/weather-conditions).
    introduced: 
    tags: []
  - name: P4 Runtime
    id: p4runtime
    description: |
      P4 is a language for programming the data plane of network devices, such
      as Programmable Switches or Programmable Network Interface Cards. The
      P4Runtime API is a control plane specification to manage the data plane
      elements of those devices dynamically by a P4 program.

      The `p4runtime` plugin gathers metrics about `Counter` values present in
      P4 Program loaded onto networking device. Metrics are collected through
      gRPC connection with [P4Runtime](https://github.com/p4lang/p4runtime)
      server.

      P4Runtime Plugin uses `PkgInfo.Name` field. If user wants to gather
      information about program name, please follow [6.2.1. Annotating P4 code
      with PkgInfo] instruction and apply changes to your P4 program.
    introduced: 
    tags: []
  - name: Passenger
    id: passenger
    description: |
      Gather [Phusion Passenger](https://www.phusionpassenger.com/) metrics
      using the `passenger-status` command line utility.
    introduced: 
    tags: []
  - name: PF
    id: pf
    description: |
      The pf plugin gathers information from the FreeBSD/OpenBSD pf firewall.
      Currently it can retrieve information about the state table: the number
      of current entries in the table, and counters for the number of searches,
      inserts, and removals to the table.

      The pf plugin retrieves this information by invoking the `pfstat`
      command. The `pfstat` command requires read access to the device file
      `/dev/pf`. You have several options to permit telegraf to run `pfctl`:

      * Run telegraf as root. This is strongly discouraged.
      * Change the ownership and permissions for /dev/pf such that the user
      telegraf runs at can read the /dev/pf device file. This is probably not
      that good of an idea either.
      * Configure sudo to grant telegraf to run `pfctl` as root. This is the
      most restrictive option, but require sudo setup.
      * Add "telegraf" to the "proxy" group as /dev/pf is owned by root:proxy.
    introduced: 
    tags: []
  - name: PgBouncer
    id: pgbouncer
    description: |
      The `pgbouncer` plugin provides metrics for your PgBouncer load balancer.

      More information about the meaning of these metrics can be found in the
      [PgBouncer Documentation](https://pgbouncer.github.io/usage.html).

      - PgBouncer minimum tested version: 1.5
    introduced: 
    tags: []
  - name: PHP-FPM
    id: phpfpm
    description: |
      Get phpfpm stats using either HTTP status page or fpm socket.
    introduced: 
    tags: []
  - name: Ping
    id: ping
    description: |
      Sends a ping message by executing the system ping command and reports the
      results.

      This plugin has two main methods of operation: `exec` and `native`. The
      recommended method is `native`, which has greater system compatibility
      and performance. However, for backwards compatibility the `exec` method
      is the default.

      When using `method = "exec"`, the systems ping utility is executed to
      send the ping packets.

      Most ping command implementations are supported, one notable exception
      being that there is currently no support for GNU Inetutils ping. You may
      instead use the iputils-ping implementation:

      When using `method = "native"` a ping is sent and the results are
      reported in native Go by the Telegraf process, eliminating the need to
      execute the system `ping` command.
    introduced: 
    tags: []
  - name: Postfix
    id: postfix
    description: |
      The postfix plugin reports metrics on the postfix queues.

      For each of the active, hold, incoming, maildrop, and deferred queues
      (<http://www.postfix.org/QSHAPE_README.html#queues>), it will report the
      queue length (number of items), size (bytes used by items), and age (age
      of oldest item in seconds).
    introduced: 
    tags: []
  - name: PostgreSQL
    id: postgresql
    description: |
      The `postgresql` plugin provides metrics for your PostgreSQL Server
      instance. Recorded metrics are lightweight and use Dynamic Management
      Views supplied by PostgreSQL.
    introduced: 
    tags: []
  - name: PostgreSQL Extensible
    id: postgresql_extensible
    description: |
      This postgresql plugin provides metrics for your postgres database. It
      has been designed to parse SQL queries in the plugin section of your
      `telegraf.conf`.

      The example below has two queries are specified, with the following
      parameters:

      * The SQL query itself
      * The minimum PostgreSQL version supported (the numeric display visible in
      pg_settings)
      * A boolean to define if the query has to be run against some specific
      database (defined in the `databases` variable of the plugin section)
      * The name of the measurement
      * A list of the columns to be defined as tags
    introduced: 
    tags: []
  - name: PowerDNS
    id: powerdns
    description: |
      The powerdns plugin gathers metrics about PowerDNS using unix socket.
    introduced: 
    tags: []
  - name: PowerDNS Recursor
    id: powerdns_recursor
    description: |
      The `powerdns_recursor` plugin gathers metrics about PowerDNS Recursor
      using the unix controlsocket.
    introduced: 
    tags: []
  - name: Processes
    id: processes
    description: |
      This plugin gathers info about the total number of processes and groups
      them by status (zombie, sleeping, running, etc.)

      On linux this plugin requires access to procfs (/proc), on other OSes it
      requires access to execute `ps`.

      **Supported Platforms**: Linux, FreeBSD, Darwin
    introduced: 
    tags: []
  - name: Procstat
    id: procstat
    description: |
      The procstat plugin can be used to monitor the system resource usage of
      one or more processes. The procstat_lookup metric displays the query
      information, specifically the number of PIDs returned on a search

      Processes can be selected for monitoring using one of several methods:

      - pidfile
      - exe
      - pattern
      - user
      - systemd_unit
      - cgroup
      - supervisor_unit
      - win_service
    introduced: 
    tags: []
  - name: Prometheus
    id: prometheus
    description: |
      The prometheus input plugin gathers metrics from HTTP servers exposing
      metrics in Prometheus format.
    introduced: 
    tags: []
  - name: Proxmox
    id: proxmox
    description: |
      The proxmox plugin gathers metrics about containers and VMs using the
      Proxmox API.

      Telegraf minimum version: Telegraf 1.16.0
    introduced: 
    tags: []
  - name: PuppetAgent
    id: puppetagent
    description: |
      The puppetagent plugin collects variables outputted from the
      'last_run_summary.yaml' file usually located in `/var/lib/puppet/state/`
      [PuppetAgent
      Runs](https://puppet.com/blog/puppet-monitoring-how-to-monitor-success-or-failure-of-puppet-runs/).
    introduced: 
    tags: []
  - name: RabbitMQ
    id: rabbitmq
    description: |
      Reads metrics from RabbitMQ servers via the [Management
      Plugin](https://www.rabbitmq.com/management.html).

      For additional details reference the [RabbitMQ Management HTTP Stats]().
    introduced: 
    tags: []
  - name: Radius
    id: radius
    description: |
      The Radius plugin collects radius authentication response times.
    introduced: 
    tags: []
  - name: Raindrops
    id: raindrops
    description: |
      The [raindrops](http://raindrops.bogomips.org/) plugin reads from
      specified raindops
      [middleware](http://raindrops.bogomips.org/Raindrops/Middleware.html) URI
      and adds stats to InfluxDB.
    introduced: 
    tags: []
  - name: RAS Daemon
    id: ras
    description: |
      This plugin is only available on Linux (only for `386`, `amd64`, `arm`
      and `arm64` architectures).

      The `RAS` plugin gathers and counts errors provided by
      [RASDaemon](https://github.com/mchehab/rasdaemon).
    introduced: 
    tags: []
  - name: RavenDB
    id: ravendb
    description: |
      Reads metrics from RavenDB servers via monitoring endpoints APIs.

      Requires RavenDB Server 5.2+.
    introduced: 
    tags: []
  - name: Redfish
    id: redfish
    description: |
      The `redfish` plugin gathers metrics and status information about CPU
      temperature, fanspeed, Powersupply, voltage, hostname and Location
      details (datacenter, placement, rack and room) of hardware servers for
      which [DMTF's Redfish](https://redfish.dmtf.org/) is enabled.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Redis
    id: redis
    description: |
      The Redis input plugin gathers metrics from one or many Redis servers.
    introduced: 
    tags: []
  - name: Redis Sentinel
    id: redis_sentinel
    description: |
      A plugin for Redis Sentinel to monitor multiple Sentinel instances that
      are monitoring multiple Redis servers and replicas.
    introduced: 
    tags: []
  - name: RethinkDB
    id: rethinkdb
    description: |
      Collect metrics from [RethinkDB](https://www.rethinkdb.com/).
    introduced: 
    tags: []
  - name: Riak
    id: riak
    description: |
      The Riak plugin gathers metrics from one or more riak instances.
    introduced: 
    tags: []
  - name: Riemann Listener
    id: riemann_listener
    description: |
      The Riemann Listener is a simple input plugin that listens for messages
      from client that use riemann clients using riemann-protobuff format.
    introduced: 
    tags: []
  - name: Siemens S7
    id: s7comm
    description: |
      This plugin reads metrics from Siemens PLCs via the S7 protocol.
    introduced: 
    tags: []
  - name: Salesforce
    id: salesforce
    description: |
      The Salesforce plugin gathers metrics about the limits in your Salesforce
      organization and the remaining usage. It fetches its data from the
      [limits endpoint]() of Salesforce's REST API.
    introduced: 
    tags: []
  - name: LM Sensors
    id: sensors
    description: |
      Collect [lm-sensors](https://en.wikipedia.org/wiki/Lm_sensors) metrics -
      requires the lm-sensors package installed.

      This plugin collects sensor metrics with the `sensors` executable from
      the lm-sensor package.
    introduced: 
    tags: []
  - name: SFlow
    id: sflow
    description: |
      The SFlow Input Plugin provides support for acting as an SFlow V5
      collector in accordance with the specification from
      [sflow.org](https://sflow.org/).

      Currently only Flow Samples of Ethernet / IPv4 & IPv4 TCP & UDP headers
      are turned into metrics. Counters and other header samples are ignored.
    introduced: 
    tags: []
  - name: Slab
    id: slab
    description: |
      This plugin collects details on how much memory each entry in Slab cache
      is consuming. For example, it collects the consumption of `kmalloc-1024`
      and `xfs_inode`. Since this information is obtained by parsing
      `/proc/slabinfo` file, only Linux is supported. The specification of
      `/proc/slabinfo` has not changed since [Linux v2.6.12 (April
      2005)](https://github.com/torvalds/linux/blob/1da177e4/mm/slab.c#L2848-L2861),
      so it can be regarded as sufficiently stable. The memory usage is
      equivalent to the `CACHE_SIZE` column of `slabtop` command. If the
      HOST_PROC environment variable is set, Telegraf will use its value
      instead of `/proc`

      **Note: `/proc/slabinfo` is usually restricted to read as root user. Make
      sure telegraf can execute `sudo` without password.**
    introduced: 
    tags: []
  - name: SLURM
    id: slurm
    description: |
      This plugin gather diag, jobs, nodes, partitions and reservation metrics
      by leveraging SLURM's REST API as provided by the `slurmrestd` daemon.

      This plugin targets the `openapi/v0.0.38` OpenAPI plugin as defined in
      SLURM's documentation. That particular plugin should be configured when
      starting the `slurmrestd` daemon up. For more information, be sure to
      check SLURM's documentation [here](https://slurm.schedmd.com/rest.html).

      A great wealth of information can also be found on the repository of the
      Go module implementing the API client,
      [pcolladosoto/goslurm](https://github.com/pcolladosoto/goslurm).
    introduced: 
    tags: []
  - name: S.M.A.R.T.
    id: smart
    description: |
      Get metrics using the command line utility `smartctl` for S.M.A.R.T.
      (Self-Monitoring, Analysis and Reporting Technology) storage devices.
      SMART is a monitoring system included in computer hard disk drives (HDDs)
      and solid-state drives (SSDs) that detects and reports on various
      indicators of drive reliability, with the intent of enabling the
      anticipation of hardware failures. See smartmontools
      (<https://www.smartmontools.org/>).

      SMART information is separated between different measurements:
      `smart_device` is used for general information, while `smart_attribute`
      stores the detailed attribute information if `attributes = true` is
      enabled in the plugin configuration.

      If no devices are specified, the plugin will scan for SMART devices via
      the following command:

      Metrics will be reported from the following `smartctl` command:

      This plugin supports _smartmontools_ version 5.41 and above, but v. 5.41
      and v. 5.42 might require setting `nocheck`, see the comment in the
      sample configuration. Also, NVMe capabilities were introduced in version
      6.5.

      To enable SMART on a storage device run:
    introduced: 
    tags: []
  - name: smartctl JSON
    id: smartctl
    description: |
      Get metrics using the command line utility `smartctl` for S.M.A.R.T.
      (Self-Monitoring, Analysis and Reporting Technology) storage devices.
      SMART is a monitoring system included in computer hard disk drives
      (HDDs), solid-state drives (SSDs), and nVME drives that detects and
      reports on various indicators of drive reliability, with the intent of
      enabling the anticipation of hardware failures.

      This version of the plugin requires support of the JSON flag from the
      `smartctl` command. This flag was added in 7.0 (2019) and further
      enhanced in subsequent releases.

      See smartmontools (<https://www.smartmontools.org/>) for more
      information.
    introduced: 
    tags: []
  - name: SNMP
    id: snmp
    description: |
      The `snmp` input plugin uses polling to gather metrics from SNMP agents.
      Support for gathering individual OIDs as well as complete SNMP tables is
      included.
    introduced: 
    tags: []
  - name: SNMP Trap
    id: snmp_trap
    description: |
      The SNMP Trap plugin is a service input plugin that receives SNMP
      notifications (traps and inform requests).

      Notifications are received on plain UDP. The port to listen is
      configurable.
    introduced: 
    tags: []
  - name: Socket Listener
    id: socket_listener
    description: |
      The Socket Listener is a service input plugin that listens for messages
      from streaming (tcp, unix) or datagram (udp, unixgram) protocols.

      The plugin expects messages in the Telegraf Input Data Formats.
    introduced: 
    tags: []
  - name: SocketStat
    id: socketstat
    description: |
      The socketstat plugin gathers indicators from established connections,
      using iproute2's `ss` command.

      The `ss` command does not require specific privileges.

      **WARNING: The output format will produce series with very high
      cardinality.** You should either store those by an engine which doesn't
      suffer from it, use a short retention policy or do appropriate filtering.
    introduced: 
    tags: []
  - name: Solr
    id: solr
    description: |
      The [solr](http://lucene.apache.org/solr/) plugin collects stats via the
      [MBean Request Handler]().

      More about [performance
      statistics](https://cwiki.apache.org/confluence/display/solr/Performance+Statistics+Reference).

      Tested from 3.5 to 9.3
    introduced: 
    tags: []
  - name: SQL
    id: sql
    description: |
      This plugin reads metrics from performing SQL queries against a SQL
      server. Different server types are supported and their settings might
      differ (especially the connection parameters). Please check the list of
      supported SQL drivers options.
    introduced: 
    tags: []
  - name: SQL Server
    id: sqlserver
    description: |
      The `sqlserver` plugin provides metrics for your SQL Server instance.
      Recorded metrics are lightweight and use Dynamic Management Views
      supplied by SQL Server.
    introduced: 
    tags: []
  - name: Stackdriver Google Cloud Monitoring
    id: stackdriver
    description: |
      Query data from Google Cloud Monitoring (formerly Stackdriver) using the
      [Cloud Monitoring API v3](https://cloud.google.com/monitoring/api/v3/).

      This plugin accesses APIs which are
      [chargeable](https://cloud.google.com/stackdriver/pricing#stackdriver_monitoring_services);
      you might incur costs.
    introduced: 
    tags: []
  - name: StatsD
    id: statsd
    description: |
      The StatsD input plugin gathers metrics from a Statsd server.
    introduced: 
    tags: []
  - name: Supervisor
    id: supervisor
    description: |
      This plugin gathers information about processes that running under
      supervisor using XML-RPC API.

      Minimum tested version of supervisor: 3.3.2
    introduced: 
    tags: []
  - name: Suricata
    id: suricata
    description: |
      This plugin reports internal performance counters of the Suricata IDS/IPS
      engine, such as captured traffic volume, memory usage, uptime, flow
      counters, and much more. It provides a socket for the Suricata log output
      to write JSON stats output to, and processes the incoming data to fit
      Telegraf's format. It can also report for triggered Suricata IDS/IPS
      alerts.
    introduced: 
    tags: []
  - name: Swap
    id: swap
    description: |
      The swap plugin collects system swap metrics. This plugin ONLY supports
      Linux.

      For more information on what swap memory is, read [All about Linux swap
      space](https://www.linux.com/news/all-about-linux-swap-space).
    introduced: 
    tags: []
  - name: Synproxy
    id: synproxy
    description: |
      The synproxy plugin gathers the synproxy counters. Synproxy is a Linux
      netfilter module used for SYN attack mitigation. The use of synproxy is
      documented in `man iptables-extensions` under the SYNPROXY section.
    introduced: 
    tags: []
  - name: Syslog
    id: syslog
    description: |
      The syslog plugin listens for syslog messages transmitted over a Unix
      Domain socket, [UDP](https://tools.ietf.org/html/rfc5426),
      [TCP](https://tools.ietf.org/html/rfc6587), or
      [TLS](https://tools.ietf.org/html/rfc5425); with or without the octet
      counting framing.

      Syslog messages should be formatted according to [RFC
      5424](https://tools.ietf.org/html/rfc5424) (syslog protocol) or [RFC
      3164](https://tools.ietf.org/html/rfc3164) (BSD syslog protocol).
    introduced: 
    tags: []
  - name: sysstat
    id: sysstat
    description: |
      Collect [sysstat](https://github.com/sysstat/sysstat) metrics - requires
      the sysstat package installed.

      This plugin collects system metrics with the sysstat collector utility
      `sadc` and parses the created binary data file with the `sadf` utility.
    introduced: 
    tags: []
  - name: System
    id: system
    description: |
      The system plugin gathers general stats on system load, uptime, and
      number of users logged in. It is similar to the unix `uptime` command.

      Number of CPUs is obtained from the /proc/cpuinfo file.
    introduced: 
    tags: []
  - name: Systemd-Units
    id: systemd_units
    description: |
      This plugin gathers the status of systemd-units on Linux, using systemd's
      DBus interface.

      Please note: At least systemd v230 is required!
    introduced: 
    tags: []
  - name: Tacacs
    id: tacacs
    description: |
      The Tacacs plugin collects successful tacacs authentication response
      times from tacacs servers such as Aruba ClearPass, FreeRADIUS or tac_plus
      (TACACS+). It is primarily meant to monitor how long it takes for the
      server to fully handle an auth request, including all potential dependent
      calls (for example to AD servers, or other sources of truth for auth the
      tacacs server uses).
    introduced: 
    tags: []
  - name: Tail
    id: tail
    description: |
      The tail plugin "tails" a logfile and parses each log message.

      By default, the tail plugin acts like the following unix tail command:

      - `-F` means that it will follow the _name_ of the given file, so that it
      will be compatible with log-rotated files, and that it will retry on
      inaccessible files.
      - `--lines=0` means that it will start at the end of the file (unless the
      `from_beginning` option is set).

      see <http://man7.org/linux/man-pages/man1/tail.1.html> for more details.

      The plugin expects messages in one of the Telegraf Input Data Formats.
    introduced: 
    tags: []
  - name: Teamspeak 3
    id: teamspeak
    description: |
      This plugin uses the Teamspeak 3 ServerQuery interface of the Teamspeak
      server to collect statistics of one or more virtual servers. If you are
      querying an external Teamspeak server, make sure to add the host which is
      running Telegraf to query_ip_allowlist.txt in the Teamspeak Server
      directory. For information about how to configure the server take a look
      the [Teamspeak 3 ServerQuery Manual]().
    introduced: 
    tags: []
  - name: Temperature
    id: temp
    description: |
      The temp input plugin gather metrics on system temperature. This plugin
      is meant to be multi platform and uses platform specific collection
      methods.

      Currently supports Linux and Windows.
    introduced: 
    tags: []
  - name: Tengine
    id: tengine
    description: |
      The tengine plugin gathers metrics from the [Tengine Web
      Server](http://tengine.taobao.org/) via the
      [reqstat](http://tengine.taobao.org/document/http_reqstat.html) module.
    introduced: 
    tags: []
  - name: Tomcat
    id: tomcat
    description: |
      The Tomcat plugin collects statistics available from the tomcat manager
      status page from the `http://<host>/manager/status/all?XML=true URL.`
      (`XML=true` will return only xml data).

      See the [Tomcat
      documentation](https://tomcat.apache.org/tomcat-9.0-doc/manager-howto.html#Server_Status)
      for details of these statistics.
    introduced: 
    tags: []
  - name: Trig
    id: trig
    description: |
      The `trig` plugin is for demonstration purposes and inserts sine and
      cosine
    introduced: 
    tags: []
  - name: Twemproxy
    id: twemproxy
    description: |
      The `twemproxy` plugin gathers statistics from
      [Twemproxy](https://github.com/twitter/twemproxy) servers.
    introduced: 
    tags: []
  - name: Unbound
    id: unbound
    description: |
      This plugin gathers stats from [Unbound](https://www.unbound.net/) - a
      validating, recursive, and caching DNS resolver.
    introduced: 
    tags: []
  - name: UPSD
    id: upsd
    description: |
      This plugin reads data of one or more Uninterruptible Power Supplies from
      an `upsd` daemon using its NUT network protocol.
    introduced: 
    tags: []
  - name: uWSGI
    id: uwsgi
    description: |
      The uWSGI input plugin gathers metrics about uWSGI using its [Stats
      Server](https://uwsgi-docs.readthedocs.io/en/latest/StatsServer.html).
    introduced: 
    tags: []
  - name: Varnish
    id: varnish
    description: |
      This plugin gathers stats from [Varnish HTTP
      Cache](https://varnish-cache.org/)
    introduced: 
    tags: []
  - name: Hashicorp Vault
    id: vault
    description: |
      The Vault plugin could grab metrics from every Vault agent of the
      cluster. Telegraf may be present in every node and connect to the agent
      locally. In this case should be something like `http://127.0.0.1:8200`.

      > Tested on vault 1.8.5
    introduced: 
    tags: []
  - name: VMware vSphere
    id: vsphere
    description: |
      The VMware vSphere plugin uses the vSphere API to gather metrics from
      multiple vCenter servers.

      * Clusters
      * Hosts
      * Resource Pools
      * VMs
      * Datastores
      * vSAN
    introduced: 
    tags: []
  - name: Webhooks
    id: webhooks
    description: |
      This is a Telegraf service plugin that start a http server and register
      multiple webhook listeners.

      Change the config file to point to the InfluxDB server you are using and
      adjust the settings to match your environment. Once that is complete:
    introduced: 
    tags: []
  - name: Windows Eventlog
    id: win_eventlog
    description: |
      Telegraf's win_eventlog input plugin gathers metrics from the windows
      event log.
    introduced: 
    tags: []
  - name: Windows Performance Counters
    id: win_perf_counters
    description: |
      This document presents the input plugin to read Performance Counters on
      Windows operating systems.

      The configuration is parsed and then tested for validity, such as whether
      the Object, Instance and Counter exist on Telegraf startup.

      Counter paths are refreshed periodically, see the CountersRefreshInterval
      configuration parameter for more info.

      In case of query for all instances `["*"]`, the plugin does not return
      the instance `_Total` by default. See IncludeTotal for more info.
    introduced: 
    tags: []
  - name: Windows Services
    id: win_services
    description: |
      Reports information about Windows service status.

      Monitoring some services may require running Telegraf with administrator
      privileges.
    introduced: 
    tags: []
  - name: Windows Management Instrumentation
    id: win_wmi
    description: |
      This document presents the input plugin to read WMI classes on Windows
      operating systems. With the win_wmi plugin, it is possible to capture and
      filter virtually any configuration or metric value exposed through the
      Windows Management Instrumentation
      ([WMI](https://learn.microsoft.com/en-us/windows/win32/wmisdk/wmi-start-page))
      service. At minimum, the telegraf service user must have permission to
      [read](https://learn.microsoft.com/en-us/windows/win32/wmisdk/access-to-wmi-namespaces)
      the WMI namespace that is being queried.
    introduced: 
    tags: []
  - name: Wireguard
    id: wireguard
    description: |
      The Wireguard input plugin collects statistics on the local Wireguard
      server using the [`wgctrl`](https://github.com/WireGuard/wgctrl-go)
      library. It reports gauge metrics for Wireguard interface device(s) and
      its peers.
    introduced: 
    tags: []
  - name: Wireless
    id: wireless
    description: |
      The wireless plugin gathers metrics about wireless link quality by
      reading the `/proc/net/wireless` file. This plugin currently supports
      linux only.
    introduced: 
    tags: []
  - name: x509 Certificate
    id: x509_cert
    description: |
      This plugin provides information about X509 certificate accessible via
      local file, tcp, udp, https or smtp protocol.

      When using a UDP address as a certificate source, the server must support
      [DTLS](https://en.wikipedia.org/wiki/Datagram_Transport_Layer_Security).
    introduced: 
    tags: []
  - name: XtremIO
    id: xtremio
    description: |
      The `xtremio` plugin gathers metrics from a Dell EMC XtremIO Storage
      Array's V3 Rest API. Documentation can be found
      [here](https://dl.dell.com/content/docu96624_xtremio-storage-array-x1-and-x2-cluster-types-with-xms-6-3-0-to-6-3-3-and-xios-4-0-15-to-4-0-31-and-6-0-0-to-6-3-3-restful-api-3-x-guide.pdf?language=en_us).
    introduced: 
    tags: []
  - name: ZFS
    id: zfs
    description: |
      This ZFS plugin provides metrics from your ZFS filesystems. It supports
      ZFS on Linux and FreeBSD. It gets ZFS stat from `/proc/spl/kstat/zfs` on
      Linux and from `sysctl`, 'zfs' and `zpool` on FreeBSD.
    introduced: 
    tags: []
  - name: Zipkin
    id: zipkin
    description: |
      This plugin implements the Zipkin http server to gather trace and timing
      data needed to troubleshoot latency problems in microservice
      architectures.

      __Please Note:__ This plugin is experimental; Its data schema may be
      subject to change based on its main usage cases and the evolution of the
      OpenTracing standard.
    introduced: 
    tags: []
  - name: Zookeeper
    id: zookeeper
    description: |
      The zookeeper plugin collects variables outputted from the 'mntr' command
      [Zookeeper
      Admin](https://zookeeper.apache.org/doc/current/zookeeperAdmin.html).

      If in Zookeper, the Prometheus Metric provider is enabled, instead use
      the `prometheus` input plugin. By default, the Prometheus metrics are
      exposed at `http://<ip>:7000/metrics` URL. Using the `prometheus` input
      plugin provides a native solution to read and process Prometheus metrics,
      while this plugin is specific to using `mntr` to collect the Java
      Properties format.
    introduced: 
    tags: []
output:
  - name: Amon
    id: amon
    description: |
      This plugin writes metrics to [Amon monitoring
      platform](https://www.amon.cx). It requires a `serverkey` and
      `amoninstance` URL which can be obtained
      [here](https://www.amon.cx/docs/monitoring/) for your account.

      > [!IMPORTANT]
      > If point values being sent cannot be converted to a `float64`, the
      > metric is skipped.
    introduced: v0.2.1
    tags: [databases, freebsd, linux, macos, windows]
  - name: AMQP
    id: amqp
    description: |
      This plugin writes to an Advanced Message Queuing Protocol v0.9.1 broker.
      A prominent implementation of this protocol is
      [RabbitMQ](https://www.rabbitmq.com).

      > [!NOTE]
      > This plugin does not bind the AMQP exchange to a queue.

      For an introduction check the [AMQP concepts
      page](https://www.rabbitmq.com/tutorials/amqp-concepts.html) and the
      [RabbitMQ getting started
      guide](https://www.rabbitmq.com/getstarted.html).
    introduced: v0.1.9
    tags: [messaging, freebsd, linux, macos, windows]
  - name: Azure Application Insights
    id: application_insights
    description: |
      This plugin writes metrics to the [Azure Application
      Insights](https://azure.microsoft.com/en-us/services/application-insights/)
      service.
    introduced: v1.7.0
    tags: [applications, cloud, freebsd, linux, macos, windows]
  - name: Azure Data Explorer
    id: azure_data_explorer
    description: |
      This plugin writes metrics to the [Azure Data
      Explorer](https://docs.microsoft.com/en-us/azure/data-explorer), [Azure
      Synapse Data
      Explorer](https://docs.microsoft.com/en-us/azure/synapse-analytics/data-explorer/data-explorer-overview),
      and [Real time analytics in
      Fabric](https://learn.microsoft.com/en-us/fabric/real-time-analytics/overview)
      services.

      Azure Data Explorer is a distributed, columnar store, purpose built for
      any type of logs, metrics and time series data.
    introduced: v1.20.0
    tags: [cloud, datastore, freebsd, linux, macos, windows]
  - name: Azure Monitor
    id: azure_monitor
    description: |
      This plugin writes metrics to [Azure
      Monitor](https://learn.microsoft.com/en-us/azure/azure-monitor) which has
      a metric resolution of one minute. To accomodate for this in Telegraf,
      the plugin will automatically aggregate metrics into one minute buckets
      and send them to the service on every flush interval.

      > [!IMPORTANT]
      > The Azure Monitor custom metrics service is currently in preview and
      > might not be available in all Azure regions.

      The metrics from each input plugin will be written to a separate Azure
      Monitor namespace, prefixed with `Telegraf/` by default. The field name
      for each metric is written as the Azure Monitor metric name. All field
      values are written as a summarized set that includes: min, max, sum,
      count. Tags are written as a dimension on each Azure Monitor metric.

      > [!NOTE]
      > Azure Monitor won't accept metrics that are too far in the past or
      > future. Keep this in mind when configuring your output buffer limits or
      > other variables, such as flush intervals, or when using input sources
      > that could cause metrics to be out of this allowed range. Currently, the
      > timestamp should not be older than 30 minutes or more than 4 minutes in
      > the future at the time when it is sent to Azure Monitor service.
    introduced: v1.8.0
    tags: [cloud, datastore, freebsd, linux, macos, windows]
  - name: Google BigQuery
    id: bigquery
    description: |
      This plugin writes metrics to the [Google Cloud
      BigQuery](https://cloud.google.com/bigquery) service and requires
      [authentication](https://cloud.google.com/bigquery/docs/authentication)
      with Google Cloud using either a service account or user credentials.

      > [!IMPORTANT]
      > Be aware that this plugin accesses APIs that are
      > [chargeable](https://cloud.google.com/bigquery/pricing) and might incur
      > costs.
    introduced: v1.18.0
    tags: [cloud, datastore, freebsd, linux, macos, windows]
  - name: Clarify
    id: clarify
    description: |
      This plugin writes metrics to [Clarify](https://clarify.io). To use this
      plugin you will need to obtain a set of
      [credentials](https://docs.clarify.io/users/admin/integrations/credentials).
    introduced: v1.27.0
    tags: [cloud, datastore, freebsd, linux, macos, windows]
  - name: Google Cloud PubSub
    id: cloud_pubsub
    description: |
      This plugin publishes metrics to a [Google Cloud
      PubSub](https://cloud.google.com/pubsub) topic in one of the supported
      [data formats](/telegraf/v1/data_formats/output).
    introduced: v1.10.0
    tags: [cloud, messaging, freebsd, linux, macos, windows]
  - name: Amazon CloudWatch
    id: cloudwatch
    description: |
      This plugin writes metrics to the [Amazon
      CloudWatch](https://aws.amazon.com/cloudwatch) service.
    introduced: v0.10.1
    tags: [cloud, freebsd, linux, macos, windows]
  - name: Amazon CloudWatch Logs
    id: cloudwatch_logs
    description: |
      This plugin writes log-metrics to the [Amazon
      CloudWatch](https://aws.amazon.com/cloudwatch) service.
    introduced: v1.19.0
    tags: [cloud, logging, freebsd, linux, macos, windows]
  - name: CrateDB
    id: cratedb
    description: |
      This plugin writes metrics to [CrateDB](https://crate.io/) via its
      [PostgreSQL
      protocol](https://crate.io/docs/crate/reference/protocols/postgres.html).
    introduced: v1.5.0
    tags: [cloud, datastore, freebsd, linux, macos, windows]
  - name: Datadog
    id: datadog
    description: |
      This plugin writes metrics to the [Datadog Metrics
      API](https://docs.datadoghq.com/api/v1/metrics/#submit-metrics) and
      requires an `apikey` which can be obtained
      [here](https://app.datadoghq.com/account/settings#api) for the account. >
      [!NOTE] This plugin supports the v1 API.
    introduced: v0.1.6
    tags: [applications, cloud, datastore, freebsd, linux, macos, windows]
  - name: Discard
    id: discard
    description: |
      This plugin discards all metrics written to it and is meant for testing
      purposes.
    introduced: v1.2.0
    tags: [testing, freebsd, linux, macos, windows]
  - name: Dynatrace
    id: dynatrace
    description: |
      This plugin writes metrics to [Dynatrace](https://www.dynatrace.com) via
      the [Dynatrace Metrics API
      V2](https://docs.dynatrace.com/docs/shortlink/api-metrics-v2). It may be
      run alongside the Dynatrace OneAgent for automatic authentication or it
      may be run standalone on a host without OneAgent by specifying a URL and
      API Token.

      More information on the plugin can be found in the [Dynatrace
      documentation](https://docs.dynatrace.com/docs/shortlink/api-metrics-v2-post-datapoints).

      > [!NOTE]
      > All metrics are reported as gauges, unless they are specified to be
      > delta counters using the `additional_counters` or
      > `additional_counters_patterns` config option (see below). See the
      > [Dynatrace Metrics ingestion protocol
      > documentation](https://docs.dynatrace.com/docs/shortlink/metric-ingestion-protocol)
      > for details on the types defined there.
    introduced: v1.16.0
    tags: [cloud, datastore, freebsd, linux, macos, windows]
  - name: Elasticsearch
    id: elasticsearch
    description: |
      This plugin writes metrics to [Elasticsearch](https://www.elastic.co) via
      HTTP using the [Elastic client
      library](http://olivere.github.io/elastic/). The plugin supports
      Elasticsearch releases from v5.x up to v7.x.
    introduced: v0.1.5
    tags: [datastore, logging, freebsd, linux, macos, windows]
  - name: Azure Event Hubs
    id: event_hubs
    description: |
      This plugin for [Azure Event
      Hubs](https://azure.microsoft.com/en-gb/services/event-hubs/) will send
      metrics to a single Event Hub within an Event Hubs namespace. Metrics are
      sent as message batches, each message payload containing one metric
      object. The messages do not specify a partition key, and will thus be
      automatically load-balanced (round-robin) across all the Event Hub
      partitions.
    introduced: 
    tags: []
  - name: Executable
    id: exec
    description: |
      This plugin writes metrics to an external application via `stdin`. The
      command will be executed on each write creating a new process. Metrics
      are passed in one of the supported [data
      formats](/telegraf/v1/data_formats/output).

      The executable and the individual parameters must be defined as a list.
      All outputs of the executable to `stderr` will be logged in the Telegraf
      log.

      > [!TIP]
      > For better performance consider execd which runs continuously.
    introduced: v1.12.0
    tags: [system, freebsd, linux, macos, windows]
  - name: Executable Daemon
    id: execd
    description: |
      This plugin writes metrics to an external daemon program via `stdin`. The
      command will be executed once and metrics will be passed to it on every
      write in one of the supported [data
      formats](/telegraf/v1/data_formats/output). The executable and the
      individual parameters must be defined as a list.

      All outputs of the executable to `stderr` will be logged in the Telegraf
      log. Telegraf minimum version: Telegraf 1.15.0
    introduced: v1.15.0
    tags: [system, freebsd, linux, macos, windows]
  - name: File
    id: file
    description: |
      This plugin writes metrics to one or more local files in one of the
      supported [data formats](/telegraf/v1/data_formats/output).
    introduced: v0.10.3
    tags: [system, freebsd, linux, macos, windows]
  - name: Graphite
    id: graphite
    description: |
      This plugin writes metrics to
      [Graphite](http://graphite.readthedocs.org/en/latest/index.html) via TCP.
      For details on the translation between Telegraf Metrics and Graphite
      output see the [Graphite data
      format](/telegraf/v1/plugins/#serializer-graphite).
    introduced: v0.10.1
    tags: [datastore, freebsd, linux, macos, windows]
  - name: Graylog
    id: graylog
    description: |
      This plugin writes metrics to a [Graylog](https://graylog.org/) instance
      using the [GELF data
      format](https://docs.graylog.org/en/3.1/pages/gelf.html#gelf-payload-specification).
    introduced: v1.0.0
    tags: [datatstore, logging, freebsd, linux, macos, windows]
  - name: GroundWork
    id: groundwork
    description: |
      This plugin writes metrics to a [GroundWork
      Monitor](https://www.gwos.com/product/groundwork-monitor/) instance.

      > [!IMPORTANT]
      > Plugin only supports GroundWork v8 or later.
    introduced: v1.21.0
    tags: [applications, messaging, freebsd, linux, macos, windows]
  - name: Health
    id: health
    description: |
      This plugin provides a HTTP health check endpoint that can be configured
      to return failure status codes based on the value of a metric.

      When the plugin is healthy it will return a 200 response; when unhealthy
      it will return a 503 response. The default state is healthy, one or more
      checks must fail in order for the resource to enter the failed state.
    introduced: v1.11.0
    tags: [applications, freebsd, linux, macos, windows]
  - name: HTTP
    id: http
    description: |
      This plugin writes metrics to a HTTP endpoint using one of the supported
      [data formats](/telegraf/v1/data_formats/output). For data formats
      supporting batching, metrics are sent in batches by default.
    introduced: v1.7.0
    tags: [applications, freebsd, linux, macos, windows]
  - name: InfluxDB v1.x
    id: influxdb
    description: |
      This plugin writes metrics to a [InfluxDB
      v1.x](https://docs.influxdata.com/influxdb/v1) instance via HTTP or UDP
      protocol.
    introduced: v0.1.1
    tags: [datastore, freebsd, linux, macos, windows]
  - name: InfluxDB v2.x
    id: influxdb_v2
    description: |
      This plugin writes metrics to a [InfluxDB
      v2.x](https://docs.influxdata.com/influxdb/v2) instance via HTTP.
    introduced: v1.8.0
    tags: [datastore, freebsd, linux, macos, windows]
  - name: Instrumental
    id: instrumental
    description: |
      This plugin writes metrics to the [Instrumental Collector
      API](https://instrumentalapp.com/docs/tcp-collector) and requires a
      project-specific API token.

      Instrumental accepts stats in a format very close to Graphite, with the
      only difference being that the type of stat (gauge, increment) is the
      first token, separated from the metric itself by whitespace. The
      `increment` type is only used if the metric comes in as a counter via the
      [statsd input plugin](/telegraf/v1/plugins/#input-statsd).
    introduced: v0.13.1
    tags: [applications, freebsd, linux, macos, windows]
  - name: Apache IoTDB
    id: iotdb
    description: |
      This plugin writes metrics to an [Apache IoTDB](https://iotdb.apache.org)
      instance, a database for the Internet of Things, supporting session
      connection and data insertion.
    introduced: v1.24.0
    tags: [datastore, freebsd, linux, macos, windows]
  - name: Kafka
    id: kafka
    description: |
      This plugin writes metrics to a [Kafka Broker](http://kafka.apache.org)
      acting a Kafka Producer.
    introduced: v0.1.7
    tags: [messaging, freebsd, linux, macos, windows]
  - name: Amazon Kinesis
    id: kinesis
    description: |
      This plugin writes metrics to a [Amazon
      Kinesis](https://aws.amazon.com/kinesis) endpoint. It will batch all
      Points in one request to reduce the number of API requests.

      Please consult [Amazon's official
      documentation](http://docs.aws.amazon.com/kinesis/latest/dev/key-concepts.html)
      for more details on the Kinesis architecture and concepts.
    introduced: v0.2.5
    tags: [cloud, messaging, freebsd, linux, macos, windows]
  - name: Librato
    id: librato
    description: |
      This plugin writes metrics to the [Librato](https://www.librato.com/)
      service. It requires an `api_user` and `api_token` which can be obtained
      [here](https://metrics.librato.com/account/api_tokens) for your account.

      The `source_tag` option in the Configuration file is used to send
      contextual information from Point Tags to the API. Besides from this, the
      plugin currently does not send any additional associated Point Tags.

      > [!IMPOTANT]
      > If the point value being sent cannot be converted to a `float64`, the
      > metric is skipped.
    introduced: v0.2.0
    tags: [cloud, datastore, freebsd, linux, macos, windows]
  - name: Logz.io
    id: logzio
    description: |
      This plugin writes metrics to the [Logz.io](https://logz.io) service via
      HTTP.
    introduced: v1.17.0
    tags: [cloud, datastore, freebsd, linux, macos, windows]
  - name: Grafana Loki
    id: loki
    description: |
      This plugin writes logs to a [Grafana Loki](https://grafana.com/loki)
      instance, using the metric name and tags as labels. The log line will
      contain all fields in `key="value"` format easily parsable with the
      `logfmt` parser in Loki.

      Logs within each stream are sorted by timestamp before being sent to
      Loki.
    introduced: v1.18.0
    tags: [logging, freebsd, linux, macos, windows]
  - name: MongoDB
    id: mongodb
    description: |
      This plugin writes metrics to [MongoDB](https://www.mongodb.com)
      automatically creating collections as time series collections if they
      don't exist.

      > [!NOTE]
      > This plugin requires MongoDB v5 or later for time series collections.
    introduced: v1.21.0
    tags: [datastore, freebsd, linux, macos, windows]
  - name: MQTT Producer
    id: mqtt
    description: |
      This plugin writes metrics to a [MQTT broker](http://http://mqtt.org/)
      acting as a MQTT producer. The plugin supports the MQTT protocols `3.1.1`
      and `5`.

      > [!NOTE]
      > In v2.0.12+ of the mosquitto MQTT server, there is a
      > [bug](https://github.com/eclipse/mosquitto/issues/2117) requiring the
      > `keep_alive` value to be set non-zero in Telegraf. Otherwise, the server
      > will return with `identifier rejected`. As a reference
      > `eclipse/paho.golang` sets the `keep_alive` to 30.
    introduced: v0.2.0
    tags: [messaging, freebsd, linux, macos, windows]
  - name: NATS
    id: nats
    description: |
      This plugin writes metrics to subjects of a set of
      [NATS](https://nats.io) instances in one of the supported [data
      formats](/telegraf/v1/data_formats/output).
    introduced: v1.1.0
    tags: [messaging, freebsd, linux, macos, windows]
  - name: Nebius Cloud Monitoring
    id: nebius_cloud_monitoring
    description: |
      This plugin writes metrics to the [Nebuis Cloud
      Monitoring](https://nebius.com/il/services/monitoring) service.
    introduced: v1.27.0
    tags: [cloud, datastore, freebsd, linux, macos, windows]
  - name: New Relic
    id: newrelic
    description: |
      This plugins writes metrics to [New Relic Insights](https://newrelic.com)
      using the [Metrics
      API](https://docs.newrelic.com/docs/data-ingest-apis/get-data-new-relic/metric-api/introduction-metric-api).
      To use this plugin you have to obtain an [Insights API
      Key](https://docs.newrelic.com/docs/apis/get-started/intro-apis/types-new-relic-api-keys#user-api-key).
    introduced: v1.15.0
    tags: [applications, freebsd, linux, macos, windows]
  - name: NSQ
    id: nsq
    description: |
      This plugin writes metrics to the given topic of a [NSQ](https://nsq.io)
      instance as a producer in one of the supported [data
      formats](/telegraf/v1/data_formats/output).
    introduced: v0.2.1
    tags: [messaging, freebsd, linux, macos, windows]
  - name: OpenSearch
    id: opensearch
    description: |
      This plugin writes metrics to a [OpenSearch](https://opensearch.org/)
      instance via HTTP. It supports OpenSearch releases v1 and v2 but future
      comparability with 1.x is not guaranteed and instead will focus on 2.x
      support.

      > [!TIP]
      > Consider using the existing Elasticsearch plugin for 1.x.
    introduced: v1.29.0
    tags: [datastore, logging, freebsd, linux, macos, windows]
  - name: OpenTelemetry
    id: opentelemetry
    description: |
      This plugin writes metrics to [OpenTelemetry](https://opentelemetry.io)
      servers and agents via gRPC.
    introduced: v1.20.0
    tags: [logging, messaging, freebsd, linux, macos, windows]
  - name: OpenTSDB
    id: opentsdb
    description: |
      This plugin writes metrics to an [OpenTSDB](http://opentsdb.net/)
      instance using either the telnet or HTTP mode. Using the HTTP API is
      recommended since OpenTSDB 2.0.
    introduced: v0.1.9
    tags: [datastore, freebsd, linux, macos, windows]
  - name: Parquet
    id: parquet
    description: |
      This plugin writes metrics to [parquet](https://parquet.apache.org)
      files. By default, metrics are grouped by metric name and written all to
      the same file.

      > [!IMPORTANT]
      > If a metric schema does not match the schema in the file it will be
      > dropped.

      To lean more about the parquet format, check out the [parquet
      docs](https://parquet.apache.org/docs/) as well as a blog post on
      [querying
      parquet](https://www.influxdata.com/blog/querying-parquet-millisecond-latency/).
    introduced: v1.32.0
    tags: [datastore, freebsd, linux, macos, windows]
  - name: PostgreSQL
    id: postgresql
    description: |
      This plugin writes metrics to a [PostgreSQL](https://www.postgresql.org/)
      (or compatible) server managing the schema and automatically updating
      missing columns.
    introduced: v1.24.0
    tags: [datastore, freebsd, linux, macos, windows]
  - name: Prometheus
    id: prometheus_client
    description: |
      This plugin starts a [Prometheus](https://prometheus.io) client and
      exposes the written metrics on a `/metrics` endpoint by default. This
      endpoint can then be polled by a Prometheus server.
    introduced: v0.2.1
    tags: [applications, freebsd, linux, macos, windows]
  - name: Quix
    id: quix
    description: |
      This plugin writes metrics to a [Quix](https://quix.io) endpoint.

      Please consult Quix's [official documentation](https://quix.io/docs/) for
      more details on the Quix platform architecture and concepts.
    introduced: v1.33.0
    tags: [cloud, messaging, freebsd, linux, macos, windows]
  - name: Redis Time Series
    id: redistimeseries
    description: |
      This plugin writes metrics to a [Redis
      time-series](https://redis.io/timeseries) server.
    introduced: v1.0.0
    tags: [datastore, freebsd, linux, macos, windows]
  - name: Remote File
    id: remotefile
    description: |
      This plugin writes metrics to files in a remote location using the
      [rclone library](https://rclone.org). Currently the following backends
      are supported:

      - `local`: [Local filesystem](https://rclone.org/local/)
      - `s3`: [Amazon S3 storage providers](https://rclone.org/s3/)
      - `sftp`: [Secure File Transfer Protocol](https://rclone.org/sftp/)
    introduced: v1.32.0
    tags: [datastore, freebsd, linux, macos, windows]
  - name: Riemann
    id: riemann
    description: |
      This plugin writes metric to the [Riemann](http://riemann.io) serice via
      TCP or UDP.
    introduced: v1.3.0
    tags: [datastore, freebsd, linux, macos, windows]
  - name: Sensu Go
    id: sensu
    description: |
      This plugin writes metrics to [Sensu Go](https://sensu.io) via its HTTP
      events API.
    introduced: v1.18.0
    tags: [applications, freebsd, linux, macos, windows]
  - name: SignalFx
    id: signalfx
    description: |
      This plugin writes metrics to
      [SignalFx](https://docs.signalfx.com/en/latest/).
    introduced: v1.18.0
    tags: [applications, freebsd, linux, macos, windows]
  - name: Socket Writer
    id: socket_writer
    description: |
      This plugin writes metrics to a network service e.g. via UDP or TCP in
      one of the supported [data formats](/telegraf/v1/data_formats/output).
    introduced: v1.3.0
    tags: [applications, networking, freebsd, linux, macos, windows]
  - name: SQL
    id: sql
    description: |
      This plugin writes metrics to a supported SQL database using a simple,
      hard-coded database schema. There is a table for each metric type with
      the table name corresponding to the metric name. There is a column per
      field and a column per tag with an optional column for the metric
      timestamp.

      A row is written for every metric. This means multiple metrics are never
      merged into a single row, even if they have the same metric name, tags,
      and timestamp.

      The plugin uses Golang's generic "database/sql" interface and third party
      drivers. See the driver-specific section for a list of supported drivers
      and details.
    introduced: v1.19.0
    tags: [datastore, freebsd, linux, macos, windows]
  - name: Google Cloud Monitoring
    id: stackdriver
    description: |
      This plugin writes metrics to a `project` in [Google Cloud
      Monitoring](https://cloud.google.com/monitoring/api/v3/) (formerly called
      Stackdriver).
      [Authentication](https://cloud.google.com/docs/authentication/getting-started)
      with Google Cloud is required using either a service account or user
      credentials.

      > [!IMPORTANT]
      > This plugin accesses APIs which are
      > [chargeable](https://cloud.google.com/stackdriver/pricing#google-clouds-operations-suite-pricing)
      > and might incur costs.

      By default, Metrics are grouped by the `namespace` variable and metric
      key, eg: `custom.googleapis.com/telegraf/system/load5`. However, this is
      not the best practice. Setting `metric_name_format = "official"` will
      produce a more easily queried format of:
      `metric_type_prefix/[namespace_]name_key/kind`. If the global namespace
      is not set, it is omitted as well.
    introduced: v1.9.0
    tags: [cloud, datastore, freebsd, linux, macos, windows]
  - name: ActiveMQ STOMP
    id: stomp
    description: |
      This plugin writes metrics to an [Active MQ
      Broker](http://activemq.apache.org/) for [STOMP](https://stomp.github.io)
      but also supports [Amazon MQ](https://aws.amazon.com/amazon-mq) brokers.
      Metrics can be written in one of the supported [data
      formats](/telegraf/v1/data_formats/output).
    introduced: v1.24.0
    tags: [messaging, freebsd, linux, macos, windows]
  - name: Sumo Logic
    id: sumologic
    description: |
      This plugin writes metrics to a [Sumo Logic HTTP
      Source](https://help.sumologic.com/03Send-Data/Sources/02Sources-for-Hosted-Collectors/HTTP-Source/Upload-Metrics-to-an-HTTP-Source)
      using one of the following data formats:

      - `graphite` for Content-Type of `application/vnd.sumologic.graphite`
      - `carbon2` for Content-Type of `application/vnd.sumologic.carbon2`
      - `prometheus` for Content-Type of `application/vnd.sumologic.prometheus`
    introduced: v1.16.0
    tags: [logging, freebsd, linux, macos, windows]
  - name: Syslog
    id: syslog
    description: |
      This plugin writes metrics as syslog messages via UDP in [RFC5426
      format](https://tools.ietf.org/html/rfc5426) or via TCP in [RFC6587
      format](https://tools.ietf.org/html/rfc6587) or via TLS in [RFC5425
      format](https://tools.ietf.org/html/rfc5425), with or without the octet
      counting framing.

      > [!IMPORTANT]
      > Syslog messages are formatted according to
      > [RFC5424](https://tools.ietf.org/html/rfc5424) limiting the field sizes
      > when sending messages according to the [syslog message
      > format](https://datatracker.ietf.org/doc/html/rfc5424#section-6) section
      > of the RFC. Sending messages beyond these sizes may get dropped by a
      > strict receiver silently.
    introduced: v1.11.0
    tags: [logging, freebsd, linux, macos, windows]
  - name: Amazon Timestream
    id: timestream
    description: |
      This plugin writes metrics to the [Amazon
      Timestream](https://aws.amazon.com/timestream) service.
    introduced: v1.16.0
    tags: [cloud, datastore, freebsd, linux, macos, windows]
  - name: Warp10
    id: warp10
    description: |
      This plugin writes metrics to the [Warp 10](https://www.warp10.io)
      service.
    introduced: v1.14.0
    tags: [cloud, datastore, freebsd, linux, macos, windows]
  - name: Wavefront
    id: wavefront
    description: |
      This plugin writes metrics to a [Wavefront](https://www.wavefront.com)
      instance or a Wavefront Proxy instance over HTTP or HTTPS.
    introduced: v1.5.0
    tags: [applications, cloud, freebsd, linux, macos, windows]
  - name: Websocket
    id: websocket
    description: |
      This plugin writes metrics to a WebSocket endpoint in one of the
      supported [data formats](/telegraf/v1/data_formats/output).
    introduced: v1.19.0
    tags: [applications, web, freebsd, linux, macos, windows]
  - name: Yandex Cloud Monitoring
    id: yandex_cloud_monitoring
    description: |
      This plugin writes metrics to the [Yandex Cloud
      Monitoring](https://cloud.yandex.com/services/monitoring) service.
    introduced: v1.17.0
    tags: [cloud, freebsd, linux, macos, windows]
  - name: Zabbix
    id: zabbix
    description: |
      This plugin writes metrics to [Zabbix](https://www.zabbix.com/) via
      [traps](https://www.zabbix.com/documentation/current/en/manual/appendix/items/trapper).
      It has been tested with versions v3.0, v4.0 and v6.0 but should work with
      newer versions of Zabbix as long as the protocol doesn't change.
    introduced: v1.30.0
    tags: [datastore, freebsd, linux, macos, windows]
aggregator:
  - name: Basic Statistics
    id: basicstats
    description: |
      This plugin computes basic statistics such as counts, differences,
      minima, maxima, mean values, non-negative differences etc. for a set of
      metrics and emits these statistical values every `period`.
    introduced: v1.5.0
    tags: [freebsd, linux, macos, windows]
  - name: Derivative
    id: derivative
    description: |
      This plugin computes the derivative for all fields of the aggregated
      metrics.
    introduced: v1.18.0
    tags: [freebsd, linux, macos, windows]
  - name: Final
    id: final
    description: |
      This plugin emits the last metric of a contiguous series, defined as a
      series which receives updates within the time period in `series_timeout`.
      The contiguous series may be longer than the time interval defined by
      `period`. When a series has not been updated within the `series_timeout`,
      the last metric is emitted.

      Alternatively, the plugin emits the last metric in the `period` for the
      `periodic` output strategy.

      This is useful for getting the final value for data sources that produce
      discrete time series such as procstat, cgroup, kubernetes etc. or to
      downsample metrics collected at a higher frequency.

      > [!NOTE]
      > All emited metrics do have fields with `_final` appended to the
      > field-name by default.
    introduced: v1.11.0
    tags: [freebsd, linux, macos, windows]
  - name: Histogram
    id: histogram
    description: |
      This plugin creates histograms containing the counts of field values
      within the configured range. The histogram metric is emitted every
      `period`.

      In `cumulative` mode, values added to a bucket are also added to the
      consecutive buckets in the distribution creating a [cumulative
      histogram](https://en.wikipedia.org/wiki/Histogram#/media/File:Cumulative_vs_normal_histogram.svg).

      > [!NOTE]
      > By default bucket counts are not reset between periods and will be
      > non-strictly increasing while Telegraf is running. This behavior can be
      > by setting the `reset` parameter.
    introduced: v1.4.0
    tags: [freebsd, linux, macos, windows]
  - name: Merge
    id: merge
    description: |
      This plugin merges metrics of the same series and timestamp into new
      metrics with the super-set of fields. A series here is defined by the
      metric name and the tag key-value set.

      Use this plugin when fields are split over multiple metrics, with the
      same measurement, tag set and timestamp.
    introduced: v1.13.0
    tags: [freebsd, linux, macos, windows]
  - name: Minimum-Maximum
    id: minmax
    description: |
      This plugin aggregates the minimum and maximum values of each field it
      sees, emitting the aggrate every `period` seconds with field names
      suffixed by `_min` and `_max` respectively.
    introduced: v1.1.0
    tags: [freebsd, linux, macos, windows]
  - name: Quantile
    id: quantile
    description: |
      This plugin aggregates each numeric field per metric into the specified
      quantiles and emits the quantiles every `period`. Different aggregation
      algorithms are supported with varying accuracy and limitations.
    introduced: v1.18.0
    tags: [freebsd, linux, macos, windows]
  - name: Starlark
    id: starlark
    description: |
      This plugin allows to implement a custom aggregator plugin via a
      [Starlark](https://github.com/google/starlark-go) script.

      The Starlark language is a dialect of Python and will be familiar to
      those who have experience with the Python language. However, there are
      major differences. Existing Python code is unlikely to work unmodified.

      > [!NOTE]
      > The execution environment is sandboxed, and it is not possible to access
      > the local filesystem or perfoming network operations. This is by design
      > of the Starlark language as a configuration language.

      The Starlark script used by this plugin needs to be composed of the three
      methods defining an aggreagtor named `add`, `push` and `reset`.

      The `add` method is called as soon as a new metric is added to the plugin
      the metrics to the aggregator. After `period`, the `push` method is
      called to output the resulting metrics and finally the aggregation is
      reset by using the `reset` method of the Starlark script.

      The Starlark functions might use the global function `state` to keep
      aggregation information such as added metrics etc.

      More details on the syntax and available functions can be found in the
      [Starlark
      specification](https://github.com/google/starlark-go/blob/d1966c6b9fcd/doc/spec.md).
    introduced: v1.21.0
    tags: [freebsd, linux, macos, windows]
  - name: Value Counter
    id: valuecounter
    description: |
      This plugin counts the occurrence of unique values in fields and emits
      the counter once every `period` with the field-names being suffixed by
      the unique value converted to `string`.

      > [!NOTE]
      > The fields to be counted must be configured using the `fields` setting,
      > otherwise no field will be counted and no metric is emitted.

      This plugin is useful to e.g. count the occurrances of HTTP status codes
      or other categorical values in the defined `period`.

      > [!IMPORTANT]
      > Counting fields with a high number of potential values may produce a
      > significant amounts of new fields and results in an increased memory
      > usage. Take care to only count fields with a limited set of values.
    introduced: v1.8.0
    tags: [freebsd, linux, macos, windows]
processor:
  - name: AWS EC2 Metadata
    id: aws_ec2
    description: |
      AWS EC2 Metadata processor plugin appends metadata gathered from [AWS
      IMDS](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html)
      to metrics associated with EC2 instances.
    introduced: 
    tags: []
  - name: Batch
    id: batch
    description: |
      This processor groups metrics into batches by adding a batch tag. This is
      useful for parallel processing of metrics where downstream processors,
      aggregators or outputs can then select a batch using `tagpass` or
      `metricpass`.

      Metrics are distributed across batches using the round-robin scheme.
    introduced: 
    tags: []
  - name: Clone
    id: clone
    description: |
      The clone processor plugin create a copy of each metric passing through
      it, preserving untouched the original metric and allowing modifications
      in the copied one.

      The modifications allowed are the ones supported by input plugins and
      aggregators:

      * name_override
      * name_prefix
      * name_suffix
      * tags

      Select the metrics to modify using the standard metric filtering.
    introduced: 
    tags: []
  - name: Converter
    id: converter
    description: |
      The converter processor is used to change the type of tag or field
      values. In addition to changing field types it can convert between fields
      and tags.

      Values that cannot be converted are dropped.

      **Note:** When converting tags to fields, take care to ensure the series
      is still uniquely identifiable. Fields with the same series key
      (measurement + tags) will overwrite one another.

      **Note on large strings being converted to numeric types:** When
      converting a string value to a numeric type, precision may be lost if the
      number is too large. The largest numeric type this plugin supports is
      `float64`, and if a string 'number' exceeds its size limit, accuracy may
      be lost.

      **Note on multiple measurement or timestamps:** Users can provide
      multiple tags or fields to use as the measurement name or timestamp.
      However, note that the order in the array is not guaranteed!
    introduced: 
    tags: []
  - name: Date
    id: date
    description: |
      Use the `date` processor to add the metric timestamp as a human readable
      tag.

      A common use is to add a tag that can be used to group by month or year.

      A few example usecases include:

      1) consumption data for utilities on per month basis
      1) bandwidth capacity per month
      1) compare energy production or sales on a yearly or monthly basis
    introduced: 
    tags: []
  - name: Dedup
    id: dedup
    description: |
      Filter metrics whose field values are exact repetitions of the previous
      values. This plugin will store its state between runs if the `statefile`
      option in the agent config section is set.
    introduced: 
    tags: []
  - name: Defaults
    id: defaults
    description: |
      The _Defaults_ processor allows you to ensure certain fields will always
      exist with a specified default value on your metric(s).

      There are three cases where this processor will insert a configured
      default field.

      1. The field is nil on the incoming metric
      1. The field is not nil, but its value is an empty string.
      1. The field is not nil, but its value is a string of one or more empty
      spaces.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Enum
    id: enum
    description: |
      The Enum Processor allows the configuration of value mappings for metric
      tags or fields. The main use-case for this is to rewrite status codes
      such as _red_, _amber_ and _green_ by numeric values such as 0, 1, 2. The
      plugin supports string, int, float64 and bool types for the field values.
      Multiple tags or fields can be configured with separate value mappings
      for each. Default mapping values can be configured to be used for all
      values, which are not contained in the value_mappings. The processor
      supports explicit configuration of a destination tag or field. By default
      the source tag or field is overwritten.
    introduced: 
    tags: []
  - name: Execd
    id: execd
    description: |
      The `execd` processor plugin runs an external program as a separate
      process and pipes metrics in to the process's STDIN and reads processed
      metrics from its STDOUT. The programs must accept influx line protocol on
      standard in (STDIN) and output metrics in influx line protocol to
      standard output (STDOUT).

      Program output on standard error is mirrored to the telegraf log.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Filepath
    id: filepath
    description: |
      The `filepath` processor plugin maps certain go functions from
      [path/filepath](https://golang.org/pkg/path/filepath/) onto tag and field
      values. Values can be modified in place or stored in another key.

      Implemented functions are:

      * [Base](https://golang.org/pkg/path/filepath/#Base) (accessible through
      `[[processors.filepath.basename]]`)
      * [Rel](https://golang.org/pkg/path/filepath/#Rel) (accessible through
      `[[processors.filepath.rel]]`)
      * [Dir](https://golang.org/pkg/path/filepath/#Dir) (accessible through
      `[[processors.filepath.dir]]`)
      * [Clean](https://golang.org/pkg/path/filepath/#Clean) (accessible through
      `[[processors.filepath.clean]]`)
      * [ToSlash](https://golang.org/pkg/path/filepath/#ToSlash) (accessible
      through `[[processors.filepath.toslash]]`)

      On top of that, the plugin provides an extra function to retrieve the
      final path component without its extension. This function is accessible
      through the `[[processors.filepath.stem]]` configuration item.

      Please note that, in this implementation, these functions are processed
      in the order that they appear above( except for `stem` that is applied in
      the first place).

      Specify the `tag` and/or `field` that you want processed in each section
      and optionally a `dest` if you want the result stored in a new tag or
      field.

      If you plan to apply multiple transformations to the same `tag`/`field`,
      bear in mind the processing order stated above.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Filter
    id: filter
    description: |
      The filter processor plugin allows to specify a set of rules for metrics
      with the ability to _keep_ or _drop_ those metrics. It does _not_ change
      the metric. As such a user might want to apply this processor to remove
      metrics from the processing/output stream. __NOTE:__ The filtering is
      _not_ output specific, but will apply to the metrics processed by this
      processor.
    introduced: 
    tags: []
  - name: Network Interface Name
    id: ifname
    description: |
      The `ifname` plugin looks up network interface names using SNMP.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Lookup
    id: lookup
    description: |
      The Lookup Processor allows to use one or more files containing a
      lookup-table for annotating incoming metrics. The lookup is _static_ as
      the files are only used on startup. The main use-case for this is to
      annotate metrics with additional tags e.g. dependent on their source.
      Multiple tags can be added depending on the lookup-table _files_.

      The lookup key can be generated using a Golang template with the ability
      to access the metric name via `{{.Name}}`, the tag values via `{{.Tag
      "mytag"}}`, with `mytag` being the tag-name and field-values via
      `{{.Field "myfield"}}`, with `myfield` being the field-name. Non-existing
      tags and field will result in an empty string or `nil` respectively. In
      case the key cannot be found, the metric is passed-through unchanged. By
      default all matching tags are added and existing tag-values are
      overwritten.

      Please note: The plugin only supports the addition of tags and thus all
      mapped tag-values need to be strings!
    introduced: 
    tags: []
  - name: Noise
    id: noise
    description: |
      The _Noise_ processor is used to add noise to numerical field values. For
      each field a noise is generated using a defined probability density
      function and added to the value. The function type can be configured as
      _Laplace_, _Gaussian_ or _Uniform_. Depending on the function, various
      parameters need to be configured:
    introduced: 
    tags: []
  - name: Override
    id: override
    description: |
      The override processor plugin allows overriding all modifications that
      are supported by input plugins and aggregators:

      * name_override
      * name_prefix
      * name_suffix
      * tags

      All metrics passing through this processor will be modified accordingly.
      Select the metrics to modify using the standard metric filtering options.

      Values of *name_override*, *name_prefix*, *name_suffix* and already
      present *tags* with conflicting keys will be overwritten. Absent *tags*
      will be created.

      Use-case of this plugin encompass ensuring certain tags or naming
      conventions are adhered to irrespective of input plugin configurations,
      e.g. by `taginclude`.
    introduced: 
    tags: []
  - name: Parser
    id: parser
    description: |
      This plugin parses defined fields or tags containing the specified data
      format and creates new metrics based on the contents of the field or tag.
    introduced: 
    tags: []
  - name: Pivot
    id: pivot
    description: |
      You can use the `pivot` processor to rotate single valued metrics into a
      multi field metric. This transformation often results in data that is
      more easily to apply mathematical operators and comparisons between, and
      flatten into a more compact representation for write operations with some
      output data formats.

      To perform the reverse operation use the [unpivot] processor.
    introduced: 
    tags: []
  - name: Port Name Lookup
    id: port_name
    description: |
      Use the `port_name` processor to convert a tag or field containing a
      well-known port number to the registered service name.

      Tag or field can contain a number ("80") or number and protocol separated
      by slash ("443/tcp"). If protocol is not provided it defaults to tcp but
      can be changed with the default_protocol setting. An additional tag or
      field can be specified for the protocol.

      If the source was found in tag, the service name will be added as a tag.
      If the source was found in a field, the service name will also be a
      field.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Printer
    id: printer
    description: |
      The printer processor plugin simple prints every metric passing through
      it.
    introduced: 
    tags: []
  - name: Regex
    id: regex
    description: |
      This plugin transforms tag and field _values_ as well as renaming tags,
      fields and metrics using regex patterns. Tag and field _values_ can be
      transformed using named-groups in a batch fashion.

      The regex processor **only operates on string fields**. It will not work
      on any other data types, like an integer or float.
    introduced: 
    tags: []
  - name: Rename
    id: rename
    description: |
      The `rename` processor renames measurements, fields, and tags.
    introduced: 
    tags: []
  - name: Reverse DNS
    id: reverse_dns
    description: |
      The `reverse_dns` processor does a reverse-dns lookup on tags (or fields)
      with IPs in them.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: S2 Geo
    id: s2geo
    description: |
      Use the `s2geo` processor to add tag with S2 cell ID token of specified
      [cell level](). The tag is used in `experimental/geo` Flux package
      functions. The `lat` and `lon` fields values should contain WGS-84
      coordinates in decimal degrees.
    introduced: 
    tags: []
  - name: Scale
    id: scale
    description: |
      The scale processor filters for a set of fields, and scales the
      respective values from an input range into the given output range
      according to this formula:

      Alternatively, you can apply a factor and offset to the input according
      to this formula

      Input fields are converted to floating point values if possible.
      Otherwise, fields that cannot be converted are ignored and keep their
      original value.

      **Please note:** Neither the input nor the output values are clipped to
      their respective ranges!
    introduced: 
    tags: []
  - name: SNMP Lookup
    id: snmp_lookup
    description: |
      The `snmp_lookup` plugin looks up extra tags using SNMP and caches them.

      Telegraf minimum version: Telegraf 1.30.0
    introduced: 
    tags: []
  - name: Split
    id: split
    description: |
      This plugin splits a metric up into one or more metrics based on a
      template the user provides. The timestamp of the new metric is based on
      the source metric. Templates can overlap, where a field or tag, is used
      across templates and as a result end up in multiple metrics.

      **NOTE**: If drop original is changed to true, then the plugin can result
      in dropping all metrics when no match is found! Please ensure to test
      templates before putting into production *and* use metric filtering to
      avoid data loss.

      Some outputs are sensitive to the number of metric series that are
      produced. Multiple metrics of the same series (i.e. identical name, tag
      key-values and field name) with the same timestamp might result in
      squashing those points to the latest metric produced.
    introduced: 
    tags: []
  - name: Starlark
    id: starlark
    description: |
      The `starlark` processor calls a Starlark function for each matched
      metric, allowing for custom programmatic metric processing.

      The Starlark language is a dialect of Python, and will be familiar to
      those who have experience with the Python language. However, there are
      major differences. Existing Python code is unlikely to work unmodified.
      The execution environment is sandboxed, and it is not possible to do I/O
      operations such as reading from files or sockets.

      The **[Starlark
      specification](https://github.com/google/starlark-go/blob/d1966c6b9fcd/doc/spec.md)**
      has details about the syntax and available functions.

      Telegraf minimum version: Telegraf 1.15.0
    introduced: 
    tags: []
  - name: Strings
    id: strings
    description: |
      The `strings` plugin maps certain go string functions onto measurement,
      tag, and field values. Values can be modified in place or stored in
      another key.

      Implemented functions are:

      - lowercase
      - uppercase
      - titlecase
      - trim
      - trim_left
      - trim_right
      - trim_prefix
      - trim_suffix
      - replace
      - left
      - base64decode
      - valid_utf8

      Please note that in this implementation these are processed in the order
      that they appear above.

      Specify the `measurement`, `tag`, `tag_key`, `field`, or `field_key` that
      you want processed in each section and optionally a `dest` if you want
      the result stored in a new tag or field. You can specify lots of
      transformations on data with a single strings processor.

      If you'd like to apply the change to every `tag`, `tag_key`, `field`,
      `field_key`, or `measurement`, use the value `"*"` for each respective
      field. Note that the `dest` field will be ignored if `"*"` is used.

      If you'd like to apply multiple processings to the same `tag_key` or
      `field_key`, note the process order stated above. See the second example
      below for an example.
    introduced: 
    tags: []
  - name: Tag Limit
    id: tag_limit
    description: |
      Use the `tag_limit` processor to ensure that only a certain number of
      tags are preserved for any given metric, and to choose the tags to
      preserve when the number of tags appended by the data source is over the
      limit.

      This can be useful when dealing with output systems (e.g. Stackdriver)
      that impose hard limits on the number of tags/labels per metric or where
      high levels of cardinality are computationally and/or financially
      expensive.
    introduced: 
    tags: []
  - name: Template
    id: template
    description: |
      The `template` processor applies a Go template to metrics to generate a
      new tag. The primary use case of this plugin is to create a tag that can
      be used for dynamic routing to multiple output plugins or using an output
      specific routing option.

      The template has access to each metric's measurement name, tags, fields,
      and timestamp using the interface in `/template_metric.go`.

      Read the full [Go Template
      Documentation](https://golang.org/pkg/text/template/).
    introduced: 
    tags: []
  - name: Timestamp
    id: timestamp
    description: |
      Use the timestamp processor to parse fields containing timestamps into
      timestamps of other formats.
    introduced: 
    tags: []
  - name: TopK
    id: topk
    description: |
      The TopK processor plugin is a filter designed to get the top series over
      a period of time. It can be tweaked to calculate the top metrics via
      different aggregation functions.

      This processor goes through these steps when processing a batch of
      metrics:

      1. Groups measurements in buckets based on their tags and name
      1. Every N seconds, for each bucket, for each selected field: aggregate
      all the measurements using a given aggregation function (min, sum, mean,
      etc) and the field.
      1. For each computed aggregation: order the buckets by the aggregation,
      then returns all measurements in the top `K` buckets

      Notes:

      * The deduplicates metrics
      * The name of the measurement is always used when grouping it
      * Depending on the amount of metrics on each bucket, more than `K` series
      may be returned
      * If a measurement does not have one of the selected fields, it is dropped
      from the aggregation
    introduced: 
    tags: []
  - name: Unpivot
    id: unpivot
    description: |
      You can use the `unpivot` processor to rotate a multi field series into
      single valued metrics. This transformation often results in data that is
      more easy to aggregate across fields.

      To perform the reverse operation use the [pivot] processor.
    introduced: 
    tags: []
